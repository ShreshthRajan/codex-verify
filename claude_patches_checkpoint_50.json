{
  "checkpoint_at": 50,
  "timestamp": "2025-10-12T19:44:35.385902",
  "results_so_far": [
    {
      "instance_id": "astropy__astropy-12907",
      "repo": "astropy/astropy",
      "problem_statement": "Modeling's `separability_matrix` does not compute separability correctly for nested CompoundModels\nConsider the following model:\r\n\r\n```python\r\nfrom astropy.modeling import models as m\r\nfrom astropy.modeling.separable import separability_matrix\r\n\r\ncm = m.Linear1D(10) & m.Linear1D(5)\r\n```\r\n\r\nIt's separability matrix as you might expect is a diagonal:\r\n\r\n```python\r\n>>> separability_matrix(cm)\r\narray([[ True, False],\r\n       [False,  True]])\r\n```\r\n\r\nIf I make the model more complex:\r\n```python\r\n>>> ",
      "hints_text": null,
      "claude_patch": "import numpy as np\nfrom astropy.modeling.core import Model, CompoundModel\nfrom astropy.modeling.separable import _separable, _coord_matrix\n\n\ndef _separable(transform):\n    \"\"\"\n    Calculate the separability of outputs.\n\n    Parameters\n    ----------\n    transform : `~astropy.modeling.core.Model`\n        A (compound) model.\n\n    Returns\n    -------\n    is_separable : ndarray of dtype bool\n        An array of shape (n_outputs,) where each element indicates\n        whether the output is separable.\n    \"\"\"\n    if isinstance(transform, CompoundModel):\n        sepleft = _separable(transform.left)\n        sepright = _separable(transform.right)\n        \n        if transform.op == '&':\n            return np.concatenate([sepleft, sepright])\n        elif transform.op == '|':\n            # For pipe operations, need to check if outputs from left\n            # affect multiple inputs on right\n            return sepright\n        elif transform.op == '+' or transform.op == '-' or transform.op == '*' or transform.op == '/' or transform.op == '**':\n            # Arithmetic operations mix outputs\n            return np.zeros(transform.n_outputs, dtype=bool)\n    else:\n        # A model is separable if n_inputs == n_outputs == 1 or if it's\n        # explicitly marked as separable\n        if transform.n_inputs == transform.n_outputs == 1:\n            return np.array([True])\n        elif transform.n_inputs == 1:\n            return np.zeros(transform.n_outputs, dtype=bool)\n        elif transform.n_outputs == 1:\n            return np.array([False])\n        else:\n            # Multi-input, multi-output models are generally not separable\n            return np.zeros(transform.n_outputs, dtype=bool)\n\n\ndef _coord_matrix(model, pos, noutp):\n    \"\"\"\n    Create an array representing inputs and outputs of a simple model.\n\n    Parameters\n    ----------\n    model : `~astropy.modeling.core.Model`\n        A simple model.\n    pos : str\n        Position of this model in the expression tree.\n        One of ['left', 'right'].\n    noutp : int\n        Number of outputs of the compound model of which the input model\n        is a left or right child.\n\n    Returns\n    -------\n    array : ndarray\n        A boolean array of shape (noutp, model.n_inputs).\n    \"\"\"\n    if pos == 'left':\n        return np.ones((model.n_outputs, model.n_inputs), dtype=bool)\n    else:\n        # For right models, need to account for outputs from left model\n        mat = np.zeros((noutp, model.n_inputs), dtype=bool)\n        mat[-model.n_outputs:, :] = True\n        return mat\n\n\ndef _cstack(left, right):\n    \"\"\"\n    Stack two separability matrices along the diagonal for the '&' operator.\n\n    Parameters\n    ----------\n    left : ndarray\n        Separability matrix of the left model.\n    right : ndarray\n        Separability matrix of the right model.\n\n    Returns\n    -------\n    result : ndarray\n        Combined separability matrix.\n    \"\"\"\n    left = np.asarray(left)\n    right = np.asarray(right)\n    \n    nleft_outputs, nleft_inputs = left.shape\n    nright_outputs, nright_inputs = right.shape\n    \n    # Create block diagonal matrix\n    result = np.zeros((nleft_outputs + nright_outputs, \n                       nleft_inputs + nright_inputs), dtype=bool)\n    result[:nleft_outputs, :nleft_inputs] = left\n    result[nleft_outputs:, nleft_inputs:] = right\n    \n    return result\n\n\ndef separability_matrix(transform):\n    \"\"\"\n    Compute the separability matrix of a transform.\n\n    Parameters\n    ----------\n    transform : `~astropy.modeling.core.Model`\n        A (compound) model.\n\n    Returns\n    -------\n    separability_matrix : ndarray\n        A boolean matrix of shape (n_outputs, n_inputs) where each element\n        indicates whether a particular output depends on a particular input.\n    \"\"\"\n    if isinstance(transform, CompoundModel):\n        left_matrix = separability_matrix(transform.left)\n        right_matrix = separability_matrix(transform.right)\n        \n        if transform.op == '&':\n            return _cstack(left_matrix, right_matrix)\n        elif transform.op == '|':\n            # Matrix multiplication for pipe operation\n            return np.dot(right_matrix.astype(int), left_matrix.astype(int)).astype(bool)\n        elif transform.op in ('+', '-', '*', '/', '**'):\n            # Arithmetic operations: all outputs depend on all inputs\n            return np.ones((transform.n_outputs, transform.n_inputs), dtype=bool)\n        else:\n            raise ValueError(f\"Unknown operator: {transform.op}\")\n    else:\n        # Simple model\n        if transform.separable:\n            # Model explicitly marked as separable\n            if transform.n_inputs == transform.n_outputs:\n                return np.eye(transform.n_inputs, dtype=bool)\n            else:\n                # Default: all outputs depend on all inputs\n                return np.ones((transform.n_outputs, transform.n_inputs), dtype=bool)\n        else:\n            # Non-separable model: all outputs depend on all inputs\n            return np.ones((transform.n_outputs, transform.n_inputs), dtype=bool)",
      "generation_time": 23.068993091583252,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 0,
      "high_issues": 8,
      "medium_issues": 2,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.44666666666666655,
        "style": 0.4600000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: edge_case_coverage - Low edge case coverage: 50.0%",
        "HIGH: production_readiness - Low production readiness: 73.3%"
      ],
      "verification_time": 0.16086220741271973,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "astropy__astropy-14182",
      "repo": "astropy/astropy",
      "problem_statement": "Please support header rows in RestructuredText output\n### Description\r\n\r\nIt would be great if the following would work:\r\n\r\n```Python\r\n>>> from astropy.table import QTable\r\n>>> import astropy.units as u\r\n>>> import sys\r\n>>> tbl = QTable({'wave': [350,950]*u.nm, 'response': [0.7, 1.2]*u.count})\r\n>>> tbl.write(sys.stdout,  format=\"ascii.rst\")\r\n===== ========\r\n wave response\r\n===== ========\r\n350.0      0.7\r\n950.0      1.2\r\n===== ========\r\n>>> tbl.write(sys.stdout,  format=\"ascii.fixed_width\", header",
      "hints_text": null,
      "claude_patch": "# astropy/io/ascii/rst.py\n\nfrom . import fixedwidth\n\n\nclass RST(fixedwidth.FixedWidth):\n    \"\"\"reStructuredText simple format table.\n\n    See: https://docutils.sourceforge.io/docs/ref/rst/restructuredtext.html#simple-tables\n\n    Example::\n\n      ==== ===== ======\n      Col1  Col2  Col3\n      ==== ===== ======\n        1    2.3  Hello\n        2    4.5  World\n      ==== ===== ======\n\n    Currently there is no support for reading tables which utilize continuation lines,\n    or for ones which define column spans through the use of an additional\n    line of dashes in the header.\n\n    \"\"\"\n\n    data_class = fixedwidth.FixedWidthData\n    header_class = fixedwidth.FixedWidthHeader\n\n    def __init__(self, header_rows=None):\n        super().__init__(delimiter_pad=None, bookend=False, header_rows=header_rows)\n\n    def write(self, lines):\n        lines = super().write(lines)\n        lines = [lines[0]] + [re.sub(r'\\s', '=', lines[0])] + lines[1:]\n        if self.header.start_line is not None:\n            # Multiline header - need to add header row separator line\n            i = self.header.start_line + len(self.header.header_rows)\n            lines = lines[:i+1] + [lines[i]] + lines[i+1:]\n        lines.append(lines[0])\n        return lines\n\n\nimport re",
      "generation_time": 15.756308317184448,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 0,
      "high_issues": 6,
      "medium_issues": 2,
      "low_issues": 9,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.6634779970700982,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: ast_analysis - Public function 'write' missing docstring - production documentation required",
        "HIGH: edge_case_coverage - Low edge case coverage: 50.0%"
      ],
      "verification_time": 0.0514070987701416,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "astropy__astropy-14365",
      "repo": "astropy/astropy",
      "problem_statement": "ascii.qdp Table format assumes QDP commands are upper case\n### Description\n\nascii.qdp assumes that commands in a QDP file are upper case, for example, for errors they must be \"READ SERR 1 2\" whereas QDP itself is not case sensitive and case use \"read serr 1 2\". \r\n\r\nAs many QDP files are created by hand, the expectation that all commands be all-caps should be removed.\n\n### Expected behavior\n\nThe following qdp file should read into a `Table` with errors, rather than crashing.\r\n```\r\nread serr 1 2 \r",
      "hints_text": "Welcome to Astropy \ud83d\udc4b and thank you for your first issue!\n\nA project member will respond to you as soon as possible; in the meantime, please double-check the [guidelines for submitting issues](https://",
      "claude_patch": "import re\nfrom astropy.io.ascii import qdp\n\n# Patch the _line_type function to be case-insensitive\noriginal_line_type = qdp._line_type\n\ndef _line_type_case_insensitive(line, delimiter=None):\n    \"\"\"Interpret a QDP file line (case-insensitive version).\n    \n    Parameters\n    ----------\n    line : str\n        a single line of the file\n    delimiter : str\n        delimiter for the values in the table\n\n    Returns\n    -------\n    type : str\n        Line type: \"comment\", \"command\", or \"data\"\n    \"\"\"\n    _decimal_re = r\"[+-]?(\\d+(\\.\\d*)?|\\.\\d+)([eE][+-]?\\d+)?\"\n    _command_re = r\"^\\s*(?P<command>[a-zA-Z]+)\\s+\"  # Made case-insensitive\n    \n    sep = delimiter\n    if delimiter is None:\n        sep = r\"\\s+\"\n    _new_re = rf\"^\\s*{_command_re}(?P<value>.*)\"\n    _data_re = rf\"^\\s*(?P<data>{_decimal_re}({sep}{_decimal_re})*)\\s*$\"\n    _type_re = rf\"^\\s*(?P<type>NO|LI|PO|LS|CS|ST|HI|VE|MA|ER|SE|BO|CO|CU|DA|DO|DT|FI|FR|GR|LA|LI|LO|OF|PA|PL|RE|RO|SC|TI|UT|VI|WI|XA|YA|ZA)\\s+\"  # Made case-insensitive\n    _comment_re = r\"^\\s*[!]\"\n\n    if re.match(_comment_re, line):\n        return \"comment\"\n    elif re.match(_data_re, line):\n        return \"data,data\"\n    elif re.match(_new_re, line, re.IGNORECASE):  # Added re.IGNORECASE\n        return \"new\"\n    elif re.match(_command_re, line, re.IGNORECASE):  # Added re.IGNORECASE\n        return \"command\"\n    else:\n        return None\n\n\n# Patch the _get_type_from_list_of_lines function to handle case-insensitive commands\noriginal_get_type_from_list_of_lines = qdp._get_type_from_list_of_lines\n\ndef _get_type_from_list_of_lines_case_insensitive(lines, delimiter=None):\n    \"\"\"Get the type of each line in a list of lines.\n    \n    Parameters\n    ----------\n    lines : list\n        list of lines\n    delimiter : str\n        delimiter for the values in the table\n\n    Returns\n    -------\n    type_list : list\n        list of line types\n    \"\"\"\n    type_list = []\n    for line in lines:\n        line_type = _line_type_case_insensitive(line, delimiter=delimiter)\n        type_list.append(line_type)\n    return type_list\n\n\n# Patch the _get_lines_from_file function to handle case-insensitive commands\noriginal_get_lines_from_file = qdp._get_lines_from_file\n\ndef _get_lines_from_file_case_insensitive(qdp_file, delimiter=None):\n    \"\"\"Get the lines from a QDP file.\n    \n    Parameters\n    ----------\n    qdp_file : str\n        Input QDP file name\n    delimiter : str\n        delimiter for the values in the table\n\n    Returns\n    -------\n    lines : list\n        list of lines\n    \"\"\"\n    with open(qdp_file) as fobj:\n        lines = [line.strip() for line in fobj.readlines()]\n    \n    return lines\n\n\n# Patch the _interpret_err_lines function to handle case-insensitive commands\noriginal_interpret_err_lines = qdp._interpret_err_lines\n\ndef _interpret_err_lines_case_insensitive(err_specs, ncols):\n    \"\"\"Interpret the error specifications.\n    \n    Parameters\n    ----------\n    err_specs : dict\n        ``{'serr': [1, 2], 'terr': [3, 4]}``\n    ncols : int\n        Number of columns\n\n    Returns\n    -------\n    colnames : list\n        List of column names\n    \"\"\"\n    colnames = [\"col{}\".format(i + 1) for i in range(ncols)]\n    \n    for spec_type, spec_vals in err_specs.items():\n        spec_type_lower = spec_type.lower()\n        if spec_type_lower == \"serr\":\n            for val in spec_vals:\n                colnames.append(\"col{}_err\".format(val))\n        elif spec_type_lower == \"terr\":\n            for val in spec_vals:\n                colnames.append(\"col{}_perr\".format(val))\n                colnames.append(\"col{}_nerr\".format(val))\n    \n    return colnames\n\n\n# Patch the _get_tables_from_qdp_file function to handle case-insensitive commands\noriginal_get_tables_from_qdp_file = qdp._get_tables_from_qdp_file\n\ndef _get_tables_from_qdp_file_case_insensitive(qdp_file, input_colnames=None, \n                                                delimiter=None, names=None):\n    \"\"\"Get the tables from a QDP file (case-insensitive version).\n    \n    Parameters\n    ----------\n    qdp_file : str\n        Input QDP file name\n    input_colnames : list of str\n        Column names\n    delimiter : str\n        delimiter for the values in the table\n    names : list of str\n        Names of the tables\n\n    Returns\n    -------\n    tables : dict\n        Dictionary of tables\n    \"\"\"\n    import numpy as np\n    from astropy.table import Table\n    \n    with open(qdp_file) as fobj:\n        lines = [line.strip() for line in fobj.readlines()]\n    \n    # Get the type of each line\n    type_list = []\n    for line in lines:\n        line_type = _line_type_case_insensitive(line, delimiter=delimiter)\n        type_list.append(line_type)\n    \n    # Parse the file\n    current_rows = []\n    tables = {}\n    table_id = 0\n    err_specs = {}\n    \n    command_re = re.compile(r\"READ\\s+([A-Z]+)\\s+(.*)\", re.IGNORECASE)\n    \n    for line, line_type in zip(lines, type_list):\n        if line_type == \"comment\":\n            continue\n        elif line_type == \"command\":\n            # Check if it's a READ command\n            match = command_re.match(line)\n            if match:\n                command_type = match.group(1).lower()\n                command_args = match.group(2).strip()\n                \n                if command_type in [\"serr\", \"terr\"]:\n                    # Parse error specifications\n                    args = [int(x) for x in command_args.split()]\n                    if command_type not in err_specs:\n                        err_specs[command_type] = []\n                    err_specs[command_type].extend(args)\n        elif line_type == \"new\":\n            # Start a new table\n            if current_rows:\n                # Save the current table\n                tables[table_id] = {\n                    \"data\": current_rows,\n                    \"err_specs\": err_specs.copy()\n                }\n                table_id += 1\n                current_rows = []\n                err_specs = {}\n        elif line_type and line_type.startswith(\"data\"):\n            # Add data row\n            current_rows.append(line)\n    \n    # Save the last table\n    if current_rows:\n        tables[table_id] = {\n            \"data\": current_rows,\n            \"err_specs\": err_specs.copy()\n        }\n    \n    return tables\n\n\n# Apply the patches\nqdp._line_type = _line_type_case_insensitive\nqdp._get_type_from_list_of_lines = _get_type_from_list_of_lines_case_insensitive\nqdp._interpret_err_lines = _interpret_err_lines_case_insensitive",
      "generation_time": 28.644597053527832,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 21,
      "critical_issues": 0,
      "high_issues": 12,
      "medium_issues": 3,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.4630000000000001,
        "performance": 0.925
      },
      "key_issues": [
        "HIGH: missing_exception_handling - Function '_get_tables_from_qdp_file_case_insensitive' missing exception handling for production depl",
        "HIGH: performance_bottleneck - Performance bottleneck: Deep nested loops (3 levels)",
        "HIGH: missing_exception_handling - Function '_get_lines_from_file_case_insensitive' missing exception handling for production deploymen"
      ],
      "verification_time": 0.06106996536254883,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "astropy__astropy-14995",
      "repo": "astropy/astropy",
      "problem_statement": "In v5.3, NDDataRef mask propagation fails when one of the operand does not have a mask\n### Description\n\nThis applies to v5.3. \r\n\r\nIt looks like when one of the operand does not have a mask, the mask propagation when doing arithmetic, in particular with `handle_mask=np.bitwise_or` fails.  This is not a problem in v5.2.\r\n\r\nI don't know enough about how all that works, but it seems from the error that the operand without a mask is set as a mask of None's and then the bitwise_or tries to operate on ",
      "hints_text": "Welcome to Astropy \ud83d\udc4b and thank you for your first issue!\n\nA project member will respond to you as soon as possible; in the meantime, please double-check the [guidelines for submitting issues](https://",
      "claude_patch": "import numpy as np\nfrom astropy.nddata import NDDataRef\n\n# Test to verify the fix\ndef test_mask_propagation_with_none_mask():\n    \"\"\"Test that mask propagation works when one operand has no mask.\"\"\"\n    array = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n    mask = np.array([[0, 1, 64], [8, 0, 1], [2, 1, 0]])\n\n    nref_nomask = NDDataRef(array)\n    nref_mask = NDDataRef(array, mask=mask)\n\n    # Test multiply mask by constant (mask * no mask)\n    result = nref_mask.multiply(1., handle_mask=np.bitwise_or)\n    assert np.array_equal(result.mask, mask)\n\n    # Test multiply mask by no mask (mask * no mask)\n    result = nref_mask.multiply(nref_nomask, handle_mask=np.bitwise_or)\n    assert np.array_equal(result.mask, mask)\n\n    # Test multiply no mask by mask (no mask * mask) - commutativity\n    result = nref_nomask.multiply(nref_mask, handle_mask=np.bitwise_or)\n    assert np.array_equal(result.mask, mask)\n\n    # Test with boolean masks\n    bool_mask = mask.astype(bool)\n    nref_bool_mask = NDDataRef(array, mask=bool_mask)\n    \n    result1 = nref_nomask.multiply(nref_bool_mask)\n    result2 = nref_bool_mask.multiply(nref_nomask)\n    \n    assert result1.mask.dtype == bool\n    assert result2.mask.dtype == bool\n    assert np.array_equal(result1.mask, result2.mask)\n\nif __name__ == '__main__':\n    test_mask_propagation_with_none_mask()\n    print(\"All tests passed!\")",
      "generation_time": 14.816173076629639,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 7,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 0,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8833333333333334,
        "style": 0.9243340938163356,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%",
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.12424206733703613,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "astropy__astropy-6938",
      "repo": "astropy/astropy",
      "problem_statement": "Possible bug in io.fits related to D exponents\nI came across the following code in ``fitsrec.py``:\r\n\r\n```python\r\n        # Replace exponent separator in floating point numbers\r\n        if 'D' in format:\r\n            output_field.replace(encode_ascii('E'), encode_ascii('D'))\r\n```\r\n\r\nI think this may be incorrect because as far as I can tell ``replace`` is not an in-place operation for ``chararray`` (it returns a copy). Commenting out this code doesn't cause any tests to fail so I think this code ",
      "hints_text": "It is tested with `astropy/io/fits/tests/test_checksum.py:test_ascii_table_data` but indeed the operation is not inplace and it does not fail. Using 'D' is probably better, but since #5362 (I had vagu",
      "claude_patch": "# Find the location in fitsrec.py where the bug occurs and fix it\n# The issue is that replace() returns a copy, not modifying in-place\n\n# Original buggy code:\n# output_field.replace(encode_ascii('E'), encode_ascii('D'))\n\n# Fixed code:\noutput_field = output_field.replace(encode_ascii('E'), encode_ascii('D'))",
      "generation_time": 3.552076816558838,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 3,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 0,
      "low_issues": 2,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.029809951782226562,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "astropy__astropy-7746",
      "repo": "astropy/astropy",
      "problem_statement": "Issue when passing empty lists/arrays to WCS transformations\nThe following should not fail but instead should return empty lists/arrays:\r\n\r\n```\r\nIn [1]: from astropy.wcs import WCS\r\n\r\nIn [2]: wcs = WCS('2MASS_h.fits')\r\n\r\nIn [3]: wcs.wcs_pix2world([], [], 0)\r\n---------------------------------------------------------------------------\r\nInconsistentAxisTypesError                Traceback (most recent call last)\r\n<ipython-input-3-e2cc0e97941a> in <module>()\r\n----> 1 wcs.wcs_pix2world([], [], 0)\r\n\r\n~",
      "hints_text": null,
      "claude_patch": "import numpy as np\n\n# Patch for astropy/wcs/wcs.py\n\ndef _array_converter_patch(self, func, sky, ra_dec_order=False, *args):\n    \"\"\"\n    Modified _array_converter to handle empty arrays/lists\n    \"\"\"\n    \n    if len(args) == 2:\n        # Two arguments: a sequence of sequences, and an origin\n        xy, origin = args\n        try:\n            xy = np.asarray(xy)\n            origin = int(origin)\n        except Exception:\n            raise TypeError(\n                \"When providing two arguments, they must be \"\n                \"(coords, origin), where coords is a sequence of \"\n                \"sequences, and origin is an integer.\")\n        \n        if xy.size == 0:\n            # Handle empty input\n            if xy.ndim == 1:\n                # Empty 1-D array\n                return np.array([])\n            elif xy.ndim == 2:\n                # Empty 2-D array - return with correct shape\n                if xy.shape[0] == 0:\n                    # No points, but may have axis dimension\n                    if xy.shape[1] == self.naxis:\n                        return np.empty((0, self.naxis))\n                    else:\n                        return np.empty((0, self.naxis))\n                elif xy.shape[1] == 0:\n                    # No axes\n                    return np.empty((xy.shape[0], self.naxis))\n            return np.array([])\n        \n        if xy.ndim > 2:\n            raise ValueError(\n                \"When providing two arguments, the coordinates must be \"\n                \"a 2-D array where the second dimension is the number of axes.\")\n        \n        if xy.ndim == 1:\n            xy = xy.reshape((1, xy.shape[0]))\n        \n        if xy.shape[1] != self.naxis:\n            raise ValueError(\n                \"When providing two arguments, the coordinates must have \"\n                \"{0} dimensions.\".format(self.naxis))\n        \n        if ra_dec_order and sky == 'input':\n            xy = self._denormalize_sky(xy)\n        output = func(xy, origin)\n        if ra_dec_order and sky == 'output':\n            output = self._normalize_sky(output)\n        \n        if len(args) == 2 and isinstance(args[0], np.ndarray):\n            return output\n        else:\n            return [output[:, i] for i in range(output.shape[1])]\n    \n    elif len(args) == self.naxis + 1:\n        # Multiple arguments: one for each axis, plus origin\n        axes = args[:-1]\n        origin = args[-1]\n        \n        try:\n            axes = [np.asarray(x) for x in axes]\n            origin = int(origin)\n        except Exception:\n            raise TypeError(\n                \"When providing {0} arguments, they must be \"\n                \"a 1-D array for each axis, followed by an origin.\".format(\n                    self.naxis + 1))\n        \n        # Check if any axis is empty\n        if any(axis.size == 0 for axis in axes):\n            # Return empty arrays for each axis\n            return tuple(np.array([]) for _ in range(self.naxis))\n        \n        # Check that all axes have the same shape\n        shapes = [axis.shape for axis in axes]\n        if not all(shape == shapes[0] for shape in shapes):\n            raise ValueError(\n                \"All axes must have the same shape\")\n        \n        # Stack axes into a single array\n        xy = np.column_stack(axes)\n        \n        if ra_dec_order and sky == 'input':\n            xy = self._denormalize_sky(xy)\n        output = func(xy, origin)\n        if ra_dec_order and sky == 'output':\n            output = self._normalize_sky(output)\n        \n        return tuple(output[:, i] for i in range(output.shape[1]))\n    \n    else:\n        raise TypeError(\n            \"Expected {0} or 2 arguments, got {1}\".format(\n                self.naxis + 1, len(args)))",
      "generation_time": 17.403475046157837,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 15,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 4,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.55,
        "style": 0.45199999999999996,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: ast_analysis - Function '_array_converter_patch' too long (98 lines) - production maintainability concern",
        "HIGH: logic - Low logic score: 0.00",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.19525980949401855,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-10914",
      "repo": "django/django",
      "problem_statement": "Set default FILE_UPLOAD_PERMISSION to 0o644.\nDescription\n\t\nHello,\nAs far as I can see, the \u200bFile Uploads documentation page does not mention any permission issues.\nWhat I would like to see is a warning that in absence of explicitly configured FILE_UPLOAD_PERMISSIONS, the permissions for a file uploaded to FileSystemStorage might not be consistent depending on whether a MemoryUploadedFile or a TemporaryUploadedFile was used for temporary storage of the uploaded data (which, with the default FILE_",
      "hints_text": "I think you're talking about ef70af77ec53160d5ffa060c1bdf5ed93322d84f (#28540). I guess the question is whether or not that documentation should be duplicated elsewhere.\nThank you Tim, this is precise",
      "claude_patch": "# Patch for django/conf/global_settings.py\n\n# Change FILE_UPLOAD_PERMISSIONS default from None to 0o644\nFILE_UPLOAD_PERMISSIONS = 0o644",
      "generation_time": 27.321303129196167,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 1.0,
      "verification_verdict": "PASS",
      "issues_found": 3,
      "critical_issues": 0,
      "high_issues": 0,
      "medium_issues": 0,
      "low_issues": 3,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [],
      "verification_time": 0.030870914459228516,
      "patch_quality_estimate": "HIGH"
    },
    {
      "instance_id": "django__django-10924",
      "repo": "django/django",
      "problem_statement": "Allow FilePathField path to accept a callable.\nDescription\n\t\nI have a special case where I want to create a model containing the path to some local files on the server/dev machine. Seeing as the place where these files are stored is different on different machines I have the following:\nimport os\nfrom django.conf import settings\nfrom django.db import models\nclass LocalFiles(models.Model):\n\tname = models.CharField(max_length=255)\n\tfile = models.FilePathField(path=os.path.join(settings.LOCAL_FILE_D",
      "hints_text": "So, to clarify, what exactly is the bug/feature proposal/issue here? The way I see it, you're supposed to use os.path.join() and LOCAL_FILE_DIR to define a relative path. It's sort of like how we use ",
      "claude_patch": "# Patch for django/forms/fields.py\n\n# In the FilePathField.__init__ method, evaluate callable path at the beginning\n\n# Original location: django/forms/fields.py, FilePathField class\n\nimport os\n\n# Find the FilePathField class __init__ method and modify it\n\n# Original code around line 1090-1110:\n# def __init__(self, path, match=None, recursive=False, allow_files=True,\n#              allow_folders=False, **kwargs):\n#     self.path, self.match, self.recursive = path, match, recursive\n#     self.allow_files, self.allow_folders = allow_files, allow_folders\n#     super().__init__(choices=(), **kwargs)\n#     ...\n\n# Modified code:\ndef FilePathField__init__(self, path, match=None, recursive=False, allow_files=True,\n             allow_folders=False, **kwargs):\n    # Evaluate callable path\n    if callable(path):\n        path = path()\n    \n    self.path, self.match, self.recursive = path, match, recursive\n    self.allow_files, self.allow_folders = allow_files, allow_folders\n    super(FilePathField, self).__init__(choices=(), **kwargs)\n    \n    if self.required:\n        self.choices = []\n    else:\n        self.choices = [(\"\", \"---------\")]\n    \n    if self.match is not None:\n        self.match_re = re.compile(self.match)\n    \n    if recursive:\n        for root, dirs, files in sorted(os.walk(self.path)):\n            if self.allow_files:\n                for f in sorted(files):\n                    if self.match is None or self.match_re.search(f):\n                        f = os.path.join(root, f)\n                        self.choices.append((f, f.replace(path, \"\", 1)))\n            if self.allow_folders:\n                for f in sorted(dirs):\n                    if self.match is None or self.match_re.search(f):\n                        f = os.path.join(root, f)\n                        self.choices.append((f, f.replace(path, \"\", 1)))\n    else:\n        choices = []\n        with os.scandir(self.path) as entries:\n            for f in entries:\n                if f.name == '__pycache__':\n                    continue\n                if (((self.allow_files and f.is_file()) or\n                        (self.allow_folders and f.is_dir())) and\n                        (self.match is None or self.match_re.search(f.name))):\n                    choices.append((f.path, f.name))\n        self.choices.extend(sorted(choices, key=operator.itemgetter(1)))\n    \n    self.widget.choices = self.choices\n\n\n# Patch for django/db/models/fields/__init__.py\n\n# In the FilePathField class, add deconstruct method to handle callable\n\n# Original location: django/db/models/fields/__init__.py, FilePathField class\n\ndef FilePathField_deconstruct(self):\n    name, path, args, kwargs = super(FilePathField, self).deconstruct()\n    if self.path is not None:\n        kwargs['path'] = self.path\n    if self.match is not None:\n        kwargs['match'] = self.match\n    if self.recursive is not False:\n        kwargs['recursive'] = self.recursive\n    if self.allow_files is not True:\n        kwargs['allow_files'] = self.allow_files\n    if self.allow_folders is not False:\n        kwargs['allow_folders'] = self.allow_folders\n    if kwargs.get(\"max_length\") == 100:\n        del kwargs[\"max_length\"]\n    return name, path, args, kwargs\n\n\n# Complete patch file\n\n# File: django/forms/fields.py\nimport os\nimport re\nimport operator\n\n# Locate FilePathField class and replace __init__ method\n# Around line 1090\n\nclass FilePathField:\n    def __init__(self, path, match=None, recursive=False, allow_files=True,\n                 allow_folders=False, **kwargs):\n        # Evaluate callable path at the beginning\n        if callable(path):\n            path = path()\n        \n        self.path, self.match, self.recursive = path, match, recursive\n        self.allow_files, self.allow_folders = allow_files, allow_folders\n        super().__init__(choices=(), **kwargs)\n        \n        if self.required:\n            self.choices = []\n        else:\n            self.choices = [(\"\", \"---------\")]\n        \n        if self.match is not None:\n            self.match_re = re.compile(self.match)\n        \n        if recursive:\n            for root, dirs, files in sorted(os.walk(self.path)):\n                if self.allow_files:\n                    for f in sorted(files):\n                        if self.match is None or self.match_re.search(f):\n                            f = os.path.join(root, f)\n                            self.choices.append((f, f.replace(path, \"\", 1)))\n                if self.allow_folders:\n                    for f in sorted(dirs):\n                        if self.match is None or self.match_re.search(f):\n                            f = os.path.join(root, f)\n                            self.choices.append((f, f.replace(path, \"\", 1)))\n        else:\n            choices = []\n            with os.scandir(self.path) as entries:\n                for f in entries:\n                    if f.name == '__pycache__':\n                        continue\n                    if (((self.allow_files and f.is_file()) or\n                            (self.allow_folders and f.is_dir())) and\n                            (self.match is None or self.match_re.search(f.name))):\n                        choices.append((f.path, f.name))\n            self.choices.extend(sorted(choices, key=operator.itemgetter(1)))\n        \n        self.widget.choices = self.choices",
      "generation_time": 18.93800377845764,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 23,
      "critical_issues": 0,
      "high_issues": 11,
      "medium_issues": 6,
      "low_issues": 6,
      "agent_scores": {
        "security": 0.44999999999999996,
        "correctness": 0.55,
        "style": 0.3520000000000001,
        "performance": 0.875
      },
      "key_issues": [
        "HIGH: performance_bottleneck - Performance bottleneck: Deep nested loops (3 levels)",
        "HIGH: dangerous_import - High-risk import: os (risk level: 2)",
        "HIGH: performance_bottleneck - Performance bottleneck: Deep nested loops (3 levels)"
      ],
      "verification_time": 0.05835533142089844,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11001",
      "repo": "django/django",
      "problem_statement": "Incorrect removal of order_by clause created as multiline RawSQL\nDescription\n\t\nHi.\nThe SQLCompiler is ripping off one of my \"order by\" clause, because he \"thinks\" the clause was already \"seen\" (in SQLCompiler.get_order_by()). I'm using expressions written as multiline RawSQLs, which are similar but not the same. \nThe bug is located in SQLCompiler.get_order_by(), somewhere around line computing part of SQL query without ordering:\nwithout_ordering = self.ordering_parts.search(sql).group(1)\nThe sql",
      "hints_text": "Is there a reason you can't use \u200bconditional expressions, e.g. something like: MyModel.objects.annotate( custom_order=Case( When(...), ) ).order_by('custom_order') I'm thinking that would avoid fiddly",
      "claude_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 1234567890..abcdefghij 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -340,7 +340,10 @@ class SQLCompiler:\n                     errors.append(e.args[0])\n                 continue\n             if sql:\n-                without_ordering = self.ordering_parts.search(sql).group(1)\n+                # Remove newlines from multiline SQL to ensure proper duplicate detection\n+                sql_oneline = ' '.join(sql.replace('\\r\\n', '\\n').replace('\\r', '\\n').split('\\n'))\n+                match = self.ordering_parts.search(sql_oneline)\n+                without_ordering = match.group(1) if match else sql_oneline\n                 if without_ordering in seen:\n                     continue\n                 seen.add(without_ordering)",
      "generation_time": 4.815023899078369,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.0386807918548584,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11019",
      "repo": "django/django",
      "problem_statement": "Merging 3 or more media objects can throw unnecessary MediaOrderConflictWarnings\nDescription\n\t\nConsider the following form definition, where text-editor-extras.js depends on text-editor.js but all other JS files are independent:\nfrom django import forms\nclass ColorPicker(forms.Widget):\n\tclass Media:\n\t\tjs = ['color-picker.js']\nclass SimpleTextWidget(forms.Widget):\n\tclass Media:\n\t\tjs = ['text-editor.js']\nclass FancyTextWidget(forms.Widget):\n\tclass Media:\n\t\tjs = ['text-editor.js', 'text-editor-extr",
      "hints_text": "As a tentative fix, I propose that media objects should explicitly distinguish between cases where we do / don't care about ordering, notionally something like: class FancyTextWidget(forms.Widget): cl",
      "claude_patch": "import warnings\nfrom collections import OrderedDict\n\n\ndef topological_sort(lists):\n    \"\"\"\n    Perform a topological sort on the given lists, preserving order where possible.\n    \n    This function takes multiple lists and merges them while respecting the ordering\n    constraints within each list. It builds a dependency graph and performs a\n    topological sort to find a valid ordering.\n    \n    Args:\n        lists: Multiple lists to be merged\n        \n    Returns:\n        A single merged list that respects all ordering constraints\n    \"\"\"\n    # Build dependency graph and track all items in order of first appearance\n    dependency_graph = {}\n    all_items = []\n    seen = set()\n    \n    for sublist in lists:\n        for item in sublist:\n            if item not in seen:\n                all_items.append(item)\n                seen.add(item)\n                dependency_graph[item] = set()\n    \n    # Build dependencies: if B follows A in any list, then A is a dependency of B\n    for sublist in lists:\n        for i in range(len(sublist) - 1):\n            # sublist[i] must come before sublist[i+1]\n            dependency_graph[sublist[i + 1]].add(sublist[i])\n    \n    # Perform topological sort using Kahn's algorithm with stability\n    result = []\n    in_degree = {item: 0 for item in all_items}\n    \n    # Calculate in-degrees\n    for item in all_items:\n        for dep in dependency_graph[item]:\n            in_degree[item] += 1\n    \n    # Process items in order of first appearance to maintain stability\n    available = [item for item in all_items if in_degree[item] == 0]\n    \n    while available:\n        # Take the first available item to maintain order\n        current = available.pop(0)\n        result.append(current)\n        \n        # Update in-degrees for items that depend on current\n        for item in all_items:\n            if current in dependency_graph[item]:\n                dependency_graph[item].remove(current)\n                in_degree[item] -= 1\n                if in_degree[item] == 0 and item not in available and item not in result:\n                    # Insert in order of first appearance\n                    inserted = False\n                    for i, avail_item in enumerate(available):\n                        if all_items.index(item) < all_items.index(avail_item):\n                            available.insert(i, item)\n                            inserted = True\n                            break\n                    if not inserted:\n                        available.append(item)\n    \n    # Check for cycles\n    if len(result) != len(all_items):\n        # There's a cycle, issue a warning and return best effort\n        remaining = [item for item in all_items if item not in result]\n        warnings.warn(\n            'Detected duplicate Media files in an opposite order: %s' % ', '.join(remaining),\n            MediaOrderConflictWarning,\n        )\n        result.extend(remaining)\n    \n    return result\n\n\n# Patch for django/forms/widgets.py Media class\n# Replace the _js property with this implementation:\n\n@property\ndef _js(self):\n    if not self._js_lists:\n        return []\n    # Filter out empty lists\n    non_empty_lists = [lst for lst in self._js_lists if lst]\n    if not non_empty_lists:\n        return []\n    if len(non_empty_lists) == 1:\n        # Single list - just deduplicate\n        return list(OrderedDict.fromkeys(non_empty_lists[0]))\n    # Multiple lists - use topological sort\n    return topological_sort(non_empty_lists)\n\n\n# Also update the merge method to handle the new approach:\n@staticmethod\ndef merge(*lists):\n    \"\"\"\n    Merge multiple lists into a single list, preserving order constraints.\n    \n    This is kept for backwards compatibility but now uses topological sort\n    when merging multiple lists.\n    \"\"\"\n    if not lists:\n        return []\n    \n    # Filter out empty lists\n    non_empty = [lst for lst in lists if lst]\n    if not non_empty:\n        return []\n    if len(non_empty) == 1:\n        return list(OrderedDict.fromkeys(non_empty[0]))\n    \n    return topological_sort(non_empty)",
      "generation_time": 17.16075301170349,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 20,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 6,
      "low_issues": 7,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.45,
        "style": 0.368,
        "performance": 0.96
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 33.3%",
        "HIGH: ast_analysis - Function 'topological_sort' too long (75 lines) - production maintainability concern",
        "HIGH: logic - Low logic score: 0.00"
      ],
      "verification_time": 0.05878496170043945,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11039",
      "repo": "django/django",
      "problem_statement": "sqlmigrate wraps it's outpout in BEGIN/COMMIT even if the database doesn't support transactional DDL\nDescription\n\t \n\t\t(last modified by Simon Charette)\n\t \nThe migration executor only adds the outer BEGIN/COMMIT \u200bif the migration is atomic and \u200bthe schema editor can rollback DDL but the current sqlmigrate logic only takes migration.atomic into consideration.\nThe issue can be addressed by\nChanging sqlmigrate \u200bassignment of self.output_transaction to consider connection.features.can_rollback_ddl as",
      "hints_text": "I marked the ticket as easy picking because I included the above guidelines but feel free to uncheck it if you deem it inappropriate. Super. We don't have enough Easy Pickings tickets for the demand, ",
      "claude_patch": "diff --git a/django/core/management/commands/sqlmigrate.py b/django/core/management/commands/sqlmigrate.py\nindex 1234567890..abcdefghij 100644\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -59,7 +59,7 @@ class Command(BaseCommand):\n         plan = [(executor.loader.graph.nodes[target], options['backwards'])]\n         sql_statements = executor.collect_sql(plan)\n         if not sql_statements and options['verbosity'] >= 1:\n             self.stdout.write('No operations found.')\n         return '\\n'.join(sql_statements)\n \n-        self.output_transaction = migration.atomic\n+        self.output_transaction = migration.atomic and connection.features.can_rollback_ddl",
      "generation_time": 14.900386810302734,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.0,
      "verification_verdict": "ERROR",
      "issues_found": 1,
      "critical_issues": 1,
      "high_issues": 0,
      "medium_issues": 0,
      "low_issues": 0,
      "agent_scores": {},
      "key_issues": [
        "CRITICAL: system_error - Verification failed: sequence item 1: expected str instance, NoneType found"
      ],
      "verification_time": 0.049446821212768555,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11049",
      "repo": "django/django",
      "problem_statement": "Correct expected format in invalid DurationField error message\nDescription\n\t\nIf you enter a duration \"14:00\" into a duration field, it translates to \"00:14:00\" which is 14 minutes.\nThe current error message for invalid DurationField says that this should be the format of durations: \"[DD] [HH:[MM:]]ss[.uuuuuu]\". But according to the actual behaviour, it should be: \"[DD] [[HH:]MM:]ss[.uuuuuu]\", because seconds are mandatory, minutes are optional, and hours are optional if minutes are provided.\nThi",
      "hints_text": null,
      "claude_patch": "# django/forms/fields.py\n\nfrom django.core import validators\nfrom django.core.exceptions import ValidationError\nfrom django.forms.fields import Field\nfrom django.utils.translation import gettext_lazy as _\nfrom django.utils.duration import parse_duration\n\n\n# Locate the DurationField class and update it\nclass DurationField(Field):\n    default_error_messages = {\n        'invalid': _('Enter a valid duration.'),\n        'overflow': _('The number of days must be between {min_days} and {max_days}.'),\n    }\n\n    def __init__(self, *, help_text=_('Format: \"[DD] [[HH:]MM:]ss[.uuuuuu]\"'), **kwargs):\n        super().__init__(help_text=help_text, **kwargs)\n\n    def prepare_value(self, value):\n        if isinstance(value, datetime.timedelta):\n            return duration_string(value)\n        return value\n\n    def to_python(self, value):\n        if value in self.empty_values:\n            return None\n        if isinstance(value, datetime.timedelta):\n            return value\n        try:\n            value = parse_duration(str(value))\n        except OverflowError:\n            raise ValidationError(\n                self.error_messages['overflow'].format(\n                    min_days=datetime.timedelta.min.days,\n                    max_days=datetime.timedelta.max.days,\n                ),\n                code='overflow',\n            )\n        if value is None:\n            raise ValidationError(self.error_messages['invalid'], code='invalid')\n        return value",
      "generation_time": 17.83569598197937,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 2,
      "low_issues": 7,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.6627511012661632,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 66.7%",
        "HIGH: ast_analysis - Public function 'prepare_value' missing docstring - production documentation required",
        "HIGH: logic - Low logic score: 0.60"
      ],
      "verification_time": 0.18239212036132812,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11099",
      "repo": "django/django",
      "problem_statement": "UsernameValidator allows trailing newline in usernames\nDescription\n\t\nASCIIUsernameValidator and UnicodeUsernameValidator use the regex \nr'^[\\w.@+-]+$'\nThe intent is to only allow alphanumeric characters as well as ., @, +, and -. However, a little known quirk of Python regexes is that $ will also match a trailing newline. Therefore, the user name validators will accept usernames which end with a newline. You can avoid this behavior by instead using \\A and \\Z to terminate regexes. For example, th",
      "hints_text": null,
      "claude_patch": "import re\nfrom django.core import validators\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.translation import gettext_lazy as _\n\n\n@deconstructible\nclass ASCIIUsernameValidator(validators.RegexValidator):\n    regex = r'\\A[\\w.@+-]+\\Z'\n    message = _(\n        'Enter a valid username. This value may contain only English letters, '\n        'numbers, and @/./+/-/_ characters.'\n    )\n    flags = re.ASCII\n\n\n@deconstructible\nclass UnicodeUsernameValidator(validators.RegexValidator):\n    regex = r'\\A[\\w.@+-]+\\Z'\n    message = _(\n        'Enter a valid username. This value may contain only letters, '\n        'numbers, and @/./+/-/_ characters.'\n    )\n    flags = 0",
      "generation_time": 4.120998859405518,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.992,
      "verification_verdict": "PASS",
      "issues_found": 6,
      "critical_issues": 0,
      "high_issues": 0,
      "medium_issues": 1,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.834,
        "performance": 1.0
      },
      "key_issues": [],
      "verification_time": 0.07856106758117676,
      "patch_quality_estimate": "HIGH"
    },
    {
      "instance_id": "django__django-11133",
      "repo": "django/django",
      "problem_statement": "HttpResponse doesn't handle memoryview objects\nDescription\n\t\nI am trying to write a BinaryField retrieved from the database into a HttpResponse. When the database is Sqlite this works correctly, but Postgresql returns the contents of the field as a memoryview object and it seems like current Django doesn't like this combination:\nfrom django.http import HttpResponse\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n# String content\nresponse = HttpResponse(\"My Content\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nresponse.content\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t",
      "hints_text": "I guess HttpResponseBase.make_bytes \u200bcould be adapted to deal with memoryview objects by casting them to bytes. In all cases simply wrapping the memoryview in bytes works as a workaround HttpResponse(",
      "claude_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 1234567890..abcdefghij 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -272,6 +272,8 @@ class HttpResponseBase:\n             return bytes(value, self.charset)\n         if isinstance(value, bytes):\n             return value\n+        if isinstance(value, memoryview):\n+            return value.tobytes()\n         if isinstance(value, str):\n             return bytes(value, self.charset)\n         # Handle non-string types.",
      "generation_time": 3.9488730430603027,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.024738073348999023,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11179",
      "repo": "django/django",
      "problem_statement": "delete() on instances of models without any dependencies doesn't clear PKs.\nDescription\n\t\nDeleting any model with no dependencies not updates the PK on the model. It should be set to None after .delete() call.\nSee Django.db.models.deletion:276-281. Should update the model line 280.\n",
      "hints_text": "Reproduced at 1ffddfc233e2d5139cc6ec31a4ec6ef70b10f87f. Regression in bc7dd8490b882b2cefdc7faf431dc64c532b79c9. Thanks for the report.\nRegression test.\nI have attached a simple fix which mimics what \u200b",
      "claude_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -273,11 +273,18 @@ class Collector:\n                 query = sql.DeleteQuery(model)\n                 pk_list = [obj.pk for obj in instances]\n                 count = query.delete_batch(pk_list, self.using)\n+                if count:\n+                    for obj in instances:\n+                        setattr(obj, model._meta.pk.attname, None)\n                 deleted_counter[model._meta.label] += count\n \n         # update collected instances\n         for instances_for_fieldvalues in self.field_updates.values():\n             for (field, value), instances in instances_for_fieldvalues.items():\n+                if field.primary_key:\n+                    for obj in instances:\n+                        setattr(obj, field.attname, None)\n+                else:\n                 for obj in instances:\n                     setattr(obj, field.attname, value)\n         for model, instances in self.data.items():",
      "generation_time": 9.08218502998352,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04348611831665039,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11283",
      "repo": "django/django",
      "problem_statement": "Migration auth.0011_update_proxy_permissions fails for models recreated as a proxy.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nI am trying to update my project to Django 2.2. When I launch python manage.py migrate, I get this error message when migration auth.0011_update_proxy_permissions is applying (full stacktrace is available \u200bhere):\ndjango.db.utils.IntegrityError: duplicate key value violates unique constraint \"idx_18141_auth_permission_content_type_id_01ab375a_uniq\" DETAIL: Ke",
      "hints_text": "Please provide a sample project or enough details to reproduce the issue.\nSame problem for me. If a Permission exists already with the new content_type and permission name, IntegrityError is raised si",
      "claude_patch": "# django/contrib/auth/migrations/0011_update_proxy_permissions.py\n\nfrom django.db import migrations, models\nfrom django.db.models import Q\n\n\ndef update_proxy_model_permissions(apps, schema_editor, reverse=False):\n    \"\"\"\n    Update the content_type of proxy model permissions to use the ContentType\n    of the proxy model.\n    \"\"\"\n    Permission = apps.get_model('auth', 'Permission')\n    ContentType = apps.get_model('contenttypes', 'ContentType')\n    \n    alias = schema_editor.connection.alias\n    \n    for Model in apps.get_models():\n        opts = Model._meta\n        if not opts.proxy:\n            continue\n        \n        proxy_content_type = ContentType.objects.using(alias).get_for_model(\n            Model, for_concrete_model=False\n        )\n        concrete_content_type = ContentType.objects.using(alias).get_for_model(\n            Model, for_concrete_model=True\n        )\n        \n        proxy_model_permissions = Permission.objects.using(alias).filter(\n            content_type=concrete_content_type,\n            codename__in=[\n                '%s_%s' % (action, opts.model_name)\n                for action in ('add', 'change', 'delete', 'view')\n            ],\n        )\n        \n        for permission in proxy_model_permissions:\n            # Check if a permission with the proxy content type already exists\n            try:\n                existing_permission = Permission.objects.using(alias).get(\n                    content_type=proxy_content_type,\n                    codename=permission.codename,\n                )\n                # If it exists, we need to handle the conflict\n                # Delete the old permission and keep the existing one with proxy content type\n                permission.delete()\n            except Permission.DoesNotExist:\n                # No conflict, safe to update\n                permission.content_type = proxy_content_type\n                permission.save()\n\n\ndef revert_proxy_model_permissions(apps, schema_editor):\n    \"\"\"\n    Update the content_type of proxy model permissions to use the ContentType\n    of the concrete model.\n    \"\"\"\n    Permission = apps.get_model('auth', 'Permission')\n    ContentType = apps.get_model('contenttypes', 'ContentType')\n    \n    alias = schema_editor.connection.alias\n    \n    for Model in apps.get_models():\n        opts = Model._meta\n        if not opts.proxy:\n            continue\n        \n        proxy_content_type = ContentType.objects.using(alias).get_for_model(\n            Model, for_concrete_model=False\n        )\n        concrete_content_type = ContentType.objects.using(alias).get_for_model(\n            Model, for_concrete_model=True\n        )\n        \n        proxy_model_permissions = Permission.objects.using(alias).filter(\n            content_type=proxy_content_type,\n            codename__in=[\n                '%s_%s' % (action, opts.model_name)\n                for action in ('add', 'change', 'delete', 'view')\n            ],\n        )\n        \n        for permission in proxy_model_permissions:\n            permission.content_type = concrete_content_type\n            permission.save()\n\n\nclass Migration(migrations.Migration):\n    dependencies = [\n        ('auth', '0010_alter_group_name_max_length'),\n        ('contenttypes', '0002_remove_content_type_name'),\n    ]\n    operations = [\n        migrations.RunPython(\n            update_proxy_model_permissions,\n            revert_proxy_model_permissions,\n        ),\n    ]",
      "generation_time": 11.807071208953857,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 7,
      "low_issues": 8,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.5399999999999999,
        "style": 0.46799999999999997,
        "performance": 0.988
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%"
      ],
      "verification_time": 0.1684589385986328,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11422",
      "repo": "django/django",
      "problem_statement": "Autoreloader with StatReloader doesn't track changes in manage.py.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nThis is a bit convoluted, but here we go.\nEnvironment (OSX 10.11):\n$ python -V\nPython 3.6.2\n$ pip -V\npip 19.1.1\n$ pip install Django==2.2.1\nSteps to reproduce:\nRun a server python manage.py runserver\nEdit the manage.py file, e.g. add print(): \ndef main():\n\tprint('sth')\n\tos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ticket_30479.settings')\n\t...\nUnder 2.1.8 (and prior), thi",
      "hints_text": "Thanks for the report. I simplified scenario. Regression in c8720e7696ca41f3262d5369365cc1bd72a216ca. Reproduced at 8d010f39869f107820421631111417298d1c5bb9.\nArgh. I guess this is because manage.py is",
      "claude_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 1234567890..abcdef1234 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -112,6 +112,14 @@ def iter_modules_and_files(modules, extra_files):\n     # iteration.\n     for module in list(modules.values()):\n         if module is None:\n             continue\n+        # Handle __main__ module specially since __spec__ is None\n+        if module.__name__ == '__main__':\n+            filename = getattr(module, '__file__', None)\n+            if filename:\n+                filename = Path(filename).resolve()\n+                if filename.suffix in ['.py', '.pyc', '.pyo']:\n+                    yield filename.resolve()\n+            continue\n         if getattr(module, \"__spec__\", None) is None:\n             continue\n         spec = module.__spec__",
      "generation_time": 5.5801918506622314,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04172539710998535,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11564",
      "repo": "django/django",
      "problem_statement": "Add support for SCRIPT_NAME in STATIC_URL and MEDIA_URL\nDescription\n\t \n\t\t(last modified by Rostyslav Bryzgunov)\n\t \nBy default, {% static '...' %} tag just appends STATIC_URL in the path. When running on sub-path, using SCRIPT_NAME WSGI param, it results in incorrect static URL - it doesn't prepend SCRIPT_NAME prefix.\nThis problem can be solved with prepending SCRIPT_NAME to STATIC_URL in settings.py but that doesn't work when SCRIPT_NAME is a dynamic value.\nThis can be easily added into default ",
      "hints_text": "This change doesn't seem correct to me (for one, it seems like it could break existing sites). Why not include the appropriate prefix in your STATIC_URL and MEDIA_URL settings?\nThis is not a patch. Th",
      "claude_patch": "import posixpath\nfrom urllib.parse import urljoin, urlsplit\n\nfrom django.conf import settings\nfrom django.urls import get_script_prefix\nfrom django.utils.encoding import filepath_to_uri\n\n\ndef get_static_url(path):\n    \"\"\"\n    Return the URL for the given static file path.\n    Prepends SCRIPT_NAME if STATIC_URL is a relative URL.\n    \"\"\"\n    if not path:\n        return ''\n    \n    static_url = settings.STATIC_URL\n    if not static_url:\n        return path\n    \n    # If STATIC_URL is absolute (has scheme or netloc), use it as-is\n    parsed = urlsplit(static_url)\n    if parsed.scheme or parsed.netloc:\n        return urljoin(static_url, path)\n    \n    # For relative URLs, prepend script prefix\n    script_prefix = get_script_prefix()\n    if static_url.startswith('/'):\n        # Ensure we don't double-add the script prefix\n        if not static_url.startswith(script_prefix):\n            static_url = posixpath.join(script_prefix.rstrip('/'), static_url.lstrip('/'))\n    \n    return urljoin(static_url, path)\n\n\ndef get_media_url(path):\n    \"\"\"\n    Return the URL for the given media file path.\n    Prepends SCRIPT_NAME if MEDIA_URL is a relative URL.\n    \"\"\"\n    if not path:\n        return ''\n    \n    media_url = settings.MEDIA_URL\n    if not media_url:\n        return path\n    \n    # If MEDIA_URL is absolute (has scheme or netloc), use it as-is\n    parsed = urlsplit(media_url)\n    if parsed.scheme or parsed.netloc:\n        return urljoin(media_url, path)\n    \n    # For relative URLs, prepend script prefix\n    script_prefix = get_script_prefix()\n    if media_url.startswith('/'):\n        # Ensure we don't double-add the script prefix\n        if not media_url.startswith(script_prefix):\n            media_url = posixpath.join(script_prefix.rstrip('/'), media_url.lstrip('/'))\n    \n    return urljoin(media_url, path)\n\n\n# Patch for django/core/files/storage.py\nfrom django.core.files.storage import FileSystemStorage\n\n\nclass FileSystemStoragePatched(FileSystemStorage):\n    def url(self, name):\n        if self.base_url is None:\n            raise ValueError(\"This file is not accessible via a URL.\")\n        url = filepath_to_uri(name)\n        if url is not None:\n            url = url.lstrip('/')\n        \n        # If base_url is absolute, use it as-is\n        parsed = urlsplit(self.base_url)\n        if parsed.scheme or parsed.netloc:\n            return urljoin(self.base_url, url)\n        \n        # For relative URLs, prepend script prefix\n        base_url = self.base_url\n        script_prefix = get_script_prefix()\n        if base_url.startswith('/'):\n            # Ensure we don't double-add the script prefix\n            if not base_url.startswith(script_prefix):\n                base_url = posixpath.join(script_prefix.rstrip('/'), base_url.lstrip('/'))\n        \n        return urljoin(base_url, url)\n\n\n# Patch for django/contrib/staticfiles/storage.py\nfrom django.contrib.staticfiles.storage import StaticFilesStorage\n\n\nclass StaticFilesStoragePatched(StaticFilesStorage):\n    def url(self, name, force=False):\n        if self.base_url is None:\n            raise ValueError(\"This file is not accessible via a URL.\")\n        url = filepath_to_uri(name)\n        if url is not None:\n            url = url.lstrip('/')\n        \n        # If base_url is absolute, use it as-is\n        parsed = urlsplit(self.base_url)\n        if parsed.scheme or parsed.netloc:\n            return urljoin(self.base_url, url)\n        \n        # For relative URLs, prepend script prefix\n        base_url = self.base_url\n        script_prefix = get_script_prefix()\n        if base_url.startswith('/'):\n            # Ensure we don't double-add the script prefix\n            if not base_url.startswith(script_prefix):\n                base_url = posixpath.join(script_prefix.rstrip('/'), base_url.lstrip('/'))\n        \n        return urljoin(base_url, url)\n\n\n# Patch for django/templatetags/static.py\nfrom django import template\nfrom django.templatetags.static import StaticNode as OriginalStaticNode\n\n\nclass StaticNode(OriginalStaticNode):\n    def url(self, context):\n        path = self.path.resolve(context)\n        return get_static_url(path)\n\n\n# Patch for django/contrib/staticfiles/templatetags/staticfiles.py\nfrom django.contrib.staticfiles.templatetags.staticfiles import StaticFilesNode as OriginalStaticFilesNode\nfrom django.contrib.staticfiles.storage import staticfiles_storage\n\n\nclass StaticFilesNode(OriginalStaticFilesNode):\n    def url(self, context):\n        path = self.path.resolve(context)\n        \n        # Use staticfiles_storage if available\n        if hasattr(staticfiles_storage, 'url'):\n            try:\n                return staticfiles_storage.url(path)\n            except Exception:\n                pass\n        \n        return get_static_url(path)\n\n\n# Update FileSystemStorage.url method\ndef patched_filesystem_storage_url(self, name):\n    if self.base_url is None:\n        raise ValueError(\"This file is not accessible via a URL.\")\n    url = filepath_to_uri(name)\n    if url is not None:\n        url = url.lstrip('/')\n    \n    # If base_url is absolute, use it as-is\n    parsed = urlsplit(self.base_url)\n    if parsed.scheme or parsed.netloc:\n        return urljoin(self.base_url, url)\n    \n    # For relative URLs, prepend script prefix\n    base_url = self.base_url\n    script_prefix = get_script_prefix()\n    if base_url.startswith('/'):\n        # Ensure we don't double-add the script prefix\n        if not base_url.startswith(script_prefix):\n            base_url = posixpath.join(script_prefix.rstrip('/'), base_url.lstrip('/'))\n    \n    return urljoin(base_url, url)\n\n\n# Apply patches\nFileSystemStorage.url = patched_filesystem_storage_url",
      "generation_time": 19.09284496307373,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.0,
      "verification_verdict": "ERROR",
      "issues_found": 1,
      "critical_issues": 1,
      "high_issues": 0,
      "medium_issues": 0,
      "low_issues": 0,
      "agent_scores": {},
      "key_issues": [
        "CRITICAL: system_error - Verification failed: sequence item 1: expected str instance, NoneType found"
      ],
      "verification_time": 0.2012619972229004,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11583",
      "repo": "django/django",
      "problem_statement": "Auto-reloading with StatReloader very intermittently throws \"ValueError: embedded null byte\".\nDescription\n\t\nRaising this mainly so that it's tracked, as I have no idea how to reproduce it, nor why it's happening. It ultimately looks like a problem with Pathlib, which wasn't used prior to 2.2.\nStacktrace:\nTraceback (most recent call last):\n File \"manage.py\" ...\n\texecute_from_command_line(sys.argv)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/core/management/__init__.py\", line",
      "hints_text": "Thanks for the report, however as you've admitted there is too many unknowns to accept this ticket. I don't believe that it is related with pathlib, maybe samba connection is unstable it's hard to tel",
      "claude_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 1234567890..abcdefghij 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -129,7 +129,11 @@ def iter_modules_and_files(modules, extra_files):\n             # during iteration.\n             for path in list(sys_file_paths):\n                 if path.exists():\n-                    results.add(path.resolve().absolute())\n+                    try:\n+                        results.add(path.resolve().absolute())\n+                    except ValueError:\n+                        # Ignore paths that contain null bytes or other invalid data\n+                        results.add(path.absolute())\n     return frozenset(results)",
      "generation_time": 20.74847984313965,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.041674137115478516,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11620",
      "repo": "django/django",
      "problem_statement": "When DEBUG is True, raising Http404 in a path converter's to_python method does not result in a technical response\nDescription\n\t\nThis is the response I get (plain text): \nA server error occurred. Please contact the administrator.\nI understand a ValueError should be raised which tells the URL resolver \"this path does not match, try next one\" but Http404 is what came to my mind intuitively and the error message was not very helpful.\nOne could also make a point that raising a Http404 should be vali",
      "hints_text": "It seems that other exceptions correctly result in a technical 500 response.\nThe technical_404_response view performs a new URL resolving (cf \u200bhttps://github.com/django/django/blob/a8e492bc81fca829f5d",
      "claude_patch": "# django/views/debug.py\n\nfrom django.http import Http404, HttpResponse, HttpResponseNotFound\nfrom django.urls import Resolver404\nfrom django.template import Context, Engine, TemplateDoesNotExist\nfrom django.template.defaultfilters import pprint\nfrom django.utils.html import escape\nfrom django.utils.version import get_docs_version\n\ndef technical_404_response(request, exception):\n    \"\"\"Create a technical 404 error response. `exception` is the Http404.\"\"\"\n    try:\n        error_url = exception.args[0]['path']\n    except (IndexError, TypeError, KeyError):\n        error_url = request.path_info[1:]  # Trim leading slash\n\n    try:\n        tried = exception.args[0]['tried']\n    except (IndexError, TypeError, KeyError):\n        tried = []\n\n    try:\n        # Resolve the URL again to get the URLconf and tried patterns\n        from django.urls import get_resolver\n        resolver = get_resolver()\n        resolver.resolve(error_url)\n    except Http404:\n        # If Http404 is raised during resolution (e.g., from a path converter),\n        # we still want to show the technical 404 page\n        pass\n    except Resolver404:\n        pass\n\n    # Get the URLconf that was used\n    from django.urls import get_urlconf\n    urlconf = get_urlconf()\n\n    if not urlconf:\n        # This should only happen if something is seriously wrong\n        from django.conf import settings\n        urlconf = settings.ROOT_URLCONF\n\n    # Load the template\n    t = Engine.get_default().from_string(TECHNICAL_404_TEMPLATE)\n    reporter_filter = get_default_exception_reporter_filter()\n    c = Context({\n        'urlconf': urlconf,\n        'root_urlconf': urlconf,\n        'request_path': error_url,\n        'urlpatterns': tried,\n        'reason': str(exception),\n        'request': request,\n        'settings': reporter_filter.get_safe_settings(),\n        'raising_view_name': get_caller(request),\n    })\n    return HttpResponseNotFound(t.render(c), content_type='text/html')",
      "generation_time": 16.280475854873657,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 13,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 2,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.6399999999999999,
        "style": 0.868,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: contract_violation - Function 'technical_404_response' docstring mentions exceptions but none are raised"
      ],
      "verification_time": 0.1869359016418457,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11630",
      "repo": "django/django",
      "problem_statement": "Django throws error when different apps with different models have the same name table name.\nDescription\n\t\nError message:\ntable_name: (models.E028) db_table 'table_name' is used by multiple models: base.ModelName, app2.ModelName.\nWe have a Base app that points to a central database and that has its own tables. We then have multiple Apps that talk to their own databases. Some share the same table names.\nWe have used this setup for a while, but after upgrading to Django 2.2 we're getting an error ",
      "hints_text": "Regression in [5d25804eaf81795c7d457e5a2a9f0b9b0989136c], ticket #20098. My opinion is that as soon as the project has a non-empty DATABASE_ROUTERS setting, the error should be turned into a warning, ",
      "claude_patch": "from django.core.checks import Warning, Error\nfrom django.conf import settings\n\ndef _check_db_table_collision(self, databases):\n    errors = []\n    if not databases:\n        return errors\n\n    # Get all models\n    from django.apps import apps\n    all_models = apps.get_models(include_auto_created=True)\n    \n    # Group models by db_table\n    db_tables = {}\n    for model in all_models:\n        db_table = model._meta.db_table\n        if db_table not in db_tables:\n            db_tables[db_table] = []\n        db_tables[db_table].append(model)\n    \n    # Check for collisions\n    for db_table, models in db_tables.items():\n        if len(models) > 1:\n            model_labels = ', '.join(\n                model._meta.label for model in models\n            )\n            # Use Warning instead of Error if DATABASE_ROUTERS is configured\n            if getattr(settings, 'DATABASE_ROUTERS', None):\n                errors.append(\n                    Warning(\n                        \"db_table '%s' is used by multiple models: %s.\" % (db_table, model_labels),\n                        hint=(\n                            'You have configured DATABASE_ROUTERS. Ensure that your '\n                            'database routers are correctly routing these models to '\n                            'different databases. You can silence this warning by adding '\n                            'it to SILENCED_SYSTEM_CHECKS.'\n                        ),\n                        obj=db_table,\n                        id='models.W028',\n                    )\n                )\n            else:\n                errors.append(\n                    Error(\n                        \"db_table '%s' is used by multiple models: %s.\" % (db_table, model_labels),\n                        obj=db_table,\n                        id='models.E028',\n                    )\n                )\n    \n    return errors",
      "generation_time": 8.688374996185303,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 11,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 3,
      "low_issues": 7,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8766666666666667,
        "style": 0.6764304792996556,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.10916018486022949,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-11742",
      "repo": "django/django",
      "problem_statement": "Add check to ensure max_length fits longest choice.\nDescription\n\t\nThere is currently no check to ensure that Field.max_length is large enough to fit the longest value in Field.choices.\nThis would be very helpful as often this mistake is not noticed until an attempt is made to save a record with those values that are too long.\n",
      "hints_text": null,
      "claude_patch": "from django.core import checks\nfrom django.db import models\n\n\ndef _check_max_length_with_choices(field):\n    \"\"\"\n    Check that max_length is sufficient for the longest choice value.\n    \"\"\"\n    if not hasattr(field, 'max_length') or field.max_length is None:\n        return []\n    \n    if not field.choices:\n        return []\n    \n    # Get all choice values, handling both flat and grouped choices\n    choice_values = []\n    for choice in field.choices:\n        if isinstance(choice, (list, tuple)) and len(choice) == 2:\n            # Could be a grouped choice or a regular choice\n            if isinstance(choice[1], (list, tuple)):\n                # Grouped choice: (group_name, [(value, label), ...])\n                for sub_choice in choice[1]:\n                    if isinstance(sub_choice, (list, tuple)) and len(sub_choice) >= 1:\n                        choice_values.append(sub_choice[0])\n            else:\n                # Regular choice: (value, label)\n                choice_values.append(choice[0])\n    \n    if not choice_values:\n        return []\n    \n    # Find the longest choice value\n    max_choice_length = 0\n    longest_value = None\n    for value in choice_values:\n        if value is None:\n            continue\n        # Convert to string as that's how it will be stored\n        str_value = str(value)\n        value_length = len(str_value)\n        if value_length > max_choice_length:\n            max_choice_length = value_length\n            longest_value = str_value\n    \n    if max_choice_length > field.max_length:\n        return [\n            checks.Error(\n                \"'max_length' is too small to fit the longest choice.\",\n                hint=(\n                    f\"The longest choice value is {max_choice_length} characters, \"\n                    f\"but 'max_length' is only {field.max_length}. \"\n                    f\"Increase 'max_length' to at least {max_choice_length}.\"\n                ),\n                obj=field,\n                id='fields.E009',\n            )\n        ]\n    \n    return []\n\n\n# Patch CharField._check_max_length_attribute to include the choices check\noriginal_check_max_length_attribute = models.CharField._check_max_length_attribute\n\ndef patched_check_max_length_attribute(self):\n    errors = original_check_max_length_attribute(self)\n    errors.extend(_check_max_length_with_choices(self))\n    return errors\n\nmodels.CharField._check_max_length_attribute = patched_check_max_length_attribute",
      "generation_time": 10.895648956298828,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 19,
      "critical_issues": 0,
      "high_issues": 8,
      "medium_issues": 5,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.56,
        "performance": 0.967
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: ast_analysis - Function '_check_max_length_with_choices' too long (54 lines) - production maintainability concern",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.13026094436645508,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11797",
      "repo": "django/django",
      "problem_statement": "Filtering on query result overrides GROUP BY of internal query\nDescription\n\t\nfrom django.contrib.auth import models\na = models.User.objects.filter(email__isnull=True).values('email').annotate(m=Max('id')).values('m')\nprint(a.query) # good\n# SELECT MAX(\"auth_user\".\"id\") AS \"m\" FROM \"auth_user\" WHERE \"auth_user\".\"email\" IS NULL GROUP BY \"auth_user\".\"email\"\nprint(a[:1].query) # good\n# SELECT MAX(\"auth_user\".\"id\") AS \"m\" FROM \"auth_user\" WHERE \"auth_user\".\"email\" IS NULL GROUP BY \"auth_user\".\"email\"",
      "hints_text": "Workaround: from django.contrib.auth import models a = models.User.objects.filter(email__isnull=True).values('email').aggregate(Max('id'))['id_max'] b = models.User.objects.filter(id=a)\nThanks for tac",
      "claude_patch": "from django.db.models.lookups import Exact\n\n# Store the original process_rhs method\n_original_exact_process_rhs = Exact.process_rhs\n\ndef patched_exact_process_rhs(self):\n    \"\"\"\n    Process the right-hand side of an Exact lookup.\n    \n    Only clear select clause and add pk field if the RHS query\n    doesn't already have selected fields (similar to In.process_rhs).\n    \"\"\"\n    if hasattr(self.rhs, 'resolve_expression'):\n        # Get the query object if it exists\n        query_obj = getattr(self.rhs, 'query', None)\n        if query_obj is not None:\n            # Check if the query already has selected fields\n            # If it does, don't override them with pk\n            if not getattr(self.rhs, 'has_select_fields', True):\n                # Original behavior: clear and add pk\n                return _original_exact_process_rhs(self)\n            else:\n                # Query already has selected fields, don't modify them\n                # Just resolve the expression without clearing select clause\n                from django.db.models.sql.query import Query\n                if isinstance(query_obj, Query):\n                    # Don't call clear_select_clause or add_fields\n                    # Just return the processed RHS as-is\n                    pass\n    \n    # For queries with selected fields, skip the clear_select_clause and add_fields\n    if not getattr(self.rhs, 'has_select_fields', True):\n        return _original_exact_process_rhs(self)\n    \n    # Process RHS without modifying the select clause\n    from django.db.models.expressions import Subquery\n    if hasattr(self.rhs, '_iterable_class'):\n        # This is a QuerySet, convert to subquery without modifying fields\n        return self.rhs, ()\n    \n    return _original_exact_process_rhs(self)\n\n# Apply the patch\nExact.process_rhs = patched_exact_process_rhs",
      "generation_time": 15.440067052841187,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 8,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 0,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.7166666666666666,
        "style": 0.8644460665510887,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: logic - Low logic score: 0.60",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path",
        "HIGH: loop_nesting - Extreme loop nesting: 4 levels"
      ],
      "verification_time": 0.13013291358947754,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11815",
      "repo": "django/django",
      "problem_statement": "Migrations uses value of enum object instead of its name.\nDescription\n\t \n\t\t(last modified by oasl)\n\t \nWhen using Enum object as a default value for a CharField, the generated migration file uses the value of the Enum object instead of the its name. This causes a problem when using Django translation on the value of the Enum object. \nThe problem is that, when the Enum object value get translated to the users language, the old migration files raise an error stating that the Enum does not have the ",
      "hints_text": "Thanks for this report, however I'm not sure how translated values can brake migrations. Can you provide a sample project to reproduce this issue? Migrations with translatable strings works fine for m",
      "claude_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..b00c6f0df2 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,9 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n+        _, v_imports = serializer_factory(self.value.value).serialize()\n         imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        return \"%s.%s[%r]\" % (module, enum_class.__name__, self.value.name), imports\n \n \n class FloatSerializer(BaseSerializer):",
      "generation_time": 4.418089866638184,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid decimal literal (<unknown>, line 2)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.03856492042541504,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11848",
      "repo": "django/django",
      "problem_statement": "django.utils.http.parse_http_date two digit year check is incorrect\nDescription\n\t \n\t\t(last modified by Ad Timmering)\n\t \nRFC 850 does not mention this, but in RFC 7231 (and there's something similar in RFC 2822), there's the following quote:\nRecipients of a timestamp value in rfc850-date format, which uses a\ntwo-digit year, MUST interpret a timestamp that appears to be more\nthan 50 years in the future as representing the most recent year in\nthe past that had the same last two digits.\nCurrent logi",
      "hints_text": "Accepted, however I don't think your patch is correct. The check should be relative to the current year, if I read the RFC quote correctly.\nCreated a pull request: Created a pull request: \u200bhttps://git",
      "claude_patch": "import datetime\nfrom django.utils.http import parse_http_date\n\n# Patch for django/utils/http.py parse_http_date function\n\ndef parse_http_date(date):\n    \"\"\"\n    Parse a date format as specified by HTTP RFC7231 section 7.1.1.1.\n\n    The three formats allowed by the RFC are accepted, even if only the first\n    one is still in widespread use.\n\n    Return an integer expressed in seconds since the epoch, in UTC.\n    \"\"\"\n    # email.utils.parsedate() does the job for RFC1123 dates; unfortunately\n    # RFC7231 makes it mandatory to support RFC850 dates too. So we roll\n    # our own RFC-compliant parsing.\n    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:\n        m = regex.match(date)\n        if m is not None:\n            break\n    else:\n        raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n    try:\n        tz = datetime.timezone.utc\n        year = int(m.group('year'))\n        if year < 100:\n            # According to RFC 7231, recipients of a timestamp value in\n            # rfc850-date format (two-digit year) must interpret a timestamp\n            # that appears to be more than 50 years in the future as\n            # representing the most recent year in the past that had the same\n            # last two digits.\n            current_year = datetime.datetime.now(tz=tz).year\n            current_century = current_year - (current_year % 100)\n            \n            # Construct the full year using current century\n            full_year = current_century + year\n            \n            # If this year is more than 50 years in the future, roll back 100 years\n            if full_year - current_year > 50:\n                full_year -= 100\n            \n            year = full_year\n        month = MONTHS.index(m.group('mon').lower()) + 1\n        day = int(m.group('day'))\n        hour = int(m.group('hour'))\n        min = int(m.group('min'))\n        sec = int(m.group('sec'))\n        result = datetime.datetime(year, month, day, hour, min, sec, tzinfo=tz)\n        return int(result.timestamp())\n    except Exception as exc:\n        raise ValueError(\"%r is not a valid date\" % date) from exc",
      "generation_time": 12.197566032409668,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 2,
      "low_issues": 5,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 1.0,
        "style": 0.8200000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.07587194442749023,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-11905",
      "repo": "django/django",
      "problem_statement": "Prevent using __isnull lookup with non-boolean value.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \n__isnull should not allow for non-boolean values. Using truthy/falsey doesn't promote INNER JOIN to an OUTER JOIN but works fine for a simple queries. Using non-boolean values is \u200bundocumented and untested. IMO we should raise an error for non-boolean values to avoid confusion and for consistency.\n",
      "hints_text": "PR here: \u200bhttps://github.com/django/django/pull/11873\nAfter the reconsideration I don't think that we should change this \u200bdocumented behavior (that is in Django from the very beginning). __isnull look",
      "claude_patch": "import warnings\nfrom django.db.models.lookups import BuiltinLookup\nfrom django.utils.deprecation import RemovedInDjango40Warning\n\n\nclass IsNull(BuiltinLookup):\n    lookup_name = 'isnull'\n    prepare_rhs = False\n\n    def as_sql(self, compiler, connection):\n        # Check if rhs is a boolean value\n        if not isinstance(self.rhs, bool):\n            warnings.warn(\n                'Using non-boolean values for the __isnull lookup is deprecated. '\n                'Use True or False instead.',\n                RemovedInDjango40Warning,\n                stacklevel=2,\n            )\n        \n        sql, params = compiler.compile(self.lhs)\n        if self.rhs:\n            return \"%s IS NULL\" % sql, params\n        else:\n            return \"%s IS NOT NULL\" % sql, params",
      "generation_time": 4.46682596206665,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 2,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.785583060661102,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.16338419914245605,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-11910",
      "repo": "django/django",
      "problem_statement": "ForeignKey's to_field parameter gets the old field's name when renaming a PrimaryKey.\nDescription\n\t\nHaving these two models \nclass ModelA(models.Model):\n\tfield_wrong = models.CharField('field1', max_length=50, primary_key=True) # I'm a Primary key.\nclass ModelB(models.Model):\n\tfield_fk = models.ForeignKey(ModelA, blank=True, null=True, on_delete=models.CASCADE) \n... migrations applyed ...\nthe ModelA.field_wrong field has been renamed ... and Django recognizes the \"renaming\"\n# Primary key renamed",
      "hints_text": "Thanks for this ticket. It looks like a regression in dcdd219ee1e062dc6189f382e0298e0adf5d5ddf, because an AlterField operation wasn't generated in such cases before this change (and I don't think we ",
      "claude_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 1234567890..abcdefghij 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -1089,6 +1089,23 @@ class MigrationAutodetector:\n                         dependencies=dependencies,\n                     )\n                 )\n+                # Check if this is a ForeignKey pointing to a renamed primary key\n+                # If so, we should not generate an AlterField operation since\n+                # RenameField will handle the reference update\n+                if old_field.remote_field and hasattr(old_field.remote_field, 'model'):\n+                    remote_model = old_field.remote_field.model\n+                    if isinstance(remote_model, str):\n+                        remote_model_key = self.resolve_model_key(remote_model, app_label)\n+                    else:\n+                        remote_model_key = (remote_model._meta.app_label, remote_model._meta.model_name)\n+                    \n+                    to_field_name = old_field.remote_field.field_name\n+                    if to_field_name and remote_model_key:\n+                        # Check if the to_field was renamed\n+                        renamed_fields = self.renamed_fields.get(remote_model_key, {})\n+                        if to_field_name in renamed_fields.values():\n+                            # Skip this AlterField as RenameField will handle it\n+                            continue\n \n     def create_altered_indexes(self):\n         option_name = operations.AddIndex.option_name",
      "generation_time": 27.681917190551758,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.048561811447143555,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11964",
      "repo": "django/django",
      "problem_statement": "The value of a TextChoices/IntegerChoices field has a differing type\nDescription\n\t\nIf we create an instance of a model having a CharField or IntegerField with the keyword choices pointing to IntegerChoices or TextChoices, the value returned by the getter of the field will be of the same type as the one created by enum.Enum (enum value).\nFor example, this model:\nfrom django.db import models\nfrom django.utils.translation import gettext_lazy as _\nclass MyChoice(models.TextChoices):\n\tFIRST_CHOICE = ",
      "hints_text": "Hi NyanKiyoshi, what a lovely report. Thank you. Clearly :) the expected behaviour is that test_created_object_is_str should pass. It's interesting that the underlying __dict__ values differ, which ex",
      "claude_patch": "# django/db/models/fields/__init__.py\n\n# Find the Field class and update the to_python method or add conversion in __set__\n# The issue is in how CharField and IntegerField handle enum values\n\n# Patch for CharField\nfrom django.db.models.fields import CharField\n\n_original_charfield_get_prep_value = CharField.get_prep_value\n\ndef _patched_charfield_get_prep_value(self, value):\n    # Convert enum members to their values\n    if value is not None and hasattr(value, 'value') and hasattr(value, '__class__'):\n        # Check if it's an enum member\n        try:\n            import enum\n            if isinstance(value, enum.Enum):\n                value = value.value\n        except ImportError:\n            pass\n    return _original_charfield_get_prep_value(self, value)\n\nCharField.get_prep_value = _patched_charfield_get_prep_value\n\n\n# Patch for IntegerField\nfrom django.db.models.fields import IntegerField\n\n_original_integerfield_get_prep_value = IntegerField.get_prep_value\n\ndef _patched_integerfield_get_prep_value(self, value):\n    # Convert enum members to their values\n    if value is not None and hasattr(value, 'value') and hasattr(value, '__class__'):\n        # Check if it's an enum member\n        try:\n            import enum\n            if isinstance(value, enum.Enum):\n                value = value.value\n        except ImportError:\n            pass\n    return _original_integerfield_get_prep_value(self, value)\n\nIntegerField.get_prep_value = _patched_integerfield_get_prep_value",
      "generation_time": 16.340643167495728,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 14,
      "critical_issues": 0,
      "high_issues": 5,
      "medium_issues": 3,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.5566666666666666,
        "style": 0.6044422951406981,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: ast_analysis - Empty exception handler - production systems need error logging"
      ],
      "verification_time": 0.17558002471923828,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11999",
      "repo": "django/django",
      "problem_statement": "Cannot override get_FOO_display() in Django 2.2+.\nDescription\n\t\nI cannot override the get_FIELD_display function on models since version 2.2. It works in version 2.1.\nExample:\nclass FooBar(models.Model):\n\tfoo_bar = models.CharField(_(\"foo\"), choices=[(1, 'foo'), (2, 'bar')])\n\tdef __str__(self):\n\t\treturn self.get_foo_bar_display() # This returns 'foo' or 'bar' in 2.2, but 'something' in 2.1\n\tdef get_foo_bar_display(self):\n\t\treturn \"something\"\nWhat I expect is that I should be able to override thi",
      "hints_text": "Thanks for this report. Regression in a68ea231012434b522ce45c513d84add516afa60. Reproduced at 54a7b021125d23a248e70ba17bf8b10bc8619234.\nOK, I have a lead on this. Not at all happy about how it looks a",
      "claude_patch": "# In django/db/models/fields/__init__.py, modify the Field.contribute_to_class method\n\ndef contribute_to_class(self, cls, name, private_only=False):\n    \"\"\"\n    Register the field with the model class it belongs to.\n\n    If private_only is True, create a separate instance of this field\n    for every subclass of cls, even if cls is not an abstract model.\n    \"\"\"\n    self.set_attributes_from_name(name)\n    self.model = cls\n    if private_only:\n        cls._meta.add_field(self, private=True)\n    else:\n        cls._meta.add_field(self)\n    if self.column:\n        # Don't override a get_FOO_display() method defined explicitly on\n        # this class, but don't check methods derived from inheritance, to\n        # allow overriding inherited choices.\n        if self.choices is not None:\n            display_method_name = 'get_%s_display' % self.name\n            if not hasattr(cls, display_method_name) or display_method_name not in cls.__dict__:\n                setattr(\n                    cls,\n                    display_method_name,\n                    partialmethod(cls._get_FIELD_display, field=self),\n                )",
      "generation_time": 12.158276081085205,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 6,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 1,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.9400900980183242,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.04597592353820801,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12113",
      "repo": "django/django",
      "problem_statement": "admin_views.test_multidb fails with persistent test SQLite database.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nI've tried using persistent SQLite databases for the tests (to make use of\n--keepdb), but at least some test fails with:\nsqlite3.OperationalError: database is locked\nThis is not an issue when only using TEST[\"NAME\"] with \"default\" (which is good enough in terms of performance).\ndiff --git i/tests/test_sqlite.py w/tests/test_sqlite.py\nindex f1b65f7d01..9ce4e32e14 100644\n---",
      "hints_text": "This is only an issue when setting TEST[\"NAME\"], but not NAME. The following works: DATABASES = { 'default': { 'ENGINE': 'django.db.backends.sqlite3', 'NAME': 'django_tests_default.sqlite3', }, 'other",
      "claude_patch": "# django/db/backends/sqlite3/creation.py\n\ndef test_db_signature(self):\n    \"\"\"\n    Return a tuple that uniquely identifies a test database.\n\n    This takes into account the special memory test database name.\n    \"\"\"\n    test_database_name = self._get_test_db_name()\n    sig = [self.connection.settings_dict['NAME']]\n    if test_database_name != ':memory:':\n        sig.append(test_database_name)\n    return tuple(sig)",
      "generation_time": 16.585742712020874,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 8,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 2,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.7933333333333333,
        "style": 0.974,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%"
      ],
      "verification_time": 0.0503690242767334,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12125",
      "repo": "django/django",
      "problem_statement": "makemigrations produces incorrect path for inner classes\nDescription\n\t\nWhen you define a subclass from django.db.models.Field as an inner class of some other class, and use this field inside a django.db.models.Model class, then when you run manage.py makemigrations, a migrations file is created which refers to the inner class as if it were a top-level class of the module it is in.\nTo reproduce, create the following as your model:\nclass Outer(object):\n\tclass Inner(models.CharField):\n\t\tpass\nclass ",
      "hints_text": "This should be possible to do by relying on __qualname__ (instead of __name__) now that master is Python 3 only.\n\u200bPR\nI think we should focus on using __qualname__ during migration serialization as wel",
      "claude_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -263,7 +263,10 @@ class TypeSerializer(BaseSerializer):\n         return cls(value)\n \n     def serialize(self):\n-        special_cases = [\n+        # Use __qualname__ for proper nested class support (e.g. Outer.Inner)\n+        # Fall back to __name__ if __qualname__ is not available\n+        attr_name = getattr(self.value, '__qualname__', self.value.__name__)\n+        special_cases = [\n             (models.Model, \"models.Model\", []),\n             (type(None), 'type(None)', []),\n         ]\n@@ -271,7 +274,7 @@ class TypeSerializer(BaseSerializer):\n             if case is self.value:\n                 return string, set(imports)\n         if hasattr(self.value, \"__module__\"):\n-            module = self.value.__module__\n+            module = self.value.__module__\n             if module == builtins.__name__:\n-                return self.value.__name__, set()\n+                return attr_name, set()\n             else:\n-                return \"%s.%s\" % (module, self.value.__name__), {\"import %s\" % module}\n+                return \"%s.%s\" % (module, attr_name), {\"import %s\" % module}",
      "generation_time": 7.816658973693848,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.040441036224365234,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12184",
      "repo": "django/django",
      "problem_statement": "Optional URL params crash some view functions.\nDescription\n\t\nMy use case, running fine with Django until 2.2:\nURLConf:\nurlpatterns += [\n\t...\n\tre_path(r'^module/(?P<format>(html|json|xml))?/?$', views.modules, name='modules'),\n]\nView:\ndef modules(request, format='html'):\n\t...\n\treturn render(...)\nWith Django 3.0, this is now producing an error:\nTraceback (most recent call last):\n File \"/l10n/venv/lib/python3.6/site-packages/django/core/handlers/exception.py\", line 34, in inner\n\tresponse = get_resp",
      "hints_text": "Tracked regression in 76b993a117b61c41584e95149a67d8a1e9f49dd1.\nIt seems to work if you remove the extra parentheses: re_path(r'^module/(?P<format>html|json|xml)?/?$', views.modules, name='modules'), ",
      "claude_patch": "# django/urls/resolvers.py\n\nimport re\nfrom django.urls.resolvers import RoutePattern, RegexPattern\n\n\n# Patch for RegexPattern class\noriginal_regex_pattern_init = RegexPattern.__init__\n\ndef patched_regex_pattern_init(self, regex, name=None, is_endpoint=False):\n    original_regex_pattern_init(self, regex, name, is_endpoint)\n    # Override the regex property to filter out unnamed groups\n    self._original_regex = self._regex\n    self._filtered_regex_string = self._filter_unnamed_groups(self._regex_string)\n    \ndef _filter_unnamed_groups(self, pattern):\n    \"\"\"Convert unnamed groups to non-capturing groups.\"\"\"\n    # This regex finds groups that are not named (?P<name>...) and not already non-capturing (?:...)\n    # We need to be careful to only convert capturing groups that are not named\n    result = []\n    i = 0\n    while i < len(pattern):\n        if pattern[i:i+2] == '(?':\n            if pattern[i:i+3] == '(?P':\n                # Named group - keep as is\n                result.append(pattern[i])\n                i += 1\n            elif pattern[i:i+3] == '(?:':\n                # Non-capturing group - keep as is\n                result.append(pattern[i])\n                i += 1\n            else:\n                # Unnamed capturing group - convert to non-capturing\n                result.append('(?:')\n                i += 2\n        else:\n            result.append(pattern[i])\n            i += 1\n    return ''.join(result)\n\nRegexPattern._filter_unnamed_groups = _filter_unnamed_groups\n\n\n# Better approach: Fix in the match method\noriginal_match = RegexPattern.match\n\ndef patched_match(self, path):\n    match = self.regex.search(path)\n    if match:\n        # Extract only named groups for kwargs\n        kwargs = {}\n        for key, value in match.groupdict().items():\n            if value is not None:\n                kwargs[key] = value\n        # Don't include positional args from unnamed groups\n        args = ()\n        return path[match.end():], args, kwargs\n    return None\n\nRegexPattern.match = patched_match",
      "generation_time": 22.76774501800537,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 15,
      "critical_issues": 0,
      "high_issues": 5,
      "medium_issues": 4,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.44666666666666655,
        "style": 0.68,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 33.3%",
        "HIGH: ast_analysis - Public function 'patched_regex_pattern_init' missing docstring - production documentation required",
        "HIGH: edge_case_coverage - Low edge case coverage: 66.7%"
      ],
      "verification_time": 0.1831519603729248,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12284",
      "repo": "django/django",
      "problem_statement": "Model.get_FOO_display() does not work correctly with inherited choices.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nGiven a base model with choices A containing 3 tuples\nChild Model inherits the base model overrides the choices A and adds 2 more tuples\nget_foo_display does not work correctly for the new tuples added\nExample:\nclass A(models.Model):\n foo_choice = [(\"A\",\"output1\"),(\"B\",\"output2\")]\n field_foo = models.CharField(max_length=254,choices=foo_choice)\n class Meta:\n\t abstract =",
      "hints_text": "Thanks for this report. Can you provide models and describe expected behavior? Can you also check if it's not a duplicate of #30931?, that was fixed in Django 2.2.7.\nReplying to felixxm: Thanks for th",
      "claude_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -763,8 +763,12 @@ class Field(RegisterLookupMixin):\n         self.model = cls\n         if private_only:\n             cls._meta.add_field(self, private=True)\n         else:\n             cls._meta.add_field(self)\n         if self.choices is not None:\n-            if not hasattr(cls, 'get_%s_display' % self.name):\n+            # Only set get_FOO_display if it's not defined in the current class\n+            # (not inherited). This allows proper inheritance of choices.\n+            if 'get_%s_display' % self.name not in cls.__dict__:\n                 setattr(\n                     cls,\n                     'get_%s_display' % self.name,",
      "generation_time": 5.330243110656738,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04292011260986328,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12286",
      "repo": "django/django",
      "problem_statement": "translation.E004 shouldn't be raised on sublanguages when a base language is available.\nDescription\n\t\nAccording to Django documentation:\nIf a base language is available but the sublanguage specified is not, Django uses the base language. For example, if a user specifies de-at (Austrian German) but Django only has de available, Django uses de.\nHowever, when using Django 3.0.2, if my settings.py has\nLANGUAGE_CODE = \"de-at\"\nI get this error message:\nSystemCheckError: System check identified some is",
      "hints_text": "Thanks for this report. Regression in 4400d8296d268f5a8523cd02ddc33b12219b2535.",
      "claude_patch": "# django/core/checks/translation.py\n\nfrom django.conf import settings\nfrom django.utils.translation import LANGUAGE_SESSION_KEY, get_supported_language_variant\n\nfrom . import Error, Tags, register\n\n\n@register(Tags.translation)\ndef check_setting_language_code(app_configs, **kwargs):\n    \"\"\"Error if LANGUAGE_CODE setting is invalid.\"\"\"\n    tag = settings.LANGUAGE_CODE\n    if not isinstance(tag, str) or not tag:\n        return [\n            Error(\n                'You have provided an invalid value for the LANGUAGE_CODE setting: {!r}.'.format(tag),\n                id='translation.E001',\n            ),\n        ]\n    \n    # Check if the language code or its base language is available\n    try:\n        get_supported_language_variant(tag)\n    except LookupError:\n        return [\n            Error(\n                'You have provided a value for the LANGUAGE_CODE setting that is not in '\n                'the LANGUAGES setting.',\n                id='translation.E004',\n            ),\n        ]\n    \n    return []\n\n\n@register(Tags.translation)\ndef check_setting_languages(app_configs, **kwargs):\n    \"\"\"Error if LANGUAGES setting is invalid.\"\"\"\n    return [\n        Error(\n            'You have provided an invalid value for the LANGUAGES setting: {!r}.'.format(settings.LANGUAGES),\n            id='translation.E002',\n        )\n    ] if not isinstance(settings.LANGUAGES, (list, tuple)) else []\n\n\n@register(Tags.translation)\ndef check_setting_languages_bidi(app_configs, **kwargs):\n    \"\"\"Error if LANGUAGES_BIDI setting is invalid.\"\"\"\n    return [\n        Error(\n            'You have provided an invalid value for the LANGUAGES_BIDI setting: {!r}.'.format(settings.LANGUAGES_BIDI),\n            id='translation.E003',\n        )\n    ] if not isinstance(settings.LANGUAGES_BIDI, (list, tuple)) else []\n\n\n@register(Tags.translation)\ndef check_language_settings_consistent(app_configs, **kwargs):\n    \"\"\"Error if language settings are not consistent with each other.\"\"\"\n    available_tags = {tag for tag, _ in settings.LANGUAGES} | {'en-us'}\n    if settings.LANGUAGE_CODE not in available_tags:\n        # Check if base language is available\n        language_code = settings.LANGUAGE_CODE\n        base_language = language_code.split('-')[0].lower()\n        \n        # Check if any language with this base exists\n        has_base_language = any(\n            tag.split('-')[0].lower() == base_language\n            for tag in available_tags\n        )\n        \n        if not has_base_language:\n            return [\n                Error(\n                    'You have provided a value for the LANGUAGE_CODE setting that is not in '\n                    'the LANGUAGES setting.',\n                    id='translation.E004',\n                ),\n            ]\n    return []",
      "generation_time": 10.992879867553711,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 15,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 7,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.45,
        "style": 0.78,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path",
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.10839700698852539,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12308",
      "repo": "django/django",
      "problem_statement": "JSONField are not properly displayed in admin when they are readonly.\nDescription\n\t\nJSONField values are displayed as dict when readonly in the admin.\nFor example, {\"foo\": \"bar\"} would be displayed as {'foo': 'bar'}, which is not valid JSON.\nI believe the fix would be to add a special case in django.contrib.admin.utils.display_for_field to call the prepare_value of the JSONField (not calling json.dumps directly to take care of the InvalidJSONInput case).\n",
      "hints_text": "\u200bPR\nThe proposed patch is problematic as the first version coupled contrib.postgres with .admin and the current one is based off the type name which is brittle and doesn't account for inheritance. It ",
      "claude_patch": "import json\nfrom django.contrib.admin.utils import display_for_field\nfrom django.core.serializers.json import DjangoJSONEncoder\nfrom django.db import models\n\n# Patch for django/contrib/admin/utils.py\n\ndef display_for_field(value, field, empty_value_display):\n    from django.contrib.admin.templatetags.admin_list import _boolean_icon\n    from django.contrib.admin.utils import lookup_field\n    from django.db import models\n    from django.utils.html import format_html\n    from django.utils.safestring import mark_safe\n    import json\n    from django.core.serializers.json import DjangoJSONEncoder\n\n    if getattr(field, 'flatchoices', None):\n        return dict(field.flatchoices).get(value, empty_value_display)\n    # BooleanField needs special-case null-handling, so it comes before the\n    # general null test.\n    elif isinstance(field, models.BooleanField):\n        return _boolean_icon(value)\n    elif value is None:\n        return empty_value_display\n    elif isinstance(field, models.DateTimeField):\n        return formats.localize(timezone.template_localtime(value))\n    elif isinstance(field, (models.DateField, models.TimeField)):\n        return formats.localize(value)\n    elif isinstance(field, models.DecimalField):\n        return formats.number_format(value, field.decimal_places)\n    elif isinstance(field, (models.IntegerField, models.FloatField)):\n        return formats.number_format(value)\n    elif isinstance(field, models.FileField) and value:\n        return format_html('<a href=\"{}\">{}</a>', value.url, value)\n    elif isinstance(field, models.JSONField):\n        try:\n            # Use the field's encoder if available\n            encoder = getattr(field, 'encoder', DjangoJSONEncoder)\n            return json.dumps(value, ensure_ascii=False, cls=encoder)\n        except (TypeError, ValueError):\n            return value\n    else:\n        return display_for_value(value, empty_value_display)",
      "generation_time": 16.093302011489868,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 2,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.7221631061577262,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: ast_analysis - Public function 'display_for_field' missing docstring - production documentation required",
        "HIGH: loop_nesting - Extreme loop nesting: 10 levels"
      ],
      "verification_time": 0.20811724662780762,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12453",
      "repo": "django/django",
      "problem_statement": "`TransactionTestCase.serialized_rollback` fails to restore objects due to ordering constraints\nDescription\n\t\nI hit this problem in a fairly complex projet and haven't had the time to write a minimal reproduction case. I think it can be understood just by inspecting the code so I'm going to describe it while I have it in mind.\nSetting serialized_rollback = True on a TransactionTestCase triggers \u200brollback emulation. In practice, for each database:\nBaseDatabaseCreation.create_test_db calls connecti",
      "hints_text": "I've run into a problem related to this one (just reported as #31051), so I ended up looking into this problem as well. The original report still seems accurate to me, with the proposed solution valid",
      "claude_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex bca8376..8e5c9a5 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -4,7 +4,7 @@ import time\n from django.apps import apps\n from django.conf import settings\n from django.core import serializers\n-from django.db import router\n+from django.db import router, transaction\n from django.utils.six import StringIO\n from django.utils.six.moves import input\n \n@@ -128,8 +128,12 @@ class BaseDatabaseCreation(object):\n         the serialize_db_to_string method.\n         \"\"\"\n         data = StringIO(data)\n-        for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n-            obj.save()\n+        with transaction.atomic(using=self.connection.alias):\n+            with self.connection.constraint_checks_disabled():\n+                for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n+                    obj.save()\n+            # Check constraints after all objects are saved\n+            self.connection.check_constraints()\n \n     def _get_database_display_str(self, verbosity, database_name):\n         \"\"\"",
      "generation_time": 5.376755952835083,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid decimal literal (<unknown>, line 2)",
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.038564205169677734,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12470",
      "repo": "django/django",
      "problem_statement": "Inherited model doesn't correctly order by \"-pk\" when specified on Parent.Meta.ordering\nDescription\n\t\nGiven the following model definition:\nfrom django.db import models\nclass Parent(models.Model):\n\tclass Meta:\n\t\tordering = [\"-pk\"]\nclass Child(Parent):\n\tpass\nQuerying the Child class results in the following:\n>>> print(Child.objects.all().query)\nSELECT \"myapp_parent\".\"id\", \"myapp_child\".\"parent_ptr_id\" FROM \"myapp_child\" INNER JOIN \"myapp_parent\" ON (\"myapp_child\".\"parent_ptr_id\" = \"myapp_parent\".",
      "hints_text": null,
      "claude_patch": "# File: django/db/models/sql/query.py\n\nfrom django.db.models.sql.query import Query\n\n# Store the original add_ordering method\n_original_add_ordering = Query.add_ordering\n\ndef patched_add_ordering(self, *ordering):\n    \"\"\"\n    Add items from the 'ordering' sequence to the query's \"order by\"\n    clause. These items are either field names (not column names) --\n    possibly with a direction prefix ('-' or '?') -- or OrderBy\n    expressions.\n    \n    If 'ordering' is empty, clear all ordering from the query.\n    \"\"\"\n    errors = []\n    for item in ordering:\n        if isinstance(item, str):\n            if item == '?':\n                continue\n            if item.startswith('-'):\n                descending = True\n                item_without_prefix = item[1:]\n            else:\n                descending = False\n                item_without_prefix = item\n            \n            # Check if this is 'pk' and needs special handling\n            if item_without_prefix == 'pk':\n                # Get the actual primary key field\n                field = self.get_meta().pk\n                if field:\n                    # Reconstruct the ordering with the actual field name\n                    if descending:\n                        item = '-' + field.name\n                    else:\n                        item = field.name\n        \n        errors.extend(self.add_ordering_item(item))\n    \n    if errors:\n        raise FieldError('Invalid order_by arguments: %s' % errors)\n\n# Monkey patch is not ideal, but we need to fix the actual issue in the codebase\n# The real fix should be in django/db/models/sql/query.py\n\n# Actually, let's look at the proper location for the fix:\n\n# File: django/db/models/sql/compiler.py\nfrom django.db.models.sql.compiler import SQLCompiler\n\n_original_get_order_by = SQLCompiler.get_order_by\n\ndef patched_get_order_by(self):\n    \"\"\"\n    Return a list of 2-tuples of the form (expr, (sql, params, is_ref)) for the\n    ORDER BY clause.\n    \n    The order_by clause can alter the select clause (for example it can add\n    aliases to clauses that do not yet have one, or it can add totally new\n    select clauses).\n    \"\"\"\n    if self.query.extra_order_by:\n        ordering = self.query.extra_order_by\n    elif not self.query.default_ordering:\n        ordering = self.query.order_by\n    else:\n        ordering = (self.query.order_by or self.query.get_meta().ordering or [])\n    \n    if ordering:\n        # Resolve 'pk' to the actual primary key field name while preserving direction\n        resolved_ordering = []\n        for item in ordering:\n            if isinstance(item, str):\n                if item == 'pk':\n                    resolved_ordering.append(self.query.get_meta().pk.name)\n                elif item == '-pk':\n                    resolved_ordering.append('-' + self.query.get_meta().pk.name)\n                else:\n                    resolved_ordering.append(item)\n            else:\n                resolved_ordering.append(item)\n        ordering = resolved_ordering\n    \n    return _original_get_order_by(self)\n\n# The actual fix needs to be in the Options class or where ordering is resolved\n# File: django/db/models/options.py\n\nfrom django.db.models.options import Options\n\n_original_ordering_property = Options.ordering\n\n@property\ndef patched_ordering(self):\n    \"\"\"\n    Return the ordering with 'pk' resolved to the actual primary key field.\n    \"\"\"\n    ordering = self._ordering\n    if ordering:\n        resolved = []\n        for item in ordering:\n            if isinstance(item, str):\n                if item == 'pk':\n                    resolved.append(self.pk.name)\n                elif item == '-pk':\n                    resolved.append('-' + self.pk.name)\n                else:\n                    resolved.append(item)\n            else:\n                resolved.append(item)\n        return tuple(resolved)\n    return ordering\n\n# Apply the patch\nOptions.ordering = patched_ordering",
      "generation_time": 28.868751049041748,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 14,
      "critical_issues": 0,
      "high_issues": 6,
      "medium_issues": 4,
      "low_issues": 4,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 0.55,
        "style": 0.7,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: logic - Low logic score: 0.40",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.1767578125,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12497",
      "repo": "django/django",
      "problem_statement": "Wrong hint about recursive relationship.\nDescription\n\t \n\t\t(last modified by Matheus Cunha Motta)\n\t \nWhen there's more than 2 ForeignKeys in an intermediary model of a m2m field and no through_fields have been set, Django will show an error with the following hint:\nhint=(\n\t'If you want to create a recursive relationship, '\n\t'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\nBut 'symmetrical' and 'through' are m2m keyword arguments, not ForeignKey.\nThis was probably a small mistake where the",
      "hints_text": "Here's a PR: \u200bhttps://github.com/django/django/pull/12497 Edit: forgot to run tests and there was an error detected in the PR. I'll try to fix and run tests before submitting again.",
      "claude_patch": "# File: django/db/models/fields/related.py\n\n# Find and replace the incorrect hint in the ManyToManyField validation\n\n# The fix should be in the _check_relationship_model method or similar validation method\n# that checks for ambiguous relationships in through models\n\n# Original code would be something like:\n# hint=(\n#     'If you want to create a recursive relationship, '\n#     'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n# )\n\n# Should be changed to:\n# hint=(\n#     'If you want to create a recursive relationship, '\n#     'use ManyToManyField(\"%s\", through=\"%s\").'\n# )\n\n# Let's find the actual location and fix it:\n\nfrom django.core import checks\nfrom django.db import models\n\n\ndef _check_relationship_model(self, from_model=None, **kwargs):\n    if hasattr(self, 'remote_field') and self.remote_field.through and not self.remote_field.through._meta.auto_created:\n        from_model = from_model or self.model\n        if isinstance(self.remote_field.through, str):\n            return []\n        \n        # Check if there are multiple foreign keys to the same model\n        seen_from = sum(\n            from_model == getattr(field.remote_field, 'model', None)\n            for field in self.remote_field.through._meta.fields\n            if hasattr(field, 'remote_field')\n        )\n        seen_to = sum(\n            self.remote_field.model == getattr(field.remote_field, 'model', None)\n            for field in self.remote_field.through._meta.fields\n            if hasattr(field, 'remote_field')\n        )\n        \n        if seen_from > 1 and seen_to > 1:\n            errors = [\n                checks.Error(\n                    \"The model is used as an intermediate model by \"\n                    \"'%s.%s', but it has more than one foreign key \"\n                    \"to '%s', which is ambiguous. You must specify \"\n                    \"which foreign key Django should use via the \"\n                    \"through_fields keyword argument.\" % (\n                        from_model._meta.object_name,\n                        self.name,\n                        from_model._meta.object_name,\n                    ),\n                    hint=(\n                        'If you want to create a recursive relationship, '\n                        'use ManyToManyField(\"%s\", through=\"%s\").' % (\n                            from_model._meta.object_name,\n                            self.remote_field.through._meta.object_name,\n                        )\n                    ),\n                    obj=self,\n                    id='fields.E335',\n                )\n            ]\n            return errors\n        elif seen_from > 1 or seen_to > 1:\n            errors = [\n                checks.Error(\n                    \"The model is used as an intermediate model by \"\n                    \"'%s.%s', but it has more than one foreign key \"\n                    \"from/to '%s', which is ambiguous. You must specify \"\n                    \"which foreign key Django should use via the \"\n                    \"through_fields keyword argument.\" % (\n                        from_model._meta.object_name,\n                        self.name,\n                        from_model._meta.object_name if seen_from > 1 else self.remote_field.model._meta.object_name,\n                    ),\n                    hint=(\n                        'If you want to create a recursive relationship, '\n                        'use ManyToManyField(\"%s\", through=\"%s\").' % (\n                            from_model._meta.object_name,\n                            self.remote_field.through._meta.object_name,\n                        )\n                    ),\n                    obj=self,\n                    id='fields.E335',\n                )\n            ]\n            return errors\n    \n    return []",
      "generation_time": 15.84498381614685,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 13,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 5,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8233333333333333,
        "style": 0.42800000000000016,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: ast_analysis - Function '_check_relationship_model' too long (67 lines) - production maintainability concern",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.17656874656677246,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12589",
      "repo": "django/django",
      "problem_statement": "Django 3.0: \"GROUP BY\" clauses error with tricky field annotation\nDescription\n\t\nLet's pretend that we have next model structure with next model's relations:\nclass A(models.Model):\n\tbs = models.ManyToManyField('B',\n\t\t\t\t\t\t\t\trelated_name=\"a\",\n\t\t\t\t\t\t\t\tthrough=\"AB\")\nclass B(models.Model):\n\tpass\nclass AB(models.Model):\n\ta = models.ForeignKey(A, on_delete=models.CASCADE, related_name=\"ab_a\")\n\tb = models.ForeignKey(B, on_delete=models.CASCADE, related_name=\"ab_b\")\n\tstatus = models.IntegerField()\nclass C",
      "hints_text": "This is due to a collision of AB.status and the status annotation. The easiest way to solve this issue is to disable group by alias when a collision is detected with involved table columns. This can b",
      "claude_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 1234567890..abcdefghij 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1940,6 +1940,17 @@ class Query(BaseExpression):\n                 expressions.extend(expr.get_source_expressions())\n             for expr in expressions:\n                 cols = expr.get_group_by_cols()\n+                # Check if alias collides with any column name in joined tables\n+                if alias is not None:\n+                    for table_alias in self.alias_map:\n+                        try:\n+                            table = self.alias_map[table_alias].table\n+                            if hasattr(table, 'model'):\n+                                field_names = {f.column for f in table.model._meta.get_fields() if hasattr(f, 'column')}\n+                                if alias in field_names:\n+                                    alias = None\n+                                    break\n+                        except (AttributeError, TypeError):\n+                            continue\n                 group_by.extend(cols)\n         self.group_by = tuple(group_by)",
      "generation_time": 18.956820011138916,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.046054840087890625,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12700",
      "repo": "django/django",
      "problem_statement": "Settings are cleaned insufficiently.\nDescription\n\t\nPosting publicly after checking with the rest of the security team.\nI just ran into a case where django.views.debug.SafeExceptionReporterFilter.get_safe_settings() would return several un-cleansed values. Looking at cleanse_setting() I realized that we \u200bonly take care of `dict`s but don't take other types of iterables into account but \u200breturn them as-is.\nExample:\nIn my settings.py I have this:\nMY_SETTING = {\n\t\"foo\": \"value\",\n\t\"secret\": \"value\",\n",
      "hints_text": "Do I need to change both versions? Or just create a single implementation for current master branch?",
      "claude_patch": "def cleanse_setting(self, key, value):\n    \"\"\"\n    Cleanse an individual setting key/value of sensitive content. If the\n    value is a dictionary, recursively cleanse the keys in that dictionary.\n    \"\"\"\n    try:\n        if self.hidden_settings.search(key):\n            cleansed = self.cleansed_substitute\n        elif isinstance(value, dict):\n            cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}\n        elif isinstance(value, (list, tuple)):\n            cleansed = type(value)(\n                self.cleanse_setting('', item) if isinstance(item, dict)\n                else self.cleanse_setting('', item) if isinstance(item, (list, tuple))\n                else item\n                for item in value\n            )\n        else:\n            cleansed = value\n    except TypeError:\n        # If the key isn't regex-able, just return as-is.\n        cleansed = value\n\n    if callable(cleansed):\n        cleansed = self.callables_substitute\n\n    return cleansed",
      "generation_time": 9.582522869110107,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 7,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 1,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.9474900980183243,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path",
        "HIGH: loop_nesting - Extreme loop nesting: 4 levels"
      ],
      "verification_time": 0.04312300682067871,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12708",
      "repo": "django/django",
      "problem_statement": "Migration crashes deleting an index_together if there is a unique_together on the same fields\nDescription\n\t\nHappens with Django 1.11.10\nSteps to reproduce:\n1) Create models with 2 fields, add 2 same fields to unique_together and to index_together\n2) Delete index_together -> Fail\nIt will fail at django/db/backends/base/schema.py, line 378, in _delete_composed_index(), ValueError: Found wrong number (2) of constraints for as this one will find two constraints, the _uniq and the _idx one. No way to",
      "hints_text": "Reproduced on master at 623139b5d1bd006eac78b375bcaf5948e695c3c6.\nI haven't looked under the hood on this yet, but could it be related to the ordering of the operations generated for the mgiration? on",
      "claude_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 1234567890..abcdefghij 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -365,7 +365,7 @@ class BaseDatabaseSchemaEditor:\n         \"\"\"\n         meta_constraint_names = {constraint.name for constraint in model._meta.constraints}\n         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n-        columns = [model._meta.get_field(field).column for field in fields]\n+        columns = [model._meta.get_field(field).column for field in fields] if fields else []\n         constraint_names = self._constraint_names(\n             model,\n             columns,\n@@ -374,13 +374,28 @@ class BaseDatabaseSchemaEditor:\n             foreign_key=foreign_key,\n             primary_key=primary_key,\n         )\n-        if len(constraint_names) != 1:\n+        # Filter out constraints that shouldn't be deleted based on the index parameter\n+        if index is not None:\n+            # When index=True, we only want to delete indexes (not unique constraints)\n+            # When index=False, we only want to delete unique constraints (not indexes)\n+            filtered_constraint_names = []\n+            for constraint_name in constraint_names:\n+                # Check if this is an index by seeing if it's in meta_index_names\n+                # or if it follows the index naming pattern\n+                is_index = (\n+                    constraint_name in meta_index_names or\n+                    '_idx' in constraint_name or\n+                    not ('_uniq' in constraint_name or constraint_name in meta_constraint_names)\n+                )\n+                if (index and is_index) or (not index and not is_index):\n+                    filtered_constraint_names.append(constraint_name)\n+            constraint_names = filtered_constraint_names\n+        \n+        if len(constraint_names) != 1:\n             raise ValueError(\n                 \"Found wrong number (%s) of constraints for %s(%s)\" %\n                 (\n                     len(constraint_names),\n                     model._meta.db_table,\n-                    \", \".join(columns),\n+                    \", \".join(columns) if columns else \"\",\n                 )\n             )\n         self.execute(self._delete_constraint_sql(self.sql_delete_index, model, constraint_names[0]))\ndiff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex 2345678901..bcdefghijk 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -350,7 +350,7 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         return constraint_names\n \n     def _delete_composed_index(self, model, fields, *args):\n-        meta_constraint_names = {constraint.name for constraint in model._meta.constraints}\n+        meta_constraint_names = {constraint.name for constraint in model._meta.constraints if hasattr(constraint, 'name')}\n         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n         columns = [model._meta.get_field(field).column for field in fields]\n         constraint_names = self._constraint_names(\n@@ -360,6 +360,21 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             index=True,\n         ) - meta_constraint_names - meta_index_names\n         if len(constraint_names) != 1:\n+            # Try to filter by index type if we have multiple constraints\n+            # This handles the case where both unique_together and index_together exist\n+            index_only_names = []\n+            for name in constraint_names:\n+                # Check if this is an index (not a unique constraint)\n+                # by examining the constraint in the database\n+                with self.connection.cursor() as cursor:\n+                    cursor.execute(\n+                        \"SELECT sql FROM sqlite_master WHERE type='index' AND name=%s\",\n+                        [name]\n+                    )\n+                    result = cursor.fetchone()\n+                    if result and result[0] and 'UNIQUE' not in result[0].upper():\n+                        index_only_names.append(name)\n+            constraint_names = index_only_names if index_only_names else constraint_names\n+        if len(constraint_names) != 1:\n             raise ValueError(\n                 \"Found wrong number (%s) of constraints for %s(%s)\" %\n                 (",
      "generation_time": 17.104320764541626,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: unterminated triple-quoted string literal (detected at line 82) (<unknown>, line 6)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.04997396469116211,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12747",
      "repo": "django/django",
      "problem_statement": "QuerySet.Delete - inconsistent result when zero objects deleted\nDescription\n\t\nThe result format of the QuerySet.Delete method is a tuple: (X, Y) \nX - is the total amount of deleted objects (including foreign key deleted objects)\nY - is a dictionary specifying counters of deleted objects for each specific model (the key is the _meta.label of the model and the value is counter of deleted objects of this model).\nExample: <class 'tuple'>: (2, {'my_app.FileAccess': 1, 'my_app.File': 1})\nWhen there ar",
      "hints_text": "I guess we could adapt the code not to include any key if the count is zero in the second case.",
      "claude_patch": "# File: django/db/models/deletion.py\n\ndef delete(self):\n    \"\"\"\n    Delete the instances in the current QuerySet.\n    \"\"\"\n    # ... existing code ...\n    \n    # Find the location where the deletion results are being compiled\n    # and ensure that models with zero deletions are not added to the dictionary\n    \n    # The fix should be in the Collector class's delete method\n    # We need to modify how deleted_counter is populated\n\n# Patch for django/db/models/deletion.py\n\nfrom django.db import models, router, transaction\nfrom django.db.models import signals, sql\n\nclass Collector:\n    # ... existing code ...\n    \n    def delete(self):\n        # ... existing setup code ...\n        \n        # The issue is in how we build the deleted_counter dictionary\n        # We should only include entries where the count is > 0\n        \n        deleted_counter = {}\n        \n        # ... existing deletion logic ...\n        \n        # When building the result, filter out zero counts\n        for model, instances in self.data.items():\n            count = len(instances)\n            if count > 0:  # Only add to counter if count > 0\n                deleted_counter[model._meta.label] = count\n        \n        return sum(deleted_counter.values()), deleted_counter\n\n# The actual fix location in django/db/models/deletion.py\n\n# Original problematic code is around line 440-450 in Collector.delete()\n# We need to modify the part that builds deleted_counter\n\n# Here's the specific patch:\n\ndef delete(self):\n    # ... existing code before the return statement ...\n    \n    # Build the deleted counter, excluding zero counts\n    deleted_counter = {}\n    for model, instances in self.data.items():\n        count = len(instances)\n        if count > 0:\n            deleted_counter[model._meta.label] = count\n    \n    # ... rest of existing code ...\n    \n    return sum(deleted_counter.values()), deleted_counter",
      "generation_time": 18.63441300392151,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 13,
      "critical_issues": 0,
      "high_issues": 4,
      "medium_issues": 5,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.7556192706675355,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: ast_analysis - Public function 'delete' missing docstring - production documentation required",
        "HIGH: edge_case_coverage - Low edge case coverage: 66.7%"
      ],
      "verification_time": 0.17224717140197754,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12856",
      "repo": "django/django",
      "problem_statement": "Add check for fields of UniqueConstraints.\nDescription\n\t \n\t\t(last modified by Marnanel Thurman)\n\t \nWhen a model gains a UniqueConstraint, makemigrations doesn't check that the fields named therein actually exist.\nThis is in contrast to the older unique_together syntax, which raises models.E012 if the fields don't exist.\nIn the attached demonstration, you'll need to uncomment \"with_unique_together\" in settings.py in order to show that unique_together raises E012.\n",
      "hints_text": "Demonstration\nAgreed. We can simply call cls._check_local_fields() for UniqueConstraint's fields. I attached tests.\nTests.\nHello Django Team, My name is Jannah Mandwee, and I am working on my final pr",
      "claude_patch": "diff --git a/django/db/models/constraints.py b/django/db/models/constraints.py\nindex 1234567..abcdefg 100644\n--- a/django/db/models/constraints.py\n+++ b/django/db/models/constraints.py\n@@ -1,6 +1,7 @@\n from enum import Enum\n \n from django.db.models.query_utils import Q\n+from django.db.models.utils import resolve_callables\n from django.db.models.sql.query import Query\n \n __all__ = ['BaseConstraint', 'CheckConstraint', 'Deferrable', 'UniqueConstraint']\n@@ -81,6 +82,27 @@ class CheckConstraint(BaseConstraint):\n     def __eq__(self, other):\n         if isinstance(other, CheckConstraint):\n             return self.name == other.name and self.check == other.check\n         return super().__eq__(other)\n \n+    def _check(self, **kwargs):\n+        errors = super()._check(**kwargs)\n+        errors.extend(self._check_check_constraint())\n+        return errors\n+\n+    def _check_check_constraint(self):\n+        from django.db import models\n+        errors = []\n+        for field_name in self.check.flatten():\n+            if not hasattr(field_name, 'split'):\n+                continue\n+            if field_name.split('__')[0] not in [f.name for f in self.model._meta.get_fields()]:\n+                errors.append(\n+                    models.E012(\n+                        \"'%s' refers to the nonexistent field '%s'.\" % (\n+                            self.name, field_name,\n+                        ),\n+                        obj=self.model,\n+                    )\n+                )\n+        return errors\n+\n \n class Deferrable(Enum):\n@@ -159,6 +181,29 @@ class UniqueConstraint(BaseConstraint):\n             return (\n                 self.name == other.name and\n                 self.fields == other.fields and\n                 self.condition == other.condition and\n                 self.deferrable == other.deferrable and\n                 self.include == other.include and\n                 self.opclasses == other.opclasses\n             )\n         return super().__eq__(other)\n+\n+    def _check(self, **kwargs):\n+        errors = super()._check(**kwargs)\n+        errors.extend(self._check_unique_constraint_fields())\n+        return errors\n+\n+    def _check_unique_constraint_fields(self):\n+        from django.db import models\n+        errors = []\n+        for field_name in self.fields:\n+            try:\n+                self.model._meta.get_field(field_name)\n+            except models.FieldDoesNotExist:\n+                errors.append(\n+                    models.E012(\n+                        \"'constraints' refers to the nonexistent field '%s'.\" % field_name,\n+                        obj=self.model,\n+                    )\n+                )\n+        return errors",
      "generation_time": 22.298759937286377,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.058094024658203125,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12908",
      "repo": "django/django",
      "problem_statement": "Union queryset should raise on distinct().\nDescription\n\t \n\t\t(last modified by Sielc Technologies)\n\t \nAfter using\n.annotate() on 2 different querysets\nand then .union()\n.distinct() will not affect the queryset\n\tdef setUp(self) -> None:\n\t\tuser = self.get_or_create_admin_user()\n\t\tSample.h.create(user, name=\"Sam1\")\n\t\tSample.h.create(user, name=\"Sam2 acid\")\n\t\tSample.h.create(user, name=\"Sam3\")\n\t\tSample.h.create(user, name=\"Sam4 acid\")\n\t\tSample.h.create(user, name=\"Dub\")\n\t\tSample.h.create(user, name=\"",
      "hints_text": "distinct() is not supported but doesn't raise an error yet. As \u200b\u200bper the documentation, \"only LIMIT, OFFSET, COUNT(*), ORDER BY, and specifying columns (i.e. slicing, count(), order_by(), and values()",
      "claude_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1234,6 +1234,8 @@ class QuerySet:\n         assert not self.query.is_sliced, \\\n             \"Cannot create distinct fields once a slice has been taken.\"\n         obj = self._chain()\n+        if obj.query.combinator:\n+            raise NotSupportedError('Calling distinct() after union() is not supported.')\n         obj.query.add_distinct_fields(*field_names)\n         return obj",
      "generation_time": 9.11375093460083,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04244804382324219,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12915",
      "repo": "django/django",
      "problem_statement": "Add get_response_async for ASGIStaticFilesHandler\nDescription\n\t\nIt looks like the StaticFilesHandlerMixin is missing the the async response function.\nWithout this, when trying to use the ASGIStaticFilesHandler, this is the traceback:\nException inside application: 'NoneType' object is not callable\nTraceback (most recent call last):\n File \".../lib/python3.7/site-packages/daphne/cli.py\", line 30, in asgi\n\tawait self.app(scope, receive, send)\n File \".../src/django/django/contrib/staticfiles/handlers",
      "hints_text": null,
      "claude_patch": "# django/contrib/staticfiles/handlers.py\n\nfrom django.core.handlers.asgi import ASGIHandler\nfrom django.core.handlers.wsgi import WSGIHandler\nfrom django.http import Http404\nfrom django.utils.functional import cached_property\nfrom django.contrib.staticfiles import finders\nfrom django.contrib.staticfiles.views import serve\nfrom asgiref.sync import sync_to_async\n\n\nclass StaticFilesHandlerMixin:\n    \"\"\"\n    Common methods used by WSGI and ASGI handlers.\n    \"\"\"\n    # May be used to differentiate between handler types (e.g., in a\n    # request_finished signal)\n    handles_files = True\n\n    def load_middleware(self):\n        # Middleware are already loaded for self.application; no need to reload\n        # them for self.\n        pass\n\n    def get_base_url(self):\n        utils_module = import_module('django.contrib.staticfiles.utils')\n        return utils_module.get_files_url()\n\n    @cached_property\n    def base_url(self):\n        return self.get_base_url()\n\n    def _should_handle(self, path):\n        \"\"\"\n        Check if the path should be handled. Ignore the path if:\n        * the host is provided as part of the base_url\n        * the request's path isn't under the media path (or equal)\n        \"\"\"\n        return path.startswith(self.base_url[2]) and not self.base_url[1]\n\n    def file_path(self, url):\n        \"\"\"\n        Return the relative path to the media file on disk for the given URL.\n        \"\"\"\n        relative_url = url[len(self.base_url[2]):]\n        return url2pathname(relative_url)\n\n    def serve(self, request):\n        \"\"\"Serve the request path.\"\"\"\n        return serve(request, self.file_path(request.path), insecure=True)\n\n    def get_response(self, request):\n        try:\n            return self.serve(request)\n        except Http404 as e:\n            return response_for_exception(request, e)\n\n    async def get_response_async(self, request):\n        try:\n            return await sync_to_async(self.serve, thread_sensitive=False)(request)\n        except Http404 as e:\n            return await sync_to_async(response_for_exception, thread_sensitive=False)(request, e)\n\n\nclass StaticFilesHandler(StaticFilesHandlerMixin, WSGIHandler):\n    \"\"\"\n    WSGI middleware that intercepts calls to the static files directory, as\n    defined by the STATIC_URL setting, and serves those files.\n    \"\"\"\n    def __init__(self, application):\n        self.application = application\n        self.base_url = urlparse(self.get_base_url())\n        super().__init__()\n\n    def __call__(self, environ, start_response):\n        if not self._should_handle(get_path_info(environ)):\n            return self.application(environ, start_response)\n        return super().__call__(environ, start_response)\n\n\nclass ASGIStaticFilesHandler(StaticFilesHandlerMixin, ASGIHandler):\n    \"\"\"\n    ASGI application which wraps another and intercepts requests for static\n    files, passing them off to Django's static file serving.\n    \"\"\"\n    def __init__(self, application):\n        self.application = application\n        self.base_url = urlparse(self.get_base_url())\n        super().__init__()\n\n    async def __call__(self, scope, receive, send):\n        # Only even look at HTTP requests\n        if scope['type'] == 'http' and self._should_handle(scope['path']):\n            # Serve static content\n            # (the one thing super() doesn't do is __call__, apparently)\n            return await super().__call__(scope, receive, send)\n        # Hand off to the main app\n        return await self.application(scope, receive, send)\n\n\ndef import_module(name):\n    \"\"\"Import a module by name.\"\"\"\n    from importlib import import_module as _import_module\n    return _import_module(name)\n\n\ndef urlparse(url):\n    \"\"\"Parse a URL into components.\"\"\"\n    from urllib.parse import urlparse as _urlparse\n    return _urlparse(url)\n\n\ndef url2pathname(path):\n    \"\"\"Convert URL path to filesystem path.\"\"\"\n    from urllib.request import url2pathname as _url2pathname\n    return _url2pathname(path)\n\n\ndef get_path_info(environ):\n    \"\"\"Get the path info from WSGI environ.\"\"\"\n    from django.core.handlers.wsgi import get_path_info as _get_path_info\n    return _get_path_info(environ)\n\n\ndef response_for_exception(request, exc):\n    \"\"\"Get response for an exception.\"\"\"\n    from django.core.handlers.exception import response_for_exception as _response_for_exception\n    return _response_for_exception(request, exc)",
      "generation_time": 20.18037509918213,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 37,
      "critical_issues": 0,
      "high_issues": 8,
      "medium_issues": 21,
      "low_issues": 8,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.496,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: missing_input_validation - Function 'response_for_exception' missing input validation for production safety",
        "HIGH: missing_edge_case - Function 'response_for_exception' missing None value handling",
        "HIGH: contract_violation - Function 'response_for_exception' docstring mentions exceptions but none are raised"
      ],
      "verification_time": 0.23186516761779785,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12983",
      "repo": "django/django",
      "problem_statement": "Make django.utils.text.slugify() strip dashes and underscores\nDescription\n\t \n\t\t(last modified by Elinaldo do Nascimento Monteiro)\n\t \nBug generation slug\nExample:\nfrom django.utils import text\ntext.slugify(\"___This is a test ---\")\noutput: ___this-is-a-test-\nImprovement after correction\nfrom django.utils import text\ntext.slugify(\"___This is a test ---\")\noutput: this-is-a-test\n\u200bPR\n",
      "hints_text": "The current version of the patch converts all underscores to dashes which (as discussed on the PR) isn't an obviously desired change. A discussion is needed to see if there's consensus about that chan",
      "claude_patch": "import re\nimport unicodedata\n\n\ndef slugify(value, allow_unicode=False):\n    \"\"\"\n    Convert to ASCII if 'allow_unicode' is False. Convert spaces or repeated\n    dashes to single dashes. Remove characters that aren't alphanumerics,\n    underscores, or hyphens. Convert to lowercase. Also strip leading and\n    trailing whitespace, dashes, and underscores.\n    \"\"\"\n    value = str(value)\n    if allow_unicode:\n        value = unicodedata.normalize('NFKC', value)\n    else:\n        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n    value = re.sub(r'[^\\w\\s-]', '', value.lower())\n    return re.sub(r'[-\\s]+', '-', value).strip('-_')",
      "generation_time": 5.27709698677063,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 10,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 2,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8333333333333334,
        "style": 0.9319999999999999,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%"
      ],
      "verification_time": 0.041522979736328125,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-13028",
      "repo": "django/django",
      "problem_statement": "Queryset raises NotSupportedError when RHS has filterable=False attribute.\nDescription\n\t \n\t\t(last modified by Nicolas Baccelli)\n\t \nI'm migrating my app to django 3.0.7 and I hit a strange behavior using a model class with a field labeled filterable\nclass ProductMetaDataType(models.Model):\n\tlabel = models.CharField(max_length=255, unique=True, blank=False, null=False)\n\tfilterable = models.BooleanField(default=False, verbose_name=_(\"filterable\"))\n\tclass Meta:\n\t\tapp_label = \"adminpricing\"\n\t\tverbose",
      "hints_text": "Thanks for the report, that's a nice edge case. We should be able to fix this by checking if rhs is an expression: diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index ce18",
      "claude_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..ad981377a0 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1124,7 +1124,7 @@ class Query(BaseExpression):\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        if hasattr(expression, 'resolve_expression') and not getattr(expression, 'filterable', True):\n             raise NotSupportedError(\n                 expression.__class__.__name__ + ' is disallowed in the filter '\n                 'clause.'",
      "generation_time": 3.5461058616638184,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.038374900817871094,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13033",
      "repo": "django/django",
      "problem_statement": "Self referencing foreign key doesn't correctly order by a relation \"_id\" field.\nDescription\n\t\nInitially discovered on 2.2.10 but verified still happens on 3.0.6. Given the following models:\nclass OneModel(models.Model):\n\tclass Meta:\n\t\tordering = (\"-id\",)\n\tid = models.BigAutoField(primary_key=True)\n\troot = models.ForeignKey(\"OneModel\", on_delete=models.CASCADE, null=True)\n\toneval = models.BigIntegerField(null=True)\nclass TwoModel(models.Model):\n\tid = models.BigAutoField(primary_key=True)\n\trecord ",
      "hints_text": "This is with a postgres backend. Fairly vanilla Django. Some generic middleware installed (cors, csrf, auth, session). Apps are: INSTALLED_APPS = ( \"django.contrib.contenttypes\", \"django.contrib.auth\"",
      "claude_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex abbb1e37cb..a8f5b61fbe 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -727,7 +727,7 @@ class SQLCompiler:\n             # If we get to this point and the field is a relation to another model,\n             # append the default ordering for that model unless it is the pk\n             # shortcut or the attribute name of the field that is specified.\n-            if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk':\n+            if field.is_relation and opts.ordering and getattr(field, 'attname', None) != pieces[-1] and name != 'pk':\n                 # Firstly, avoid infinite loops.\n                 already_seen = already_seen or set()\n                 join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)",
      "generation_time": 4.399239778518677,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.03932809829711914,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13158",
      "repo": "django/django",
      "problem_statement": "QuerySet.none() on combined queries returns all results.\nDescription\n\t\nI came across this issue on Stack Overflow. I'm not 100% sure it's a bug, but it does seem strange. With this code (excuse the bizarre example filtering):\nclass Publication(models.Model):\n\tpass\nclass Article(models.Model):\n\tpublications = models.ManyToManyField(to=Publication, blank=True, null=True)\nclass ArticleForm(forms.ModelForm):\n\tpublications = forms.ModelMultipleChoiceField(\n\t\tPublication.objects.filter(id__lt=2) | Pub",
      "hints_text": "Thanks for the report. QuerySet.none() doesn't work properly on combined querysets, it returns all results instead of an empty queryset.",
      "claude_patch": "# File: django/db/models/query.py\n\ndef none(self):\n    \"\"\"Return an empty QuerySet.\"\"\"\n    if self.query.combinator:\n        clone = self._chain()\n        clone.query.set_empty()\n        return clone\n    clone = self._chain()\n    clone.query.set_empty()\n    return clone",
      "generation_time": 17.514339208602905,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 3,
      "low_issues": 3,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.7266666666666667,
        "style": 0.874,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 63.3%",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.049137115478515625,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13220",
      "repo": "django/django",
      "problem_statement": "Allow ValidationErrors to equal each other when created identically\nDescription\n\t \n\t\t(last modified by kamni)\n\t \nCurrently ValidationErrors (django.core.exceptions.ValidationError) that have identical messages don't equal each other, which is counter-intuitive, and can make certain kinds of testing more complicated. Please add an __eq__ method that allows two ValidationErrors to be compared. \nIdeally, this would be more than just a simple self.messages == other.messages. It would be most helpful",
      "hints_text": "I probably wouldn't want to limit the comparison to an error's message but rather to its full set of attributes (message, code, params). While params is always pushed into message when iterating over ",
      "claude_patch": "def __eq__(self, other):\n    if not isinstance(other, ValidationError):\n        return NotImplemented\n    \n    # Compare error_dict if both have it\n    if hasattr(self, 'error_dict') and hasattr(other, 'error_dict'):\n        if set(self.error_dict.keys()) != set(other.error_dict.keys()):\n            return False\n        for key in self.error_dict.keys():\n            self_errors = self.error_dict[key]\n            other_errors = other.error_dict[key]\n            if len(self_errors) != len(other_errors):\n                return False\n            # Compare as sets to be order-independent\n            self_set = {(e.message, e.code, tuple(sorted(e.params.items())) if e.params else None) for e in self_errors}\n            other_set = {(e.message, e.code, tuple(sorted(e.params.items())) if e.params else None) for e in other_errors}\n            if self_set != other_set:\n                return False\n        return True\n    \n    # Compare error_list if both have it\n    if hasattr(self, 'error_list') and hasattr(other, 'error_list'):\n        if len(self.error_list) != len(other.error_list):\n            return False\n        # Compare as sets to be order-independent\n        self_set = {(e.message, e.code, tuple(sorted(e.params.items())) if e.params else None) for e in self.error_list}\n        other_set = {(e.message, e.code, tuple(sorted(e.params.items())) if e.params else None) for e in other.error_list}\n        return self_set == other_set\n    \n    # If one has error_dict and other has error_list, they're not equal\n    if hasattr(self, 'error_dict') != hasattr(other, 'error_dict'):\n        return False\n    if hasattr(self, 'error_list') != hasattr(other, 'error_list'):\n        return False\n    \n    # Fallback to comparing messages\n    return self.messages == other.messages\n\ndef __hash__(self):\n    # Since we're implementing __eq__, we should make the object unhashable\n    # to avoid issues with dict/set usage, as ValidationError is mutable\n    raise TypeError(\"unhashable type: 'ValidationError'\")",
      "generation_time": 9.32982873916626,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 12,
      "critical_issues": 0,
      "high_issues": 5,
      "medium_issues": 2,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.45,
        "style": 0.7112853916011771,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.10",
        "HIGH: edge_case_coverage - Low edge case coverage: 50.0%"
      ],
      "verification_time": 0.05811190605163574,
      "patch_quality_estimate": "LOW"
    }
  ]
}