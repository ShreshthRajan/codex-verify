[
  {
    "problem_id": "sql_injection_005",
    "issue_description": "Fix SQL query construction to prevent injection attacks",
    "repo_context": "Database utility module for user authentication system",
    "codex_solution": "class UserAuthenticator:\n    def __init__(self, db_connection):\n        self.db = db_connection\n    \n    def authenticate_user(self, username, password):\n        \"\"\"Authenticate user against database\"\"\"\n        # BUG: SQL injection vulnerability - directly interpolating user input\n        query = f\"SELECT * FROM users WHERE username = '{username}' AND password = '{password}'\"\n        cursor = self.db.cursor()\n        cursor.execute(query)\n        result = cursor.fetchone()\n        \n        if result:\n            return {'id': result[0], 'username': result[1], 'role': result[3]}\n        return None\n    \n    def get_user_by_id(self, user_id):\n        \"\"\"Retrieve user by ID\"\"\"\n        # BUG: Still vulnerable even with integer casting attempt\n        query = f\"SELECT * FROM users WHERE id = {user_id}\"\n        cursor = self.db.cursor()\n        cursor.execute(query)\n        return cursor.fetchone()",
    "actual_issue": "SQL injection vulnerability - user input is directly interpolated into SQL queries without parameterization. Attacker can inject malicious SQL like username=\"admin' --\" to bypass authentication.",
    "failure_category": "security",
    "difficulty_level": "easy",
    "should_be_rejected": true
  },
  {
    "problem_id": "race_condition_003",
    "issue_description": "Implement thread-safe counter with proper locking",
    "repo_context": "Metrics collection system for high-traffic web application",
    "codex_solution": "import threading\nimport time\n\nclass MetricsCounter:\n    def __init__(self):\n        self.counts = {}\n        self.lock = threading.Lock()\n    \n    def increment(self, metric_name, value=1):\n        \"\"\"Increment a metric counter\"\"\"\n        # BUG: Check-then-act race condition\n        if metric_name not in self.counts:\n            self.counts[metric_name] = 0\n        \n        with self.lock:\n            self.counts[metric_name] += value\n    \n    def get_count(self, metric_name):\n        \"\"\"Get current count for a metric\"\"\"\n        # BUG: Reading without lock can get inconsistent state\n        return self.counts.get(metric_name, 0)\n    \n    def reset_all(self):\n        \"\"\"Reset all counters\"\"\"\n        with self.lock:\n            self.counts = {}\n    \n    def get_top_metrics(self, n=10):\n        \"\"\"Get top N metrics by count\"\"\"\n        # BUG: Iterating over dict without lock during sorting\n        sorted_metrics = sorted(self.counts.items(), key=lambda x: x[1], reverse=True)\n        return sorted_metrics[:n]",
    "actual_issue": "Multiple race conditions: 1) Check for key existence happens outside lock in increment(), 2) get_count() reads without lock, 3) get_top_metrics() iterates over dict without lock protection, allowing concurrent modifications.",
    "failure_category": "correctness",
    "difficulty_level": "medium",
    "should_be_rejected": true
  },
  {
    "problem_id": "memory_leak_002",
    "issue_description": "Implement caching system with proper resource cleanup",
    "repo_context": "Image processing service with caching layer",
    "codex_solution": "import weakref\nfrom datetime import datetime, timedelta\n\nclass ImageCache:\n    def __init__(self, max_size=1000):\n        self.cache = {}\n        self.max_size = max_size\n        self.access_times = {}\n    \n    def store(self, image_id, image_data, metadata):\n        \"\"\"Store image in cache\"\"\"\n        # BUG: No eviction when cache is full, grows unbounded\n        self.cache[image_id] = {\n            'data': image_data,\n            'metadata': metadata,\n            'callbacks': []  # BUG: Strong references prevent GC\n        }\n        self.access_times[image_id] = datetime.now()\n    \n    def get(self, image_id):\n        \"\"\"Retrieve image from cache\"\"\"\n        if image_id in self.cache:\n            self.access_times[image_id] = datetime.now()\n            return self.cache[image_id]['data']\n        return None\n    \n    def register_callback(self, image_id, callback):\n        \"\"\"Register callback for image events\"\"\"\n        if image_id in self.cache:\n            # BUG: Storing callback creates circular reference\n            self.cache[image_id]['callbacks'].append(callback)\n    \n    def remove_old_entries(self, max_age_hours=24):\n        \"\"\"Remove entries older than max_age_hours\"\"\"\n        cutoff = datetime.now() - timedelta(hours=max_age_hours)\n        to_remove = [k for k, v in self.access_times.items() if v < cutoff]\n        \n        for key in to_remove:\n            # BUG: Removes from access_times but not from cache\n            del self.access_times[key]",
    "actual_issue": "Memory leak issues: 1) No eviction policy when max_size is reached, 2) Callbacks stored as strong references can create circular references preventing garbage collection, 3) remove_old_entries() doesn't actually remove from cache dict, only access_times.",
    "failure_category": "resource_management",
    "difficulty_level": "medium",
    "should_be_rejected": true
  },
  {
    "problem_id": "path_traversal_001",
    "issue_description": "Implement secure file access with path validation",
    "repo_context": "File server API for document management system",
    "codex_solution": "import os\n\nclass FileServer:\n    def __init__(self, base_directory):\n        self.base_dir = base_directory\n    \n    def read_file(self, filename):\n        \"\"\"Read file from server directory\"\"\"\n        # BUG: No path traversal protection\n        filepath = os.path.join(self.base_dir, filename)\n        \n        if os.path.exists(filepath):\n            with open(filepath, 'r') as f:\n                return f.read()\n        return None\n    \n    def list_files(self, subdirectory=''):\n        \"\"\"List files in directory\"\"\"\n        # BUG: Subdirectory not validated\n        target_dir = os.path.join(self.base_dir, subdirectory)\n        \n        if os.path.isdir(target_dir):\n            return os.listdir(target_dir)\n        return []\n    \n    def delete_file(self, filename):\n        \"\"\"Delete file from server\"\"\"\n        filepath = os.path.join(self.base_dir, filename)\n        \n        # BUG: No verification that resolved path is within base_dir\n        if os.path.exists(filepath):\n            os.remove(filepath)\n            return True\n        return False",
    "actual_issue": "Path traversal vulnerability - filename parameter is not validated. Attacker can use '../../../etc/passwd' to access files outside base_directory. os.path.join() doesn't prevent path traversal attacks.",
    "failure_category": "security",
    "difficulty_level": "easy",
    "should_be_rejected": true
  },
  {
    "problem_id": "float_comparison_002",
    "issue_description": "Implement price comparison logic for e-commerce system",
    "repo_context": "Shopping cart pricing engine with discount calculations",
    "codex_solution": "class PriceCalculator:\n    def __init__(self):\n        self.tax_rate = 0.08\n    \n    def calculate_total(self, items):\n        \"\"\"Calculate total price with tax\"\"\"\n        subtotal = sum(item['price'] * item['quantity'] for item in items)\n        tax = subtotal * self.tax_rate\n        return subtotal + tax\n    \n    def apply_discount(self, price, discount_percent):\n        \"\"\"Apply percentage discount to price\"\"\"\n        discount_amount = price * (discount_percent / 100)\n        return price - discount_amount\n    \n    def is_free_shipping_eligible(self, total):\n        \"\"\"Check if order qualifies for free shipping\"\"\"\n        # BUG: Direct float comparison can fail due to precision\n        return total >= 50.00\n    \n    def price_match(self, our_price, competitor_price):\n        \"\"\"Check if prices match for price matching policy\"\"\"\n        # BUG: Float equality comparison unreliable\n        if our_price == competitor_price:\n            return 0\n        elif our_price < competitor_price:\n            return -1\n        else:\n            return 1\n    \n    def validate_payment(self, cart_total, payment_amount):\n        \"\"\"Validate payment covers cart total\"\"\"\n        # BUG: Floating point arithmetic can cause issues\n        if payment_amount == cart_total:\n            return True, 0.0\n        elif payment_amount > cart_total:\n            return True, payment_amount - cart_total\n        else:\n            return False, cart_total - payment_amount",
    "actual_issue": "Floating point comparison issues - using == for float comparisons can fail due to precision errors. After multiple calculations (discounts, tax), values like 49.999999999 won't equal 50.00, causing incorrect free shipping eligibility and payment validation failures.",
    "failure_category": "edge_case_logic",
    "difficulty_level": "medium",
    "should_be_rejected": true
  },
  {
    "problem_id": "secure_hash_001",
    "issue_description": "Implement secure password hashing system",
    "repo_context": "User authentication module with proper security practices",
    "codex_solution": "import hashlib\nimport secrets\nimport hmac\n\nclass PasswordHasher:\n    def __init__(self):\n        self.pepper = secrets.token_bytes(32)\n    \n    def hash_password(self, password):\n        \"\"\"Hash password with salt using secure algorithm\"\"\"\n        salt = secrets.token_bytes(32)\n        \n        # Using PBKDF2 with high iteration count\n        pwd_hash = hashlib.pbkdf2_hmac(\n            'sha256',\n            password.encode('utf-8'),\n            salt,\n            iterations=100000\n        )\n        \n        # Store salt with hash\n        return salt.hex() + ':' + pwd_hash.hex()\n    \n    def verify_password(self, password, stored_hash):\n        \"\"\"Verify password against stored hash\"\"\"\n        try:\n            salt_hex, hash_hex = stored_hash.split(':')\n            salt = bytes.fromhex(salt_hex)\n            stored_pwd_hash = bytes.fromhex(hash_hex)\n            \n            pwd_hash = hashlib.pbkdf2_hmac(\n                'sha256',\n                password.encode('utf-8'),\n                salt,\n                iterations=100000\n            )\n            \n            # Constant-time comparison to prevent timing attacks\n            return hmac.compare_digest(pwd_hash, stored_pwd_hash)\n        except (ValueError, AttributeError):\n            return False\n    \n    def update_password(self, user_id, old_password, new_password):\n        \"\"\"Update user password after verification\"\"\"\n        # This would integrate with database\n        # Proper implementation with verification\n        return self.hash_password(new_password)",
    "actual_issue": "None - This is secure code. Uses PBKDF2 with appropriate iterations, generates cryptographically secure random salts, uses constant-time comparison to prevent timing attacks, and properly encodes/decodes data.",
    "failure_category": "security",
    "difficulty_level": "medium",
    "should_be_rejected": false
  },
  {
    "problem_id": "n_plus_one_query_001",
    "issue_description": "Optimize database queries for blog post listing",
    "repo_context": "Blog application with posts, authors, and comments",
    "codex_solution": "class BlogService:\n    def __init__(self, db_connection):\n        self.db = db_connection\n    \n    def get_recent_posts_with_details(self, limit=10):\n        \"\"\"Get recent posts with author and comment count\"\"\"\n        cursor = self.db.cursor()\n        \n        # BUG: N+1 query problem - one query for posts, then N queries for details\n        cursor.execute(\n            \"SELECT id, title, content, author_id, created_at FROM posts \"\n            \"ORDER BY created_at DESC LIMIT ?\",\n            (limit,)\n        )\n        posts = cursor.fetchall()\n        \n        result = []\n        for post in posts:\n            # BUG: Separate query for each author\n            cursor.execute(\n                \"SELECT username, email FROM users WHERE id = ?\",\n                (post[3],)\n            )\n            author = cursor.fetchone()\n            \n            # BUG: Separate query for each post's comment count\n            cursor.execute(\n                \"SELECT COUNT(*) FROM comments WHERE post_id = ?\",\n                (post[0],)\n            )\n            comment_count = cursor.fetchone()[0]\n            \n            result.append({\n                'id': post[0],\n                'title': post[1],\n                'content': post[2],\n                'author': author[0] if author else 'Unknown',\n                'comment_count': comment_count,\n                'created_at': post[4]\n            })\n        \n        return result\n    \n    def get_post_tags(self, post_ids):\n        \"\"\"Get tags for multiple posts\"\"\"\n        # BUG: Another N+1 - separate query per post\n        tags_by_post = {}\n        cursor = self.db.cursor()\n        \n        for post_id in post_ids:\n            cursor.execute(\n                \"SELECT tag_name FROM post_tags WHERE post_id = ?\",\n                (post_id,)\n            )\n            tags_by_post[post_id] = [row[0] for row in cursor.fetchall()]\n        \n        return tags_by_post",
    "actual_issue": "N+1 query problem causing severe performance degradation. For 10 posts, executes 1 + 10 + 10 = 21 queries instead of using JOINs or IN clauses. Should use JOIN for authors and aggregate for comment counts in single query, and WHERE IN clause for tags.",
    "failure_category": "performance",
    "difficulty_level": "medium",
    "should_be_rejected": true
  },
  {
    "problem_id": "context_manager_001",
    "issue_description": "Implement database connection pool with proper resource management",
    "repo_context": "Database connection pooling for web application",
    "codex_solution": "import threading\nimport queue\nimport time\n\nclass ConnectionPool:\n    def __init__(self, create_connection, max_connections=10):\n        self.create_connection = create_connection\n        self.max_connections = max_connections\n        self.pool = queue.Queue(maxsize=max_connections)\n        self.active_connections = 0\n        self.lock = threading.Lock()\n    \n    def get_connection(self):\n        \"\"\"Get connection from pool\"\"\"\n        try:\n            # Try to get existing connection from pool\n            return self.pool.get_nowait()\n        except queue.Empty:\n            with self.lock:\n                if self.active_connections < self.max_connections:\n                    self.active_connections += 1\n                    return self.create_connection()\n                else:\n                    # Wait for available connection\n                    return self.pool.get(timeout=30)\n    \n    def return_connection(self, connection):\n        \"\"\"Return connection to pool\"\"\"\n        try:\n            self.pool.put_nowait(connection)\n        except queue.Full:\n            # Pool is full, close connection\n            connection.close()\n            with self.lock:\n                self.active_connections -= 1\n    \n    def __enter__(self):\n        \"\"\"Context manager entry\"\"\"\n        self.connection = self.get_connection()\n        return self.connection\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit\"\"\"\n        if self.connection:\n            self.return_connection(self.connection)\n        return False\n    \n    def close_all(self):\n        \"\"\"Close all connections in pool\"\"\"\n        while not self.pool.empty():\n            try:\n                conn = self.pool.get_nowait()\n                conn.close()\n            except queue.Empty:\n                break\n        self.active_connections = 0",
    "actual_issue": "None - This is correct code. Properly implements context manager protocol, uses thread-safe queue for connection pooling, correctly manages connection lifecycle with locks, handles exceptions, and provides cleanup method.",
    "failure_category": "resource_management",
    "difficulty_level": "hard",
    "should_be_rejected": false
  },
  {
    "problem_id": "unicode_handling_001",
    "issue_description": "Fix string processing to handle unicode correctly",
    "repo_context": "Text processing utility for internationalized content",
    "codex_solution": "class TextProcessor:\n    def __init__(self):\n        self.max_length = 100\n    \n    def truncate_text(self, text, max_chars=None):\n        \"\"\"Truncate text to maximum length\"\"\"\n        limit = max_chars or self.max_length\n        \n        # BUG: Counts bytes not characters for unicode strings\n        if len(text.encode('utf-8')) > limit:\n            truncated = text.encode('utf-8')[:limit].decode('utf-8', errors='ignore')\n            return truncated + '...'\n        return text\n    \n    def normalize_whitespace(self, text):\n        \"\"\"Normalize whitespace in text\"\"\"\n        # BUG: Only handles ASCII space, not unicode whitespace\n        return ' '.join(text.split())\n    \n    def count_words(self, text):\n        \"\"\"Count words in text\"\"\"\n        # BUG: Simple split doesn't handle unicode word boundaries\n        return len(text.split())\n    \n    def validate_username(self, username):\n        \"\"\"Validate username contains only allowed characters\"\"\"\n        # BUG: Doesn't account for unicode characters\n        if len(username) < 3 or len(username) > 20:\n            return False\n        \n        # BUG: isalnum() allows unicode letters but comment suggests ASCII only\n        # Should use ASCII-only check if that's the intent\n        return username.isalnum()\n    \n    def create_slug(self, title):\n        \"\"\"Create URL slug from title\"\"\"\n        # BUG: Doesn't handle non-ASCII characters properly\n        slug = title.lower().replace(' ', '-')\n        # Only removes some punctuation, not unicode variants\n        for char in '!@#$%^&*()+={}[]|\\\\:;\",.<>?/':\n            slug = slug.replace(char, '')\n        return slug",
    "actual_issue": "Multiple unicode handling bugs: 1) truncate_text() counts bytes not characters, can split multi-byte characters, 2) normalize_whitespace() only handles ASCII space, 3) count_words() doesn't handle unicode word boundaries, 4) create_slug() doesn't handle non-ASCII characters, should use unidecode or similar.",
    "failure_category": "edge_case_logic",
    "difficulty_level": "medium",
    "should_be_rejected": true
  },
  {
    "problem_id": "async_timeout_001",
    "issue_description": "Implement async HTTP client with proper timeout and error handling",
    "repo_context": "Async HTTP client for microservices communication",
    "codex_solution": "import asyncio\nimport aiohttp\nfrom typing import Optional, Dict, Any\n\nclass AsyncHTTPClient:\n    def __init__(self, base_url: str, timeout: int = 30):\n        self.base_url = base_url\n        self.timeout = aiohttp.ClientTimeout(total=timeout)\n        self.session: Optional[aiohttp.ClientSession] = None\n    \n    async def __aenter__(self):\n        \"\"\"Async context manager entry\"\"\"\n        self.session = aiohttp.ClientSession(\n            base_url=self.base_url,\n            timeout=self.timeout\n        )\n        return self\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit\"\"\"\n        if self.session:\n            await self.session.close()\n        return False\n    \n    async def get(self, endpoint: str, params: Optional[Dict] = None) -> Dict[str, Any]:\n        \"\"\"Make GET request with proper error handling\"\"\"\n        if not self.session:\n            raise RuntimeError(\"Client not initialized. Use async with context manager.\")\n        \n        try:\n            async with self.session.get(endpoint, params=params) as response:\n                response.raise_for_status()\n                return await response.json()\n        except asyncio.TimeoutError:\n            raise TimeoutError(f\"Request to {endpoint} timed out\")\n        except aiohttp.ClientError as e:\n            raise ConnectionError(f\"Request failed: {str(e)}\")\n    \n    async def post(self, endpoint: str, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Make POST request with retry logic\"\"\"\n        if not self.session:\n            raise RuntimeError(\"Client not initialized. Use async with context manager.\")\n        \n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                async with self.session.post(endpoint, json=data) as response:\n                    response.raise_for_status()\n                    return await response.json()\n            except (asyncio.TimeoutError, aiohttp.ClientError) as e:\n                if attempt == max_retries - 1:\n                    raise\n                await asyncio.sleep(2 ** attempt)  # Exponential backoff",
    "actual_issue": "None - This is correct async code. Properly implements async context manager, handles timeouts with aiohttp.ClientTimeout, includes proper error handling and retry logic with exponential backoff, validates session state, and cleans up resources.",
    "failure_category": "correctness",
    "difficulty_level": "hard",
    "should_be_rejected": false
  }
]