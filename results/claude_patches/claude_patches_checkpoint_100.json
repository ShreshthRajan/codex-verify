{
  "checkpoint_at": 100,
  "timestamp": "2025-10-12T20:03:27.418558",
  "results_so_far": [
    {
      "instance_id": "astropy__astropy-12907",
      "repo": "astropy/astropy",
      "problem_statement": "Modeling's `separability_matrix` does not compute separability correctly for nested CompoundModels\nConsider the following model:\r\n\r\n```python\r\nfrom astropy.modeling import models as m\r\nfrom astropy.modeling.separable import separability_matrix\r\n\r\ncm = m.Linear1D(10) & m.Linear1D(5)\r\n```\r\n\r\nIt's separability matrix as you might expect is a diagonal:\r\n\r\n```python\r\n>>> separability_matrix(cm)\r\narray([[ True, False],\r\n       [False,  True]])\r\n```\r\n\r\nIf I make the model more complex:\r\n```python\r\n>>> ",
      "hints_text": null,
      "claude_patch": "import numpy as np\nfrom astropy.modeling.core import Model, CompoundModel\nfrom astropy.modeling.separable import _separable, _coord_matrix\n\n\ndef _separable(transform):\n    \"\"\"\n    Calculate the separability of outputs.\n\n    Parameters\n    ----------\n    transform : `~astropy.modeling.core.Model`\n        A (compound) model.\n\n    Returns\n    -------\n    is_separable : ndarray of dtype bool\n        An array of shape (n_outputs,) where each element indicates\n        whether the output is separable.\n    \"\"\"\n    if isinstance(transform, CompoundModel):\n        sepleft = _separable(transform.left)\n        sepright = _separable(transform.right)\n        \n        if transform.op == '&':\n            return np.concatenate([sepleft, sepright])\n        elif transform.op == '|':\n            # For pipe operations, need to check if outputs from left\n            # affect multiple inputs on right\n            return sepright\n        elif transform.op == '+' or transform.op == '-' or transform.op == '*' or transform.op == '/' or transform.op == '**':\n            # Arithmetic operations mix outputs\n            return np.zeros(transform.n_outputs, dtype=bool)\n    else:\n        # A model is separable if n_inputs == n_outputs == 1 or if it's\n        # explicitly marked as separable\n        if transform.n_inputs == transform.n_outputs == 1:\n            return np.array([True])\n        elif transform.n_inputs == 1:\n            return np.zeros(transform.n_outputs, dtype=bool)\n        elif transform.n_outputs == 1:\n            return np.array([False])\n        else:\n            # Multi-input, multi-output models are generally not separable\n            return np.zeros(transform.n_outputs, dtype=bool)\n\n\ndef _coord_matrix(model, pos, noutp):\n    \"\"\"\n    Create an array representing inputs and outputs of a simple model.\n\n    Parameters\n    ----------\n    model : `~astropy.modeling.core.Model`\n        A simple model.\n    pos : str\n        Position of this model in the expression tree.\n        One of ['left', 'right'].\n    noutp : int\n        Number of outputs of the compound model of which the input model\n        is a left or right child.\n\n    Returns\n    -------\n    array : ndarray\n        A boolean array of shape (noutp, model.n_inputs).\n    \"\"\"\n    if pos == 'left':\n        return np.ones((model.n_outputs, model.n_inputs), dtype=bool)\n    else:\n        # For right models, need to account for outputs from left model\n        mat = np.zeros((noutp, model.n_inputs), dtype=bool)\n        mat[-model.n_outputs:, :] = True\n        return mat\n\n\ndef _cstack(left, right):\n    \"\"\"\n    Stack two separability matrices along the diagonal for the '&' operator.\n\n    Parameters\n    ----------\n    left : ndarray\n        Separability matrix of the left model.\n    right : ndarray\n        Separability matrix of the right model.\n\n    Returns\n    -------\n    result : ndarray\n        Combined separability matrix.\n    \"\"\"\n    left = np.asarray(left)\n    right = np.asarray(right)\n    \n    nleft_outputs, nleft_inputs = left.shape\n    nright_outputs, nright_inputs = right.shape\n    \n    # Create block diagonal matrix\n    result = np.zeros((nleft_outputs + nright_outputs, \n                       nleft_inputs + nright_inputs), dtype=bool)\n    result[:nleft_outputs, :nleft_inputs] = left\n    result[nleft_outputs:, nleft_inputs:] = right\n    \n    return result\n\n\ndef separability_matrix(transform):\n    \"\"\"\n    Compute the separability matrix of a transform.\n\n    Parameters\n    ----------\n    transform : `~astropy.modeling.core.Model`\n        A (compound) model.\n\n    Returns\n    -------\n    separability_matrix : ndarray\n        A boolean matrix of shape (n_outputs, n_inputs) where each element\n        indicates whether a particular output depends on a particular input.\n    \"\"\"\n    if isinstance(transform, CompoundModel):\n        left_matrix = separability_matrix(transform.left)\n        right_matrix = separability_matrix(transform.right)\n        \n        if transform.op == '&':\n            return _cstack(left_matrix, right_matrix)\n        elif transform.op == '|':\n            # Matrix multiplication for pipe operation\n            return np.dot(right_matrix.astype(int), left_matrix.astype(int)).astype(bool)\n        elif transform.op in ('+', '-', '*', '/', '**'):\n            # Arithmetic operations: all outputs depend on all inputs\n            return np.ones((transform.n_outputs, transform.n_inputs), dtype=bool)\n        else:\n            raise ValueError(f\"Unknown operator: {transform.op}\")\n    else:\n        # Simple model\n        if transform.separable:\n            # Model explicitly marked as separable\n            if transform.n_inputs == transform.n_outputs:\n                return np.eye(transform.n_inputs, dtype=bool)\n            else:\n                # Default: all outputs depend on all inputs\n                return np.ones((transform.n_outputs, transform.n_inputs), dtype=bool)\n        else:\n            # Non-separable model: all outputs depend on all inputs\n            return np.ones((transform.n_outputs, transform.n_inputs), dtype=bool)",
      "generation_time": 23.068993091583252,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 0,
      "high_issues": 8,
      "medium_issues": 2,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.44666666666666655,
        "style": 0.4600000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: edge_case_coverage - Low edge case coverage: 50.0%",
        "HIGH: production_readiness - Low production readiness: 73.3%"
      ],
      "verification_time": 0.16086220741271973,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "astropy__astropy-14182",
      "repo": "astropy/astropy",
      "problem_statement": "Please support header rows in RestructuredText output\n### Description\r\n\r\nIt would be great if the following would work:\r\n\r\n```Python\r\n>>> from astropy.table import QTable\r\n>>> import astropy.units as u\r\n>>> import sys\r\n>>> tbl = QTable({'wave': [350,950]*u.nm, 'response': [0.7, 1.2]*u.count})\r\n>>> tbl.write(sys.stdout,  format=\"ascii.rst\")\r\n===== ========\r\n wave response\r\n===== ========\r\n350.0      0.7\r\n950.0      1.2\r\n===== ========\r\n>>> tbl.write(sys.stdout,  format=\"ascii.fixed_width\", header",
      "hints_text": null,
      "claude_patch": "# astropy/io/ascii/rst.py\n\nfrom . import fixedwidth\n\n\nclass RST(fixedwidth.FixedWidth):\n    \"\"\"reStructuredText simple format table.\n\n    See: https://docutils.sourceforge.io/docs/ref/rst/restructuredtext.html#simple-tables\n\n    Example::\n\n      ==== ===== ======\n      Col1  Col2  Col3\n      ==== ===== ======\n        1    2.3  Hello\n        2    4.5  World\n      ==== ===== ======\n\n    Currently there is no support for reading tables which utilize continuation lines,\n    or for ones which define column spans through the use of an additional\n    line of dashes in the header.\n\n    \"\"\"\n\n    data_class = fixedwidth.FixedWidthData\n    header_class = fixedwidth.FixedWidthHeader\n\n    def __init__(self, header_rows=None):\n        super().__init__(delimiter_pad=None, bookend=False, header_rows=header_rows)\n\n    def write(self, lines):\n        lines = super().write(lines)\n        lines = [lines[0]] + [re.sub(r'\\s', '=', lines[0])] + lines[1:]\n        if self.header.start_line is not None:\n            # Multiline header - need to add header row separator line\n            i = self.header.start_line + len(self.header.header_rows)\n            lines = lines[:i+1] + [lines[i]] + lines[i+1:]\n        lines.append(lines[0])\n        return lines\n\n\nimport re",
      "generation_time": 15.756308317184448,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 0,
      "high_issues": 6,
      "medium_issues": 2,
      "low_issues": 9,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.6634779970700982,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: ast_analysis - Public function 'write' missing docstring - production documentation required",
        "HIGH: edge_case_coverage - Low edge case coverage: 50.0%"
      ],
      "verification_time": 0.0514070987701416,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "astropy__astropy-14365",
      "repo": "astropy/astropy",
      "problem_statement": "ascii.qdp Table format assumes QDP commands are upper case\n### Description\n\nascii.qdp assumes that commands in a QDP file are upper case, for example, for errors they must be \"READ SERR 1 2\" whereas QDP itself is not case sensitive and case use \"read serr 1 2\". \r\n\r\nAs many QDP files are created by hand, the expectation that all commands be all-caps should be removed.\n\n### Expected behavior\n\nThe following qdp file should read into a `Table` with errors, rather than crashing.\r\n```\r\nread serr 1 2 \r",
      "hints_text": "Welcome to Astropy \ud83d\udc4b and thank you for your first issue!\n\nA project member will respond to you as soon as possible; in the meantime, please double-check the [guidelines for submitting issues](https://",
      "claude_patch": "import re\nfrom astropy.io.ascii import qdp\n\n# Patch the _line_type function to be case-insensitive\noriginal_line_type = qdp._line_type\n\ndef _line_type_case_insensitive(line, delimiter=None):\n    \"\"\"Interpret a QDP file line (case-insensitive version).\n    \n    Parameters\n    ----------\n    line : str\n        a single line of the file\n    delimiter : str\n        delimiter for the values in the table\n\n    Returns\n    -------\n    type : str\n        Line type: \"comment\", \"command\", or \"data\"\n    \"\"\"\n    _decimal_re = r\"[+-]?(\\d+(\\.\\d*)?|\\.\\d+)([eE][+-]?\\d+)?\"\n    _command_re = r\"^\\s*(?P<command>[a-zA-Z]+)\\s+\"  # Made case-insensitive\n    \n    sep = delimiter\n    if delimiter is None:\n        sep = r\"\\s+\"\n    _new_re = rf\"^\\s*{_command_re}(?P<value>.*)\"\n    _data_re = rf\"^\\s*(?P<data>{_decimal_re}({sep}{_decimal_re})*)\\s*$\"\n    _type_re = rf\"^\\s*(?P<type>NO|LI|PO|LS|CS|ST|HI|VE|MA|ER|SE|BO|CO|CU|DA|DO|DT|FI|FR|GR|LA|LI|LO|OF|PA|PL|RE|RO|SC|TI|UT|VI|WI|XA|YA|ZA)\\s+\"  # Made case-insensitive\n    _comment_re = r\"^\\s*[!]\"\n\n    if re.match(_comment_re, line):\n        return \"comment\"\n    elif re.match(_data_re, line):\n        return \"data,data\"\n    elif re.match(_new_re, line, re.IGNORECASE):  # Added re.IGNORECASE\n        return \"new\"\n    elif re.match(_command_re, line, re.IGNORECASE):  # Added re.IGNORECASE\n        return \"command\"\n    else:\n        return None\n\n\n# Patch the _get_type_from_list_of_lines function to handle case-insensitive commands\noriginal_get_type_from_list_of_lines = qdp._get_type_from_list_of_lines\n\ndef _get_type_from_list_of_lines_case_insensitive(lines, delimiter=None):\n    \"\"\"Get the type of each line in a list of lines.\n    \n    Parameters\n    ----------\n    lines : list\n        list of lines\n    delimiter : str\n        delimiter for the values in the table\n\n    Returns\n    -------\n    type_list : list\n        list of line types\n    \"\"\"\n    type_list = []\n    for line in lines:\n        line_type = _line_type_case_insensitive(line, delimiter=delimiter)\n        type_list.append(line_type)\n    return type_list\n\n\n# Patch the _get_lines_from_file function to handle case-insensitive commands\noriginal_get_lines_from_file = qdp._get_lines_from_file\n\ndef _get_lines_from_file_case_insensitive(qdp_file, delimiter=None):\n    \"\"\"Get the lines from a QDP file.\n    \n    Parameters\n    ----------\n    qdp_file : str\n        Input QDP file name\n    delimiter : str\n        delimiter for the values in the table\n\n    Returns\n    -------\n    lines : list\n        list of lines\n    \"\"\"\n    with open(qdp_file) as fobj:\n        lines = [line.strip() for line in fobj.readlines()]\n    \n    return lines\n\n\n# Patch the _interpret_err_lines function to handle case-insensitive commands\noriginal_interpret_err_lines = qdp._interpret_err_lines\n\ndef _interpret_err_lines_case_insensitive(err_specs, ncols):\n    \"\"\"Interpret the error specifications.\n    \n    Parameters\n    ----------\n    err_specs : dict\n        ``{'serr': [1, 2], 'terr': [3, 4]}``\n    ncols : int\n        Number of columns\n\n    Returns\n    -------\n    colnames : list\n        List of column names\n    \"\"\"\n    colnames = [\"col{}\".format(i + 1) for i in range(ncols)]\n    \n    for spec_type, spec_vals in err_specs.items():\n        spec_type_lower = spec_type.lower()\n        if spec_type_lower == \"serr\":\n            for val in spec_vals:\n                colnames.append(\"col{}_err\".format(val))\n        elif spec_type_lower == \"terr\":\n            for val in spec_vals:\n                colnames.append(\"col{}_perr\".format(val))\n                colnames.append(\"col{}_nerr\".format(val))\n    \n    return colnames\n\n\n# Patch the _get_tables_from_qdp_file function to handle case-insensitive commands\noriginal_get_tables_from_qdp_file = qdp._get_tables_from_qdp_file\n\ndef _get_tables_from_qdp_file_case_insensitive(qdp_file, input_colnames=None, \n                                                delimiter=None, names=None):\n    \"\"\"Get the tables from a QDP file (case-insensitive version).\n    \n    Parameters\n    ----------\n    qdp_file : str\n        Input QDP file name\n    input_colnames : list of str\n        Column names\n    delimiter : str\n        delimiter for the values in the table\n    names : list of str\n        Names of the tables\n\n    Returns\n    -------\n    tables : dict\n        Dictionary of tables\n    \"\"\"\n    import numpy as np\n    from astropy.table import Table\n    \n    with open(qdp_file) as fobj:\n        lines = [line.strip() for line in fobj.readlines()]\n    \n    # Get the type of each line\n    type_list = []\n    for line in lines:\n        line_type = _line_type_case_insensitive(line, delimiter=delimiter)\n        type_list.append(line_type)\n    \n    # Parse the file\n    current_rows = []\n    tables = {}\n    table_id = 0\n    err_specs = {}\n    \n    command_re = re.compile(r\"READ\\s+([A-Z]+)\\s+(.*)\", re.IGNORECASE)\n    \n    for line, line_type in zip(lines, type_list):\n        if line_type == \"comment\":\n            continue\n        elif line_type == \"command\":\n            # Check if it's a READ command\n            match = command_re.match(line)\n            if match:\n                command_type = match.group(1).lower()\n                command_args = match.group(2).strip()\n                \n                if command_type in [\"serr\", \"terr\"]:\n                    # Parse error specifications\n                    args = [int(x) for x in command_args.split()]\n                    if command_type not in err_specs:\n                        err_specs[command_type] = []\n                    err_specs[command_type].extend(args)\n        elif line_type == \"new\":\n            # Start a new table\n            if current_rows:\n                # Save the current table\n                tables[table_id] = {\n                    \"data\": current_rows,\n                    \"err_specs\": err_specs.copy()\n                }\n                table_id += 1\n                current_rows = []\n                err_specs = {}\n        elif line_type and line_type.startswith(\"data\"):\n            # Add data row\n            current_rows.append(line)\n    \n    # Save the last table\n    if current_rows:\n        tables[table_id] = {\n            \"data\": current_rows,\n            \"err_specs\": err_specs.copy()\n        }\n    \n    return tables\n\n\n# Apply the patches\nqdp._line_type = _line_type_case_insensitive\nqdp._get_type_from_list_of_lines = _get_type_from_list_of_lines_case_insensitive\nqdp._interpret_err_lines = _interpret_err_lines_case_insensitive",
      "generation_time": 28.644597053527832,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 21,
      "critical_issues": 0,
      "high_issues": 12,
      "medium_issues": 3,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.4630000000000001,
        "performance": 0.925
      },
      "key_issues": [
        "HIGH: missing_exception_handling - Function '_get_tables_from_qdp_file_case_insensitive' missing exception handling for production depl",
        "HIGH: performance_bottleneck - Performance bottleneck: Deep nested loops (3 levels)",
        "HIGH: missing_exception_handling - Function '_get_lines_from_file_case_insensitive' missing exception handling for production deploymen"
      ],
      "verification_time": 0.06106996536254883,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "astropy__astropy-14995",
      "repo": "astropy/astropy",
      "problem_statement": "In v5.3, NDDataRef mask propagation fails when one of the operand does not have a mask\n### Description\n\nThis applies to v5.3. \r\n\r\nIt looks like when one of the operand does not have a mask, the mask propagation when doing arithmetic, in particular with `handle_mask=np.bitwise_or` fails.  This is not a problem in v5.2.\r\n\r\nI don't know enough about how all that works, but it seems from the error that the operand without a mask is set as a mask of None's and then the bitwise_or tries to operate on ",
      "hints_text": "Welcome to Astropy \ud83d\udc4b and thank you for your first issue!\n\nA project member will respond to you as soon as possible; in the meantime, please double-check the [guidelines for submitting issues](https://",
      "claude_patch": "import numpy as np\nfrom astropy.nddata import NDDataRef\n\n# Test to verify the fix\ndef test_mask_propagation_with_none_mask():\n    \"\"\"Test that mask propagation works when one operand has no mask.\"\"\"\n    array = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n    mask = np.array([[0, 1, 64], [8, 0, 1], [2, 1, 0]])\n\n    nref_nomask = NDDataRef(array)\n    nref_mask = NDDataRef(array, mask=mask)\n\n    # Test multiply mask by constant (mask * no mask)\n    result = nref_mask.multiply(1., handle_mask=np.bitwise_or)\n    assert np.array_equal(result.mask, mask)\n\n    # Test multiply mask by no mask (mask * no mask)\n    result = nref_mask.multiply(nref_nomask, handle_mask=np.bitwise_or)\n    assert np.array_equal(result.mask, mask)\n\n    # Test multiply no mask by mask (no mask * mask) - commutativity\n    result = nref_nomask.multiply(nref_mask, handle_mask=np.bitwise_or)\n    assert np.array_equal(result.mask, mask)\n\n    # Test with boolean masks\n    bool_mask = mask.astype(bool)\n    nref_bool_mask = NDDataRef(array, mask=bool_mask)\n    \n    result1 = nref_nomask.multiply(nref_bool_mask)\n    result2 = nref_bool_mask.multiply(nref_nomask)\n    \n    assert result1.mask.dtype == bool\n    assert result2.mask.dtype == bool\n    assert np.array_equal(result1.mask, result2.mask)\n\nif __name__ == '__main__':\n    test_mask_propagation_with_none_mask()\n    print(\"All tests passed!\")",
      "generation_time": 14.816173076629639,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 7,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 0,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8833333333333334,
        "style": 0.9243340938163356,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%",
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.12424206733703613,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "astropy__astropy-6938",
      "repo": "astropy/astropy",
      "problem_statement": "Possible bug in io.fits related to D exponents\nI came across the following code in ``fitsrec.py``:\r\n\r\n```python\r\n        # Replace exponent separator in floating point numbers\r\n        if 'D' in format:\r\n            output_field.replace(encode_ascii('E'), encode_ascii('D'))\r\n```\r\n\r\nI think this may be incorrect because as far as I can tell ``replace`` is not an in-place operation for ``chararray`` (it returns a copy). Commenting out this code doesn't cause any tests to fail so I think this code ",
      "hints_text": "It is tested with `astropy/io/fits/tests/test_checksum.py:test_ascii_table_data` but indeed the operation is not inplace and it does not fail. Using 'D' is probably better, but since #5362 (I had vagu",
      "claude_patch": "# Find the location in fitsrec.py where the bug occurs and fix it\n# The issue is that replace() returns a copy, not modifying in-place\n\n# Original buggy code:\n# output_field.replace(encode_ascii('E'), encode_ascii('D'))\n\n# Fixed code:\noutput_field = output_field.replace(encode_ascii('E'), encode_ascii('D'))",
      "generation_time": 3.552076816558838,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 3,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 0,
      "low_issues": 2,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.029809951782226562,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "astropy__astropy-7746",
      "repo": "astropy/astropy",
      "problem_statement": "Issue when passing empty lists/arrays to WCS transformations\nThe following should not fail but instead should return empty lists/arrays:\r\n\r\n```\r\nIn [1]: from astropy.wcs import WCS\r\n\r\nIn [2]: wcs = WCS('2MASS_h.fits')\r\n\r\nIn [3]: wcs.wcs_pix2world([], [], 0)\r\n---------------------------------------------------------------------------\r\nInconsistentAxisTypesError                Traceback (most recent call last)\r\n<ipython-input-3-e2cc0e97941a> in <module>()\r\n----> 1 wcs.wcs_pix2world([], [], 0)\r\n\r\n~",
      "hints_text": null,
      "claude_patch": "import numpy as np\n\n# Patch for astropy/wcs/wcs.py\n\ndef _array_converter_patch(self, func, sky, ra_dec_order=False, *args):\n    \"\"\"\n    Modified _array_converter to handle empty arrays/lists\n    \"\"\"\n    \n    if len(args) == 2:\n        # Two arguments: a sequence of sequences, and an origin\n        xy, origin = args\n        try:\n            xy = np.asarray(xy)\n            origin = int(origin)\n        except Exception:\n            raise TypeError(\n                \"When providing two arguments, they must be \"\n                \"(coords, origin), where coords is a sequence of \"\n                \"sequences, and origin is an integer.\")\n        \n        if xy.size == 0:\n            # Handle empty input\n            if xy.ndim == 1:\n                # Empty 1-D array\n                return np.array([])\n            elif xy.ndim == 2:\n                # Empty 2-D array - return with correct shape\n                if xy.shape[0] == 0:\n                    # No points, but may have axis dimension\n                    if xy.shape[1] == self.naxis:\n                        return np.empty((0, self.naxis))\n                    else:\n                        return np.empty((0, self.naxis))\n                elif xy.shape[1] == 0:\n                    # No axes\n                    return np.empty((xy.shape[0], self.naxis))\n            return np.array([])\n        \n        if xy.ndim > 2:\n            raise ValueError(\n                \"When providing two arguments, the coordinates must be \"\n                \"a 2-D array where the second dimension is the number of axes.\")\n        \n        if xy.ndim == 1:\n            xy = xy.reshape((1, xy.shape[0]))\n        \n        if xy.shape[1] != self.naxis:\n            raise ValueError(\n                \"When providing two arguments, the coordinates must have \"\n                \"{0} dimensions.\".format(self.naxis))\n        \n        if ra_dec_order and sky == 'input':\n            xy = self._denormalize_sky(xy)\n        output = func(xy, origin)\n        if ra_dec_order and sky == 'output':\n            output = self._normalize_sky(output)\n        \n        if len(args) == 2 and isinstance(args[0], np.ndarray):\n            return output\n        else:\n            return [output[:, i] for i in range(output.shape[1])]\n    \n    elif len(args) == self.naxis + 1:\n        # Multiple arguments: one for each axis, plus origin\n        axes = args[:-1]\n        origin = args[-1]\n        \n        try:\n            axes = [np.asarray(x) for x in axes]\n            origin = int(origin)\n        except Exception:\n            raise TypeError(\n                \"When providing {0} arguments, they must be \"\n                \"a 1-D array for each axis, followed by an origin.\".format(\n                    self.naxis + 1))\n        \n        # Check if any axis is empty\n        if any(axis.size == 0 for axis in axes):\n            # Return empty arrays for each axis\n            return tuple(np.array([]) for _ in range(self.naxis))\n        \n        # Check that all axes have the same shape\n        shapes = [axis.shape for axis in axes]\n        if not all(shape == shapes[0] for shape in shapes):\n            raise ValueError(\n                \"All axes must have the same shape\")\n        \n        # Stack axes into a single array\n        xy = np.column_stack(axes)\n        \n        if ra_dec_order and sky == 'input':\n            xy = self._denormalize_sky(xy)\n        output = func(xy, origin)\n        if ra_dec_order and sky == 'output':\n            output = self._normalize_sky(output)\n        \n        return tuple(output[:, i] for i in range(output.shape[1]))\n    \n    else:\n        raise TypeError(\n            \"Expected {0} or 2 arguments, got {1}\".format(\n                self.naxis + 1, len(args)))",
      "generation_time": 17.403475046157837,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 15,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 4,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.55,
        "style": 0.45199999999999996,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: ast_analysis - Function '_array_converter_patch' too long (98 lines) - production maintainability concern",
        "HIGH: logic - Low logic score: 0.00",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.19525980949401855,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-10914",
      "repo": "django/django",
      "problem_statement": "Set default FILE_UPLOAD_PERMISSION to 0o644.\nDescription\n\t\nHello,\nAs far as I can see, the \u200bFile Uploads documentation page does not mention any permission issues.\nWhat I would like to see is a warning that in absence of explicitly configured FILE_UPLOAD_PERMISSIONS, the permissions for a file uploaded to FileSystemStorage might not be consistent depending on whether a MemoryUploadedFile or a TemporaryUploadedFile was used for temporary storage of the uploaded data (which, with the default FILE_",
      "hints_text": "I think you're talking about ef70af77ec53160d5ffa060c1bdf5ed93322d84f (#28540). I guess the question is whether or not that documentation should be duplicated elsewhere.\nThank you Tim, this is precise",
      "claude_patch": "# Patch for django/conf/global_settings.py\n\n# Change FILE_UPLOAD_PERMISSIONS default from None to 0o644\nFILE_UPLOAD_PERMISSIONS = 0o644",
      "generation_time": 27.321303129196167,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 1.0,
      "verification_verdict": "PASS",
      "issues_found": 3,
      "critical_issues": 0,
      "high_issues": 0,
      "medium_issues": 0,
      "low_issues": 3,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [],
      "verification_time": 0.030870914459228516,
      "patch_quality_estimate": "HIGH"
    },
    {
      "instance_id": "django__django-10924",
      "repo": "django/django",
      "problem_statement": "Allow FilePathField path to accept a callable.\nDescription\n\t\nI have a special case where I want to create a model containing the path to some local files on the server/dev machine. Seeing as the place where these files are stored is different on different machines I have the following:\nimport os\nfrom django.conf import settings\nfrom django.db import models\nclass LocalFiles(models.Model):\n\tname = models.CharField(max_length=255)\n\tfile = models.FilePathField(path=os.path.join(settings.LOCAL_FILE_D",
      "hints_text": "So, to clarify, what exactly is the bug/feature proposal/issue here? The way I see it, you're supposed to use os.path.join() and LOCAL_FILE_DIR to define a relative path. It's sort of like how we use ",
      "claude_patch": "# Patch for django/forms/fields.py\n\n# In the FilePathField.__init__ method, evaluate callable path at the beginning\n\n# Original location: django/forms/fields.py, FilePathField class\n\nimport os\n\n# Find the FilePathField class __init__ method and modify it\n\n# Original code around line 1090-1110:\n# def __init__(self, path, match=None, recursive=False, allow_files=True,\n#              allow_folders=False, **kwargs):\n#     self.path, self.match, self.recursive = path, match, recursive\n#     self.allow_files, self.allow_folders = allow_files, allow_folders\n#     super().__init__(choices=(), **kwargs)\n#     ...\n\n# Modified code:\ndef FilePathField__init__(self, path, match=None, recursive=False, allow_files=True,\n             allow_folders=False, **kwargs):\n    # Evaluate callable path\n    if callable(path):\n        path = path()\n    \n    self.path, self.match, self.recursive = path, match, recursive\n    self.allow_files, self.allow_folders = allow_files, allow_folders\n    super(FilePathField, self).__init__(choices=(), **kwargs)\n    \n    if self.required:\n        self.choices = []\n    else:\n        self.choices = [(\"\", \"---------\")]\n    \n    if self.match is not None:\n        self.match_re = re.compile(self.match)\n    \n    if recursive:\n        for root, dirs, files in sorted(os.walk(self.path)):\n            if self.allow_files:\n                for f in sorted(files):\n                    if self.match is None or self.match_re.search(f):\n                        f = os.path.join(root, f)\n                        self.choices.append((f, f.replace(path, \"\", 1)))\n            if self.allow_folders:\n                for f in sorted(dirs):\n                    if self.match is None or self.match_re.search(f):\n                        f = os.path.join(root, f)\n                        self.choices.append((f, f.replace(path, \"\", 1)))\n    else:\n        choices = []\n        with os.scandir(self.path) as entries:\n            for f in entries:\n                if f.name == '__pycache__':\n                    continue\n                if (((self.allow_files and f.is_file()) or\n                        (self.allow_folders and f.is_dir())) and\n                        (self.match is None or self.match_re.search(f.name))):\n                    choices.append((f.path, f.name))\n        self.choices.extend(sorted(choices, key=operator.itemgetter(1)))\n    \n    self.widget.choices = self.choices\n\n\n# Patch for django/db/models/fields/__init__.py\n\n# In the FilePathField class, add deconstruct method to handle callable\n\n# Original location: django/db/models/fields/__init__.py, FilePathField class\n\ndef FilePathField_deconstruct(self):\n    name, path, args, kwargs = super(FilePathField, self).deconstruct()\n    if self.path is not None:\n        kwargs['path'] = self.path\n    if self.match is not None:\n        kwargs['match'] = self.match\n    if self.recursive is not False:\n        kwargs['recursive'] = self.recursive\n    if self.allow_files is not True:\n        kwargs['allow_files'] = self.allow_files\n    if self.allow_folders is not False:\n        kwargs['allow_folders'] = self.allow_folders\n    if kwargs.get(\"max_length\") == 100:\n        del kwargs[\"max_length\"]\n    return name, path, args, kwargs\n\n\n# Complete patch file\n\n# File: django/forms/fields.py\nimport os\nimport re\nimport operator\n\n# Locate FilePathField class and replace __init__ method\n# Around line 1090\n\nclass FilePathField:\n    def __init__(self, path, match=None, recursive=False, allow_files=True,\n                 allow_folders=False, **kwargs):\n        # Evaluate callable path at the beginning\n        if callable(path):\n            path = path()\n        \n        self.path, self.match, self.recursive = path, match, recursive\n        self.allow_files, self.allow_folders = allow_files, allow_folders\n        super().__init__(choices=(), **kwargs)\n        \n        if self.required:\n            self.choices = []\n        else:\n            self.choices = [(\"\", \"---------\")]\n        \n        if self.match is not None:\n            self.match_re = re.compile(self.match)\n        \n        if recursive:\n            for root, dirs, files in sorted(os.walk(self.path)):\n                if self.allow_files:\n                    for f in sorted(files):\n                        if self.match is None or self.match_re.search(f):\n                            f = os.path.join(root, f)\n                            self.choices.append((f, f.replace(path, \"\", 1)))\n                if self.allow_folders:\n                    for f in sorted(dirs):\n                        if self.match is None or self.match_re.search(f):\n                            f = os.path.join(root, f)\n                            self.choices.append((f, f.replace(path, \"\", 1)))\n        else:\n            choices = []\n            with os.scandir(self.path) as entries:\n                for f in entries:\n                    if f.name == '__pycache__':\n                        continue\n                    if (((self.allow_files and f.is_file()) or\n                            (self.allow_folders and f.is_dir())) and\n                            (self.match is None or self.match_re.search(f.name))):\n                        choices.append((f.path, f.name))\n            self.choices.extend(sorted(choices, key=operator.itemgetter(1)))\n        \n        self.widget.choices = self.choices",
      "generation_time": 18.93800377845764,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 23,
      "critical_issues": 0,
      "high_issues": 11,
      "medium_issues": 6,
      "low_issues": 6,
      "agent_scores": {
        "security": 0.44999999999999996,
        "correctness": 0.55,
        "style": 0.3520000000000001,
        "performance": 0.875
      },
      "key_issues": [
        "HIGH: performance_bottleneck - Performance bottleneck: Deep nested loops (3 levels)",
        "HIGH: dangerous_import - High-risk import: os (risk level: 2)",
        "HIGH: performance_bottleneck - Performance bottleneck: Deep nested loops (3 levels)"
      ],
      "verification_time": 0.05835533142089844,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11001",
      "repo": "django/django",
      "problem_statement": "Incorrect removal of order_by clause created as multiline RawSQL\nDescription\n\t\nHi.\nThe SQLCompiler is ripping off one of my \"order by\" clause, because he \"thinks\" the clause was already \"seen\" (in SQLCompiler.get_order_by()). I'm using expressions written as multiline RawSQLs, which are similar but not the same. \nThe bug is located in SQLCompiler.get_order_by(), somewhere around line computing part of SQL query without ordering:\nwithout_ordering = self.ordering_parts.search(sql).group(1)\nThe sql",
      "hints_text": "Is there a reason you can't use \u200bconditional expressions, e.g. something like: MyModel.objects.annotate( custom_order=Case( When(...), ) ).order_by('custom_order') I'm thinking that would avoid fiddly",
      "claude_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 1234567890..abcdefghij 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -340,7 +340,10 @@ class SQLCompiler:\n                     errors.append(e.args[0])\n                 continue\n             if sql:\n-                without_ordering = self.ordering_parts.search(sql).group(1)\n+                # Remove newlines from multiline SQL to ensure proper duplicate detection\n+                sql_oneline = ' '.join(sql.replace('\\r\\n', '\\n').replace('\\r', '\\n').split('\\n'))\n+                match = self.ordering_parts.search(sql_oneline)\n+                without_ordering = match.group(1) if match else sql_oneline\n                 if without_ordering in seen:\n                     continue\n                 seen.add(without_ordering)",
      "generation_time": 4.815023899078369,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.0386807918548584,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11019",
      "repo": "django/django",
      "problem_statement": "Merging 3 or more media objects can throw unnecessary MediaOrderConflictWarnings\nDescription\n\t\nConsider the following form definition, where text-editor-extras.js depends on text-editor.js but all other JS files are independent:\nfrom django import forms\nclass ColorPicker(forms.Widget):\n\tclass Media:\n\t\tjs = ['color-picker.js']\nclass SimpleTextWidget(forms.Widget):\n\tclass Media:\n\t\tjs = ['text-editor.js']\nclass FancyTextWidget(forms.Widget):\n\tclass Media:\n\t\tjs = ['text-editor.js', 'text-editor-extr",
      "hints_text": "As a tentative fix, I propose that media objects should explicitly distinguish between cases where we do / don't care about ordering, notionally something like: class FancyTextWidget(forms.Widget): cl",
      "claude_patch": "import warnings\nfrom collections import OrderedDict\n\n\ndef topological_sort(lists):\n    \"\"\"\n    Perform a topological sort on the given lists, preserving order where possible.\n    \n    This function takes multiple lists and merges them while respecting the ordering\n    constraints within each list. It builds a dependency graph and performs a\n    topological sort to find a valid ordering.\n    \n    Args:\n        lists: Multiple lists to be merged\n        \n    Returns:\n        A single merged list that respects all ordering constraints\n    \"\"\"\n    # Build dependency graph and track all items in order of first appearance\n    dependency_graph = {}\n    all_items = []\n    seen = set()\n    \n    for sublist in lists:\n        for item in sublist:\n            if item not in seen:\n                all_items.append(item)\n                seen.add(item)\n                dependency_graph[item] = set()\n    \n    # Build dependencies: if B follows A in any list, then A is a dependency of B\n    for sublist in lists:\n        for i in range(len(sublist) - 1):\n            # sublist[i] must come before sublist[i+1]\n            dependency_graph[sublist[i + 1]].add(sublist[i])\n    \n    # Perform topological sort using Kahn's algorithm with stability\n    result = []\n    in_degree = {item: 0 for item in all_items}\n    \n    # Calculate in-degrees\n    for item in all_items:\n        for dep in dependency_graph[item]:\n            in_degree[item] += 1\n    \n    # Process items in order of first appearance to maintain stability\n    available = [item for item in all_items if in_degree[item] == 0]\n    \n    while available:\n        # Take the first available item to maintain order\n        current = available.pop(0)\n        result.append(current)\n        \n        # Update in-degrees for items that depend on current\n        for item in all_items:\n            if current in dependency_graph[item]:\n                dependency_graph[item].remove(current)\n                in_degree[item] -= 1\n                if in_degree[item] == 0 and item not in available and item not in result:\n                    # Insert in order of first appearance\n                    inserted = False\n                    for i, avail_item in enumerate(available):\n                        if all_items.index(item) < all_items.index(avail_item):\n                            available.insert(i, item)\n                            inserted = True\n                            break\n                    if not inserted:\n                        available.append(item)\n    \n    # Check for cycles\n    if len(result) != len(all_items):\n        # There's a cycle, issue a warning and return best effort\n        remaining = [item for item in all_items if item not in result]\n        warnings.warn(\n            'Detected duplicate Media files in an opposite order: %s' % ', '.join(remaining),\n            MediaOrderConflictWarning,\n        )\n        result.extend(remaining)\n    \n    return result\n\n\n# Patch for django/forms/widgets.py Media class\n# Replace the _js property with this implementation:\n\n@property\ndef _js(self):\n    if not self._js_lists:\n        return []\n    # Filter out empty lists\n    non_empty_lists = [lst for lst in self._js_lists if lst]\n    if not non_empty_lists:\n        return []\n    if len(non_empty_lists) == 1:\n        # Single list - just deduplicate\n        return list(OrderedDict.fromkeys(non_empty_lists[0]))\n    # Multiple lists - use topological sort\n    return topological_sort(non_empty_lists)\n\n\n# Also update the merge method to handle the new approach:\n@staticmethod\ndef merge(*lists):\n    \"\"\"\n    Merge multiple lists into a single list, preserving order constraints.\n    \n    This is kept for backwards compatibility but now uses topological sort\n    when merging multiple lists.\n    \"\"\"\n    if not lists:\n        return []\n    \n    # Filter out empty lists\n    non_empty = [lst for lst in lists if lst]\n    if not non_empty:\n        return []\n    if len(non_empty) == 1:\n        return list(OrderedDict.fromkeys(non_empty[0]))\n    \n    return topological_sort(non_empty)",
      "generation_time": 17.16075301170349,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 20,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 6,
      "low_issues": 7,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.45,
        "style": 0.368,
        "performance": 0.96
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 33.3%",
        "HIGH: ast_analysis - Function 'topological_sort' too long (75 lines) - production maintainability concern",
        "HIGH: logic - Low logic score: 0.00"
      ],
      "verification_time": 0.05878496170043945,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11039",
      "repo": "django/django",
      "problem_statement": "sqlmigrate wraps it's outpout in BEGIN/COMMIT even if the database doesn't support transactional DDL\nDescription\n\t \n\t\t(last modified by Simon Charette)\n\t \nThe migration executor only adds the outer BEGIN/COMMIT \u200bif the migration is atomic and \u200bthe schema editor can rollback DDL but the current sqlmigrate logic only takes migration.atomic into consideration.\nThe issue can be addressed by\nChanging sqlmigrate \u200bassignment of self.output_transaction to consider connection.features.can_rollback_ddl as",
      "hints_text": "I marked the ticket as easy picking because I included the above guidelines but feel free to uncheck it if you deem it inappropriate. Super. We don't have enough Easy Pickings tickets for the demand, ",
      "claude_patch": "diff --git a/django/core/management/commands/sqlmigrate.py b/django/core/management/commands/sqlmigrate.py\nindex 1234567890..abcdefghij 100644\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -59,7 +59,7 @@ class Command(BaseCommand):\n         plan = [(executor.loader.graph.nodes[target], options['backwards'])]\n         sql_statements = executor.collect_sql(plan)\n         if not sql_statements and options['verbosity'] >= 1:\n             self.stdout.write('No operations found.')\n         return '\\n'.join(sql_statements)\n \n-        self.output_transaction = migration.atomic\n+        self.output_transaction = migration.atomic and connection.features.can_rollback_ddl",
      "generation_time": 14.900386810302734,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.0,
      "verification_verdict": "ERROR",
      "issues_found": 1,
      "critical_issues": 1,
      "high_issues": 0,
      "medium_issues": 0,
      "low_issues": 0,
      "agent_scores": {},
      "key_issues": [
        "CRITICAL: system_error - Verification failed: sequence item 1: expected str instance, NoneType found"
      ],
      "verification_time": 0.049446821212768555,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11049",
      "repo": "django/django",
      "problem_statement": "Correct expected format in invalid DurationField error message\nDescription\n\t\nIf you enter a duration \"14:00\" into a duration field, it translates to \"00:14:00\" which is 14 minutes.\nThe current error message for invalid DurationField says that this should be the format of durations: \"[DD] [HH:[MM:]]ss[.uuuuuu]\". But according to the actual behaviour, it should be: \"[DD] [[HH:]MM:]ss[.uuuuuu]\", because seconds are mandatory, minutes are optional, and hours are optional if minutes are provided.\nThi",
      "hints_text": null,
      "claude_patch": "# django/forms/fields.py\n\nfrom django.core import validators\nfrom django.core.exceptions import ValidationError\nfrom django.forms.fields import Field\nfrom django.utils.translation import gettext_lazy as _\nfrom django.utils.duration import parse_duration\n\n\n# Locate the DurationField class and update it\nclass DurationField(Field):\n    default_error_messages = {\n        'invalid': _('Enter a valid duration.'),\n        'overflow': _('The number of days must be between {min_days} and {max_days}.'),\n    }\n\n    def __init__(self, *, help_text=_('Format: \"[DD] [[HH:]MM:]ss[.uuuuuu]\"'), **kwargs):\n        super().__init__(help_text=help_text, **kwargs)\n\n    def prepare_value(self, value):\n        if isinstance(value, datetime.timedelta):\n            return duration_string(value)\n        return value\n\n    def to_python(self, value):\n        if value in self.empty_values:\n            return None\n        if isinstance(value, datetime.timedelta):\n            return value\n        try:\n            value = parse_duration(str(value))\n        except OverflowError:\n            raise ValidationError(\n                self.error_messages['overflow'].format(\n                    min_days=datetime.timedelta.min.days,\n                    max_days=datetime.timedelta.max.days,\n                ),\n                code='overflow',\n            )\n        if value is None:\n            raise ValidationError(self.error_messages['invalid'], code='invalid')\n        return value",
      "generation_time": 17.83569598197937,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 2,
      "low_issues": 7,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.6627511012661632,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 66.7%",
        "HIGH: ast_analysis - Public function 'prepare_value' missing docstring - production documentation required",
        "HIGH: logic - Low logic score: 0.60"
      ],
      "verification_time": 0.18239212036132812,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11099",
      "repo": "django/django",
      "problem_statement": "UsernameValidator allows trailing newline in usernames\nDescription\n\t\nASCIIUsernameValidator and UnicodeUsernameValidator use the regex \nr'^[\\w.@+-]+$'\nThe intent is to only allow alphanumeric characters as well as ., @, +, and -. However, a little known quirk of Python regexes is that $ will also match a trailing newline. Therefore, the user name validators will accept usernames which end with a newline. You can avoid this behavior by instead using \\A and \\Z to terminate regexes. For example, th",
      "hints_text": null,
      "claude_patch": "import re\nfrom django.core import validators\nfrom django.utils.deconstruct import deconstructible\nfrom django.utils.translation import gettext_lazy as _\n\n\n@deconstructible\nclass ASCIIUsernameValidator(validators.RegexValidator):\n    regex = r'\\A[\\w.@+-]+\\Z'\n    message = _(\n        'Enter a valid username. This value may contain only English letters, '\n        'numbers, and @/./+/-/_ characters.'\n    )\n    flags = re.ASCII\n\n\n@deconstructible\nclass UnicodeUsernameValidator(validators.RegexValidator):\n    regex = r'\\A[\\w.@+-]+\\Z'\n    message = _(\n        'Enter a valid username. This value may contain only letters, '\n        'numbers, and @/./+/-/_ characters.'\n    )\n    flags = 0",
      "generation_time": 4.120998859405518,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.992,
      "verification_verdict": "PASS",
      "issues_found": 6,
      "critical_issues": 0,
      "high_issues": 0,
      "medium_issues": 1,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.834,
        "performance": 1.0
      },
      "key_issues": [],
      "verification_time": 0.07856106758117676,
      "patch_quality_estimate": "HIGH"
    },
    {
      "instance_id": "django__django-11133",
      "repo": "django/django",
      "problem_statement": "HttpResponse doesn't handle memoryview objects\nDescription\n\t\nI am trying to write a BinaryField retrieved from the database into a HttpResponse. When the database is Sqlite this works correctly, but Postgresql returns the contents of the field as a memoryview object and it seems like current Django doesn't like this combination:\nfrom django.http import HttpResponse\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n# String content\nresponse = HttpResponse(\"My Content\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nresponse.content\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t",
      "hints_text": "I guess HttpResponseBase.make_bytes \u200bcould be adapted to deal with memoryview objects by casting them to bytes. In all cases simply wrapping the memoryview in bytes works as a workaround HttpResponse(",
      "claude_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 1234567890..abcdefghij 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -272,6 +272,8 @@ class HttpResponseBase:\n             return bytes(value, self.charset)\n         if isinstance(value, bytes):\n             return value\n+        if isinstance(value, memoryview):\n+            return value.tobytes()\n         if isinstance(value, str):\n             return bytes(value, self.charset)\n         # Handle non-string types.",
      "generation_time": 3.9488730430603027,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.024738073348999023,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11179",
      "repo": "django/django",
      "problem_statement": "delete() on instances of models without any dependencies doesn't clear PKs.\nDescription\n\t\nDeleting any model with no dependencies not updates the PK on the model. It should be set to None after .delete() call.\nSee Django.db.models.deletion:276-281. Should update the model line 280.\n",
      "hints_text": "Reproduced at 1ffddfc233e2d5139cc6ec31a4ec6ef70b10f87f. Regression in bc7dd8490b882b2cefdc7faf431dc64c532b79c9. Thanks for the report.\nRegression test.\nI have attached a simple fix which mimics what \u200b",
      "claude_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -273,11 +273,18 @@ class Collector:\n                 query = sql.DeleteQuery(model)\n                 pk_list = [obj.pk for obj in instances]\n                 count = query.delete_batch(pk_list, self.using)\n+                if count:\n+                    for obj in instances:\n+                        setattr(obj, model._meta.pk.attname, None)\n                 deleted_counter[model._meta.label] += count\n \n         # update collected instances\n         for instances_for_fieldvalues in self.field_updates.values():\n             for (field, value), instances in instances_for_fieldvalues.items():\n+                if field.primary_key:\n+                    for obj in instances:\n+                        setattr(obj, field.attname, None)\n+                else:\n                 for obj in instances:\n                     setattr(obj, field.attname, value)\n         for model, instances in self.data.items():",
      "generation_time": 9.08218502998352,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04348611831665039,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11283",
      "repo": "django/django",
      "problem_statement": "Migration auth.0011_update_proxy_permissions fails for models recreated as a proxy.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nI am trying to update my project to Django 2.2. When I launch python manage.py migrate, I get this error message when migration auth.0011_update_proxy_permissions is applying (full stacktrace is available \u200bhere):\ndjango.db.utils.IntegrityError: duplicate key value violates unique constraint \"idx_18141_auth_permission_content_type_id_01ab375a_uniq\" DETAIL: Ke",
      "hints_text": "Please provide a sample project or enough details to reproduce the issue.\nSame problem for me. If a Permission exists already with the new content_type and permission name, IntegrityError is raised si",
      "claude_patch": "# django/contrib/auth/migrations/0011_update_proxy_permissions.py\n\nfrom django.db import migrations, models\nfrom django.db.models import Q\n\n\ndef update_proxy_model_permissions(apps, schema_editor, reverse=False):\n    \"\"\"\n    Update the content_type of proxy model permissions to use the ContentType\n    of the proxy model.\n    \"\"\"\n    Permission = apps.get_model('auth', 'Permission')\n    ContentType = apps.get_model('contenttypes', 'ContentType')\n    \n    alias = schema_editor.connection.alias\n    \n    for Model in apps.get_models():\n        opts = Model._meta\n        if not opts.proxy:\n            continue\n        \n        proxy_content_type = ContentType.objects.using(alias).get_for_model(\n            Model, for_concrete_model=False\n        )\n        concrete_content_type = ContentType.objects.using(alias).get_for_model(\n            Model, for_concrete_model=True\n        )\n        \n        proxy_model_permissions = Permission.objects.using(alias).filter(\n            content_type=concrete_content_type,\n            codename__in=[\n                '%s_%s' % (action, opts.model_name)\n                for action in ('add', 'change', 'delete', 'view')\n            ],\n        )\n        \n        for permission in proxy_model_permissions:\n            # Check if a permission with the proxy content type already exists\n            try:\n                existing_permission = Permission.objects.using(alias).get(\n                    content_type=proxy_content_type,\n                    codename=permission.codename,\n                )\n                # If it exists, we need to handle the conflict\n                # Delete the old permission and keep the existing one with proxy content type\n                permission.delete()\n            except Permission.DoesNotExist:\n                # No conflict, safe to update\n                permission.content_type = proxy_content_type\n                permission.save()\n\n\ndef revert_proxy_model_permissions(apps, schema_editor):\n    \"\"\"\n    Update the content_type of proxy model permissions to use the ContentType\n    of the concrete model.\n    \"\"\"\n    Permission = apps.get_model('auth', 'Permission')\n    ContentType = apps.get_model('contenttypes', 'ContentType')\n    \n    alias = schema_editor.connection.alias\n    \n    for Model in apps.get_models():\n        opts = Model._meta\n        if not opts.proxy:\n            continue\n        \n        proxy_content_type = ContentType.objects.using(alias).get_for_model(\n            Model, for_concrete_model=False\n        )\n        concrete_content_type = ContentType.objects.using(alias).get_for_model(\n            Model, for_concrete_model=True\n        )\n        \n        proxy_model_permissions = Permission.objects.using(alias).filter(\n            content_type=proxy_content_type,\n            codename__in=[\n                '%s_%s' % (action, opts.model_name)\n                for action in ('add', 'change', 'delete', 'view')\n            ],\n        )\n        \n        for permission in proxy_model_permissions:\n            permission.content_type = concrete_content_type\n            permission.save()\n\n\nclass Migration(migrations.Migration):\n    dependencies = [\n        ('auth', '0010_alter_group_name_max_length'),\n        ('contenttypes', '0002_remove_content_type_name'),\n    ]\n    operations = [\n        migrations.RunPython(\n            update_proxy_model_permissions,\n            revert_proxy_model_permissions,\n        ),\n    ]",
      "generation_time": 11.807071208953857,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 7,
      "low_issues": 8,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.5399999999999999,
        "style": 0.46799999999999997,
        "performance": 0.988
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%"
      ],
      "verification_time": 0.1684589385986328,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11422",
      "repo": "django/django",
      "problem_statement": "Autoreloader with StatReloader doesn't track changes in manage.py.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nThis is a bit convoluted, but here we go.\nEnvironment (OSX 10.11):\n$ python -V\nPython 3.6.2\n$ pip -V\npip 19.1.1\n$ pip install Django==2.2.1\nSteps to reproduce:\nRun a server python manage.py runserver\nEdit the manage.py file, e.g. add print(): \ndef main():\n\tprint('sth')\n\tos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ticket_30479.settings')\n\t...\nUnder 2.1.8 (and prior), thi",
      "hints_text": "Thanks for the report. I simplified scenario. Regression in c8720e7696ca41f3262d5369365cc1bd72a216ca. Reproduced at 8d010f39869f107820421631111417298d1c5bb9.\nArgh. I guess this is because manage.py is",
      "claude_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 1234567890..abcdef1234 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -112,6 +112,14 @@ def iter_modules_and_files(modules, extra_files):\n     # iteration.\n     for module in list(modules.values()):\n         if module is None:\n             continue\n+        # Handle __main__ module specially since __spec__ is None\n+        if module.__name__ == '__main__':\n+            filename = getattr(module, '__file__', None)\n+            if filename:\n+                filename = Path(filename).resolve()\n+                if filename.suffix in ['.py', '.pyc', '.pyo']:\n+                    yield filename.resolve()\n+            continue\n         if getattr(module, \"__spec__\", None) is None:\n             continue\n         spec = module.__spec__",
      "generation_time": 5.5801918506622314,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04172539710998535,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11564",
      "repo": "django/django",
      "problem_statement": "Add support for SCRIPT_NAME in STATIC_URL and MEDIA_URL\nDescription\n\t \n\t\t(last modified by Rostyslav Bryzgunov)\n\t \nBy default, {% static '...' %} tag just appends STATIC_URL in the path. When running on sub-path, using SCRIPT_NAME WSGI param, it results in incorrect static URL - it doesn't prepend SCRIPT_NAME prefix.\nThis problem can be solved with prepending SCRIPT_NAME to STATIC_URL in settings.py but that doesn't work when SCRIPT_NAME is a dynamic value.\nThis can be easily added into default ",
      "hints_text": "This change doesn't seem correct to me (for one, it seems like it could break existing sites). Why not include the appropriate prefix in your STATIC_URL and MEDIA_URL settings?\nThis is not a patch. Th",
      "claude_patch": "import posixpath\nfrom urllib.parse import urljoin, urlsplit\n\nfrom django.conf import settings\nfrom django.urls import get_script_prefix\nfrom django.utils.encoding import filepath_to_uri\n\n\ndef get_static_url(path):\n    \"\"\"\n    Return the URL for the given static file path.\n    Prepends SCRIPT_NAME if STATIC_URL is a relative URL.\n    \"\"\"\n    if not path:\n        return ''\n    \n    static_url = settings.STATIC_URL\n    if not static_url:\n        return path\n    \n    # If STATIC_URL is absolute (has scheme or netloc), use it as-is\n    parsed = urlsplit(static_url)\n    if parsed.scheme or parsed.netloc:\n        return urljoin(static_url, path)\n    \n    # For relative URLs, prepend script prefix\n    script_prefix = get_script_prefix()\n    if static_url.startswith('/'):\n        # Ensure we don't double-add the script prefix\n        if not static_url.startswith(script_prefix):\n            static_url = posixpath.join(script_prefix.rstrip('/'), static_url.lstrip('/'))\n    \n    return urljoin(static_url, path)\n\n\ndef get_media_url(path):\n    \"\"\"\n    Return the URL for the given media file path.\n    Prepends SCRIPT_NAME if MEDIA_URL is a relative URL.\n    \"\"\"\n    if not path:\n        return ''\n    \n    media_url = settings.MEDIA_URL\n    if not media_url:\n        return path\n    \n    # If MEDIA_URL is absolute (has scheme or netloc), use it as-is\n    parsed = urlsplit(media_url)\n    if parsed.scheme or parsed.netloc:\n        return urljoin(media_url, path)\n    \n    # For relative URLs, prepend script prefix\n    script_prefix = get_script_prefix()\n    if media_url.startswith('/'):\n        # Ensure we don't double-add the script prefix\n        if not media_url.startswith(script_prefix):\n            media_url = posixpath.join(script_prefix.rstrip('/'), media_url.lstrip('/'))\n    \n    return urljoin(media_url, path)\n\n\n# Patch for django/core/files/storage.py\nfrom django.core.files.storage import FileSystemStorage\n\n\nclass FileSystemStoragePatched(FileSystemStorage):\n    def url(self, name):\n        if self.base_url is None:\n            raise ValueError(\"This file is not accessible via a URL.\")\n        url = filepath_to_uri(name)\n        if url is not None:\n            url = url.lstrip('/')\n        \n        # If base_url is absolute, use it as-is\n        parsed = urlsplit(self.base_url)\n        if parsed.scheme or parsed.netloc:\n            return urljoin(self.base_url, url)\n        \n        # For relative URLs, prepend script prefix\n        base_url = self.base_url\n        script_prefix = get_script_prefix()\n        if base_url.startswith('/'):\n            # Ensure we don't double-add the script prefix\n            if not base_url.startswith(script_prefix):\n                base_url = posixpath.join(script_prefix.rstrip('/'), base_url.lstrip('/'))\n        \n        return urljoin(base_url, url)\n\n\n# Patch for django/contrib/staticfiles/storage.py\nfrom django.contrib.staticfiles.storage import StaticFilesStorage\n\n\nclass StaticFilesStoragePatched(StaticFilesStorage):\n    def url(self, name, force=False):\n        if self.base_url is None:\n            raise ValueError(\"This file is not accessible via a URL.\")\n        url = filepath_to_uri(name)\n        if url is not None:\n            url = url.lstrip('/')\n        \n        # If base_url is absolute, use it as-is\n        parsed = urlsplit(self.base_url)\n        if parsed.scheme or parsed.netloc:\n            return urljoin(self.base_url, url)\n        \n        # For relative URLs, prepend script prefix\n        base_url = self.base_url\n        script_prefix = get_script_prefix()\n        if base_url.startswith('/'):\n            # Ensure we don't double-add the script prefix\n            if not base_url.startswith(script_prefix):\n                base_url = posixpath.join(script_prefix.rstrip('/'), base_url.lstrip('/'))\n        \n        return urljoin(base_url, url)\n\n\n# Patch for django/templatetags/static.py\nfrom django import template\nfrom django.templatetags.static import StaticNode as OriginalStaticNode\n\n\nclass StaticNode(OriginalStaticNode):\n    def url(self, context):\n        path = self.path.resolve(context)\n        return get_static_url(path)\n\n\n# Patch for django/contrib/staticfiles/templatetags/staticfiles.py\nfrom django.contrib.staticfiles.templatetags.staticfiles import StaticFilesNode as OriginalStaticFilesNode\nfrom django.contrib.staticfiles.storage import staticfiles_storage\n\n\nclass StaticFilesNode(OriginalStaticFilesNode):\n    def url(self, context):\n        path = self.path.resolve(context)\n        \n        # Use staticfiles_storage if available\n        if hasattr(staticfiles_storage, 'url'):\n            try:\n                return staticfiles_storage.url(path)\n            except Exception:\n                pass\n        \n        return get_static_url(path)\n\n\n# Update FileSystemStorage.url method\ndef patched_filesystem_storage_url(self, name):\n    if self.base_url is None:\n        raise ValueError(\"This file is not accessible via a URL.\")\n    url = filepath_to_uri(name)\n    if url is not None:\n        url = url.lstrip('/')\n    \n    # If base_url is absolute, use it as-is\n    parsed = urlsplit(self.base_url)\n    if parsed.scheme or parsed.netloc:\n        return urljoin(self.base_url, url)\n    \n    # For relative URLs, prepend script prefix\n    base_url = self.base_url\n    script_prefix = get_script_prefix()\n    if base_url.startswith('/'):\n        # Ensure we don't double-add the script prefix\n        if not base_url.startswith(script_prefix):\n            base_url = posixpath.join(script_prefix.rstrip('/'), base_url.lstrip('/'))\n    \n    return urljoin(base_url, url)\n\n\n# Apply patches\nFileSystemStorage.url = patched_filesystem_storage_url",
      "generation_time": 19.09284496307373,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.0,
      "verification_verdict": "ERROR",
      "issues_found": 1,
      "critical_issues": 1,
      "high_issues": 0,
      "medium_issues": 0,
      "low_issues": 0,
      "agent_scores": {},
      "key_issues": [
        "CRITICAL: system_error - Verification failed: sequence item 1: expected str instance, NoneType found"
      ],
      "verification_time": 0.2012619972229004,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11583",
      "repo": "django/django",
      "problem_statement": "Auto-reloading with StatReloader very intermittently throws \"ValueError: embedded null byte\".\nDescription\n\t\nRaising this mainly so that it's tracked, as I have no idea how to reproduce it, nor why it's happening. It ultimately looks like a problem with Pathlib, which wasn't used prior to 2.2.\nStacktrace:\nTraceback (most recent call last):\n File \"manage.py\" ...\n\texecute_from_command_line(sys.argv)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/core/management/__init__.py\", line",
      "hints_text": "Thanks for the report, however as you've admitted there is too many unknowns to accept this ticket. I don't believe that it is related with pathlib, maybe samba connection is unstable it's hard to tel",
      "claude_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 1234567890..abcdefghij 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -129,7 +129,11 @@ def iter_modules_and_files(modules, extra_files):\n             # during iteration.\n             for path in list(sys_file_paths):\n                 if path.exists():\n-                    results.add(path.resolve().absolute())\n+                    try:\n+                        results.add(path.resolve().absolute())\n+                    except ValueError:\n+                        # Ignore paths that contain null bytes or other invalid data\n+                        results.add(path.absolute())\n     return frozenset(results)",
      "generation_time": 20.74847984313965,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.041674137115478516,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11620",
      "repo": "django/django",
      "problem_statement": "When DEBUG is True, raising Http404 in a path converter's to_python method does not result in a technical response\nDescription\n\t\nThis is the response I get (plain text): \nA server error occurred. Please contact the administrator.\nI understand a ValueError should be raised which tells the URL resolver \"this path does not match, try next one\" but Http404 is what came to my mind intuitively and the error message was not very helpful.\nOne could also make a point that raising a Http404 should be vali",
      "hints_text": "It seems that other exceptions correctly result in a technical 500 response.\nThe technical_404_response view performs a new URL resolving (cf \u200bhttps://github.com/django/django/blob/a8e492bc81fca829f5d",
      "claude_patch": "# django/views/debug.py\n\nfrom django.http import Http404, HttpResponse, HttpResponseNotFound\nfrom django.urls import Resolver404\nfrom django.template import Context, Engine, TemplateDoesNotExist\nfrom django.template.defaultfilters import pprint\nfrom django.utils.html import escape\nfrom django.utils.version import get_docs_version\n\ndef technical_404_response(request, exception):\n    \"\"\"Create a technical 404 error response. `exception` is the Http404.\"\"\"\n    try:\n        error_url = exception.args[0]['path']\n    except (IndexError, TypeError, KeyError):\n        error_url = request.path_info[1:]  # Trim leading slash\n\n    try:\n        tried = exception.args[0]['tried']\n    except (IndexError, TypeError, KeyError):\n        tried = []\n\n    try:\n        # Resolve the URL again to get the URLconf and tried patterns\n        from django.urls import get_resolver\n        resolver = get_resolver()\n        resolver.resolve(error_url)\n    except Http404:\n        # If Http404 is raised during resolution (e.g., from a path converter),\n        # we still want to show the technical 404 page\n        pass\n    except Resolver404:\n        pass\n\n    # Get the URLconf that was used\n    from django.urls import get_urlconf\n    urlconf = get_urlconf()\n\n    if not urlconf:\n        # This should only happen if something is seriously wrong\n        from django.conf import settings\n        urlconf = settings.ROOT_URLCONF\n\n    # Load the template\n    t = Engine.get_default().from_string(TECHNICAL_404_TEMPLATE)\n    reporter_filter = get_default_exception_reporter_filter()\n    c = Context({\n        'urlconf': urlconf,\n        'root_urlconf': urlconf,\n        'request_path': error_url,\n        'urlpatterns': tried,\n        'reason': str(exception),\n        'request': request,\n        'settings': reporter_filter.get_safe_settings(),\n        'raising_view_name': get_caller(request),\n    })\n    return HttpResponseNotFound(t.render(c), content_type='text/html')",
      "generation_time": 16.280475854873657,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 13,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 2,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.6399999999999999,
        "style": 0.868,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: contract_violation - Function 'technical_404_response' docstring mentions exceptions but none are raised"
      ],
      "verification_time": 0.1869359016418457,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11630",
      "repo": "django/django",
      "problem_statement": "Django throws error when different apps with different models have the same name table name.\nDescription\n\t\nError message:\ntable_name: (models.E028) db_table 'table_name' is used by multiple models: base.ModelName, app2.ModelName.\nWe have a Base app that points to a central database and that has its own tables. We then have multiple Apps that talk to their own databases. Some share the same table names.\nWe have used this setup for a while, but after upgrading to Django 2.2 we're getting an error ",
      "hints_text": "Regression in [5d25804eaf81795c7d457e5a2a9f0b9b0989136c], ticket #20098. My opinion is that as soon as the project has a non-empty DATABASE_ROUTERS setting, the error should be turned into a warning, ",
      "claude_patch": "from django.core.checks import Warning, Error\nfrom django.conf import settings\n\ndef _check_db_table_collision(self, databases):\n    errors = []\n    if not databases:\n        return errors\n\n    # Get all models\n    from django.apps import apps\n    all_models = apps.get_models(include_auto_created=True)\n    \n    # Group models by db_table\n    db_tables = {}\n    for model in all_models:\n        db_table = model._meta.db_table\n        if db_table not in db_tables:\n            db_tables[db_table] = []\n        db_tables[db_table].append(model)\n    \n    # Check for collisions\n    for db_table, models in db_tables.items():\n        if len(models) > 1:\n            model_labels = ', '.join(\n                model._meta.label for model in models\n            )\n            # Use Warning instead of Error if DATABASE_ROUTERS is configured\n            if getattr(settings, 'DATABASE_ROUTERS', None):\n                errors.append(\n                    Warning(\n                        \"db_table '%s' is used by multiple models: %s.\" % (db_table, model_labels),\n                        hint=(\n                            'You have configured DATABASE_ROUTERS. Ensure that your '\n                            'database routers are correctly routing these models to '\n                            'different databases. You can silence this warning by adding '\n                            'it to SILENCED_SYSTEM_CHECKS.'\n                        ),\n                        obj=db_table,\n                        id='models.W028',\n                    )\n                )\n            else:\n                errors.append(\n                    Error(\n                        \"db_table '%s' is used by multiple models: %s.\" % (db_table, model_labels),\n                        obj=db_table,\n                        id='models.E028',\n                    )\n                )\n    \n    return errors",
      "generation_time": 8.688374996185303,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 11,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 3,
      "low_issues": 7,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8766666666666667,
        "style": 0.6764304792996556,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.10916018486022949,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-11742",
      "repo": "django/django",
      "problem_statement": "Add check to ensure max_length fits longest choice.\nDescription\n\t\nThere is currently no check to ensure that Field.max_length is large enough to fit the longest value in Field.choices.\nThis would be very helpful as often this mistake is not noticed until an attempt is made to save a record with those values that are too long.\n",
      "hints_text": null,
      "claude_patch": "from django.core import checks\nfrom django.db import models\n\n\ndef _check_max_length_with_choices(field):\n    \"\"\"\n    Check that max_length is sufficient for the longest choice value.\n    \"\"\"\n    if not hasattr(field, 'max_length') or field.max_length is None:\n        return []\n    \n    if not field.choices:\n        return []\n    \n    # Get all choice values, handling both flat and grouped choices\n    choice_values = []\n    for choice in field.choices:\n        if isinstance(choice, (list, tuple)) and len(choice) == 2:\n            # Could be a grouped choice or a regular choice\n            if isinstance(choice[1], (list, tuple)):\n                # Grouped choice: (group_name, [(value, label), ...])\n                for sub_choice in choice[1]:\n                    if isinstance(sub_choice, (list, tuple)) and len(sub_choice) >= 1:\n                        choice_values.append(sub_choice[0])\n            else:\n                # Regular choice: (value, label)\n                choice_values.append(choice[0])\n    \n    if not choice_values:\n        return []\n    \n    # Find the longest choice value\n    max_choice_length = 0\n    longest_value = None\n    for value in choice_values:\n        if value is None:\n            continue\n        # Convert to string as that's how it will be stored\n        str_value = str(value)\n        value_length = len(str_value)\n        if value_length > max_choice_length:\n            max_choice_length = value_length\n            longest_value = str_value\n    \n    if max_choice_length > field.max_length:\n        return [\n            checks.Error(\n                \"'max_length' is too small to fit the longest choice.\",\n                hint=(\n                    f\"The longest choice value is {max_choice_length} characters, \"\n                    f\"but 'max_length' is only {field.max_length}. \"\n                    f\"Increase 'max_length' to at least {max_choice_length}.\"\n                ),\n                obj=field,\n                id='fields.E009',\n            )\n        ]\n    \n    return []\n\n\n# Patch CharField._check_max_length_attribute to include the choices check\noriginal_check_max_length_attribute = models.CharField._check_max_length_attribute\n\ndef patched_check_max_length_attribute(self):\n    errors = original_check_max_length_attribute(self)\n    errors.extend(_check_max_length_with_choices(self))\n    return errors\n\nmodels.CharField._check_max_length_attribute = patched_check_max_length_attribute",
      "generation_time": 10.895648956298828,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 19,
      "critical_issues": 0,
      "high_issues": 8,
      "medium_issues": 5,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.56,
        "performance": 0.967
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: ast_analysis - Function '_check_max_length_with_choices' too long (54 lines) - production maintainability concern",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.13026094436645508,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11797",
      "repo": "django/django",
      "problem_statement": "Filtering on query result overrides GROUP BY of internal query\nDescription\n\t\nfrom django.contrib.auth import models\na = models.User.objects.filter(email__isnull=True).values('email').annotate(m=Max('id')).values('m')\nprint(a.query) # good\n# SELECT MAX(\"auth_user\".\"id\") AS \"m\" FROM \"auth_user\" WHERE \"auth_user\".\"email\" IS NULL GROUP BY \"auth_user\".\"email\"\nprint(a[:1].query) # good\n# SELECT MAX(\"auth_user\".\"id\") AS \"m\" FROM \"auth_user\" WHERE \"auth_user\".\"email\" IS NULL GROUP BY \"auth_user\".\"email\"",
      "hints_text": "Workaround: from django.contrib.auth import models a = models.User.objects.filter(email__isnull=True).values('email').aggregate(Max('id'))['id_max'] b = models.User.objects.filter(id=a)\nThanks for tac",
      "claude_patch": "from django.db.models.lookups import Exact\n\n# Store the original process_rhs method\n_original_exact_process_rhs = Exact.process_rhs\n\ndef patched_exact_process_rhs(self):\n    \"\"\"\n    Process the right-hand side of an Exact lookup.\n    \n    Only clear select clause and add pk field if the RHS query\n    doesn't already have selected fields (similar to In.process_rhs).\n    \"\"\"\n    if hasattr(self.rhs, 'resolve_expression'):\n        # Get the query object if it exists\n        query_obj = getattr(self.rhs, 'query', None)\n        if query_obj is not None:\n            # Check if the query already has selected fields\n            # If it does, don't override them with pk\n            if not getattr(self.rhs, 'has_select_fields', True):\n                # Original behavior: clear and add pk\n                return _original_exact_process_rhs(self)\n            else:\n                # Query already has selected fields, don't modify them\n                # Just resolve the expression without clearing select clause\n                from django.db.models.sql.query import Query\n                if isinstance(query_obj, Query):\n                    # Don't call clear_select_clause or add_fields\n                    # Just return the processed RHS as-is\n                    pass\n    \n    # For queries with selected fields, skip the clear_select_clause and add_fields\n    if not getattr(self.rhs, 'has_select_fields', True):\n        return _original_exact_process_rhs(self)\n    \n    # Process RHS without modifying the select clause\n    from django.db.models.expressions import Subquery\n    if hasattr(self.rhs, '_iterable_class'):\n        # This is a QuerySet, convert to subquery without modifying fields\n        return self.rhs, ()\n    \n    return _original_exact_process_rhs(self)\n\n# Apply the patch\nExact.process_rhs = patched_exact_process_rhs",
      "generation_time": 15.440067052841187,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 8,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 0,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.7166666666666666,
        "style": 0.8644460665510887,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: logic - Low logic score: 0.60",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path",
        "HIGH: loop_nesting - Extreme loop nesting: 4 levels"
      ],
      "verification_time": 0.13013291358947754,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11815",
      "repo": "django/django",
      "problem_statement": "Migrations uses value of enum object instead of its name.\nDescription\n\t \n\t\t(last modified by oasl)\n\t \nWhen using Enum object as a default value for a CharField, the generated migration file uses the value of the Enum object instead of the its name. This causes a problem when using Django translation on the value of the Enum object. \nThe problem is that, when the Enum object value get translated to the users language, the old migration files raise an error stating that the Enum does not have the ",
      "hints_text": "Thanks for this report, however I'm not sure how translated values can brake migrations. Can you provide a sample project to reproduce this issue? Migrations with translatable strings works fine for m",
      "claude_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..b00c6f0df2 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,9 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n+        _, v_imports = serializer_factory(self.value.value).serialize()\n         imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        return \"%s.%s[%r]\" % (module, enum_class.__name__, self.value.name), imports\n \n \n class FloatSerializer(BaseSerializer):",
      "generation_time": 4.418089866638184,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid decimal literal (<unknown>, line 2)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.03856492042541504,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11848",
      "repo": "django/django",
      "problem_statement": "django.utils.http.parse_http_date two digit year check is incorrect\nDescription\n\t \n\t\t(last modified by Ad Timmering)\n\t \nRFC 850 does not mention this, but in RFC 7231 (and there's something similar in RFC 2822), there's the following quote:\nRecipients of a timestamp value in rfc850-date format, which uses a\ntwo-digit year, MUST interpret a timestamp that appears to be more\nthan 50 years in the future as representing the most recent year in\nthe past that had the same last two digits.\nCurrent logi",
      "hints_text": "Accepted, however I don't think your patch is correct. The check should be relative to the current year, if I read the RFC quote correctly.\nCreated a pull request: Created a pull request: \u200bhttps://git",
      "claude_patch": "import datetime\nfrom django.utils.http import parse_http_date\n\n# Patch for django/utils/http.py parse_http_date function\n\ndef parse_http_date(date):\n    \"\"\"\n    Parse a date format as specified by HTTP RFC7231 section 7.1.1.1.\n\n    The three formats allowed by the RFC are accepted, even if only the first\n    one is still in widespread use.\n\n    Return an integer expressed in seconds since the epoch, in UTC.\n    \"\"\"\n    # email.utils.parsedate() does the job for RFC1123 dates; unfortunately\n    # RFC7231 makes it mandatory to support RFC850 dates too. So we roll\n    # our own RFC-compliant parsing.\n    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:\n        m = regex.match(date)\n        if m is not None:\n            break\n    else:\n        raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n    try:\n        tz = datetime.timezone.utc\n        year = int(m.group('year'))\n        if year < 100:\n            # According to RFC 7231, recipients of a timestamp value in\n            # rfc850-date format (two-digit year) must interpret a timestamp\n            # that appears to be more than 50 years in the future as\n            # representing the most recent year in the past that had the same\n            # last two digits.\n            current_year = datetime.datetime.now(tz=tz).year\n            current_century = current_year - (current_year % 100)\n            \n            # Construct the full year using current century\n            full_year = current_century + year\n            \n            # If this year is more than 50 years in the future, roll back 100 years\n            if full_year - current_year > 50:\n                full_year -= 100\n            \n            year = full_year\n        month = MONTHS.index(m.group('mon').lower()) + 1\n        day = int(m.group('day'))\n        hour = int(m.group('hour'))\n        min = int(m.group('min'))\n        sec = int(m.group('sec'))\n        result = datetime.datetime(year, month, day, hour, min, sec, tzinfo=tz)\n        return int(result.timestamp())\n    except Exception as exc:\n        raise ValueError(\"%r is not a valid date\" % date) from exc",
      "generation_time": 12.197566032409668,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 2,
      "low_issues": 5,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 1.0,
        "style": 0.8200000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.07587194442749023,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-11905",
      "repo": "django/django",
      "problem_statement": "Prevent using __isnull lookup with non-boolean value.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \n__isnull should not allow for non-boolean values. Using truthy/falsey doesn't promote INNER JOIN to an OUTER JOIN but works fine for a simple queries. Using non-boolean values is \u200bundocumented and untested. IMO we should raise an error for non-boolean values to avoid confusion and for consistency.\n",
      "hints_text": "PR here: \u200bhttps://github.com/django/django/pull/11873\nAfter the reconsideration I don't think that we should change this \u200bdocumented behavior (that is in Django from the very beginning). __isnull look",
      "claude_patch": "import warnings\nfrom django.db.models.lookups import BuiltinLookup\nfrom django.utils.deprecation import RemovedInDjango40Warning\n\n\nclass IsNull(BuiltinLookup):\n    lookup_name = 'isnull'\n    prepare_rhs = False\n\n    def as_sql(self, compiler, connection):\n        # Check if rhs is a boolean value\n        if not isinstance(self.rhs, bool):\n            warnings.warn(\n                'Using non-boolean values for the __isnull lookup is deprecated. '\n                'Use True or False instead.',\n                RemovedInDjango40Warning,\n                stacklevel=2,\n            )\n        \n        sql, params = compiler.compile(self.lhs)\n        if self.rhs:\n            return \"%s IS NULL\" % sql, params\n        else:\n            return \"%s IS NOT NULL\" % sql, params",
      "generation_time": 4.46682596206665,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 2,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.785583060661102,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.16338419914245605,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-11910",
      "repo": "django/django",
      "problem_statement": "ForeignKey's to_field parameter gets the old field's name when renaming a PrimaryKey.\nDescription\n\t\nHaving these two models \nclass ModelA(models.Model):\n\tfield_wrong = models.CharField('field1', max_length=50, primary_key=True) # I'm a Primary key.\nclass ModelB(models.Model):\n\tfield_fk = models.ForeignKey(ModelA, blank=True, null=True, on_delete=models.CASCADE) \n... migrations applyed ...\nthe ModelA.field_wrong field has been renamed ... and Django recognizes the \"renaming\"\n# Primary key renamed",
      "hints_text": "Thanks for this ticket. It looks like a regression in dcdd219ee1e062dc6189f382e0298e0adf5d5ddf, because an AlterField operation wasn't generated in such cases before this change (and I don't think we ",
      "claude_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 1234567890..abcdefghij 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -1089,6 +1089,23 @@ class MigrationAutodetector:\n                         dependencies=dependencies,\n                     )\n                 )\n+                # Check if this is a ForeignKey pointing to a renamed primary key\n+                # If so, we should not generate an AlterField operation since\n+                # RenameField will handle the reference update\n+                if old_field.remote_field and hasattr(old_field.remote_field, 'model'):\n+                    remote_model = old_field.remote_field.model\n+                    if isinstance(remote_model, str):\n+                        remote_model_key = self.resolve_model_key(remote_model, app_label)\n+                    else:\n+                        remote_model_key = (remote_model._meta.app_label, remote_model._meta.model_name)\n+                    \n+                    to_field_name = old_field.remote_field.field_name\n+                    if to_field_name and remote_model_key:\n+                        # Check if the to_field was renamed\n+                        renamed_fields = self.renamed_fields.get(remote_model_key, {})\n+                        if to_field_name in renamed_fields.values():\n+                            # Skip this AlterField as RenameField will handle it\n+                            continue\n \n     def create_altered_indexes(self):\n         option_name = operations.AddIndex.option_name",
      "generation_time": 27.681917190551758,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.048561811447143555,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11964",
      "repo": "django/django",
      "problem_statement": "The value of a TextChoices/IntegerChoices field has a differing type\nDescription\n\t\nIf we create an instance of a model having a CharField or IntegerField with the keyword choices pointing to IntegerChoices or TextChoices, the value returned by the getter of the field will be of the same type as the one created by enum.Enum (enum value).\nFor example, this model:\nfrom django.db import models\nfrom django.utils.translation import gettext_lazy as _\nclass MyChoice(models.TextChoices):\n\tFIRST_CHOICE = ",
      "hints_text": "Hi NyanKiyoshi, what a lovely report. Thank you. Clearly :) the expected behaviour is that test_created_object_is_str should pass. It's interesting that the underlying __dict__ values differ, which ex",
      "claude_patch": "# django/db/models/fields/__init__.py\n\n# Find the Field class and update the to_python method or add conversion in __set__\n# The issue is in how CharField and IntegerField handle enum values\n\n# Patch for CharField\nfrom django.db.models.fields import CharField\n\n_original_charfield_get_prep_value = CharField.get_prep_value\n\ndef _patched_charfield_get_prep_value(self, value):\n    # Convert enum members to their values\n    if value is not None and hasattr(value, 'value') and hasattr(value, '__class__'):\n        # Check if it's an enum member\n        try:\n            import enum\n            if isinstance(value, enum.Enum):\n                value = value.value\n        except ImportError:\n            pass\n    return _original_charfield_get_prep_value(self, value)\n\nCharField.get_prep_value = _patched_charfield_get_prep_value\n\n\n# Patch for IntegerField\nfrom django.db.models.fields import IntegerField\n\n_original_integerfield_get_prep_value = IntegerField.get_prep_value\n\ndef _patched_integerfield_get_prep_value(self, value):\n    # Convert enum members to their values\n    if value is not None and hasattr(value, 'value') and hasattr(value, '__class__'):\n        # Check if it's an enum member\n        try:\n            import enum\n            if isinstance(value, enum.Enum):\n                value = value.value\n        except ImportError:\n            pass\n    return _original_integerfield_get_prep_value(self, value)\n\nIntegerField.get_prep_value = _patched_integerfield_get_prep_value",
      "generation_time": 16.340643167495728,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 14,
      "critical_issues": 0,
      "high_issues": 5,
      "medium_issues": 3,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.5566666666666666,
        "style": 0.6044422951406981,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: ast_analysis - Empty exception handler - production systems need error logging"
      ],
      "verification_time": 0.17558002471923828,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-11999",
      "repo": "django/django",
      "problem_statement": "Cannot override get_FOO_display() in Django 2.2+.\nDescription\n\t\nI cannot override the get_FIELD_display function on models since version 2.2. It works in version 2.1.\nExample:\nclass FooBar(models.Model):\n\tfoo_bar = models.CharField(_(\"foo\"), choices=[(1, 'foo'), (2, 'bar')])\n\tdef __str__(self):\n\t\treturn self.get_foo_bar_display() # This returns 'foo' or 'bar' in 2.2, but 'something' in 2.1\n\tdef get_foo_bar_display(self):\n\t\treturn \"something\"\nWhat I expect is that I should be able to override thi",
      "hints_text": "Thanks for this report. Regression in a68ea231012434b522ce45c513d84add516afa60. Reproduced at 54a7b021125d23a248e70ba17bf8b10bc8619234.\nOK, I have a lead on this. Not at all happy about how it looks a",
      "claude_patch": "# In django/db/models/fields/__init__.py, modify the Field.contribute_to_class method\n\ndef contribute_to_class(self, cls, name, private_only=False):\n    \"\"\"\n    Register the field with the model class it belongs to.\n\n    If private_only is True, create a separate instance of this field\n    for every subclass of cls, even if cls is not an abstract model.\n    \"\"\"\n    self.set_attributes_from_name(name)\n    self.model = cls\n    if private_only:\n        cls._meta.add_field(self, private=True)\n    else:\n        cls._meta.add_field(self)\n    if self.column:\n        # Don't override a get_FOO_display() method defined explicitly on\n        # this class, but don't check methods derived from inheritance, to\n        # allow overriding inherited choices.\n        if self.choices is not None:\n            display_method_name = 'get_%s_display' % self.name\n            if not hasattr(cls, display_method_name) or display_method_name not in cls.__dict__:\n                setattr(\n                    cls,\n                    display_method_name,\n                    partialmethod(cls._get_FIELD_display, field=self),\n                )",
      "generation_time": 12.158276081085205,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 6,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 1,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.9400900980183242,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.04597592353820801,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12113",
      "repo": "django/django",
      "problem_statement": "admin_views.test_multidb fails with persistent test SQLite database.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nI've tried using persistent SQLite databases for the tests (to make use of\n--keepdb), but at least some test fails with:\nsqlite3.OperationalError: database is locked\nThis is not an issue when only using TEST[\"NAME\"] with \"default\" (which is good enough in terms of performance).\ndiff --git i/tests/test_sqlite.py w/tests/test_sqlite.py\nindex f1b65f7d01..9ce4e32e14 100644\n---",
      "hints_text": "This is only an issue when setting TEST[\"NAME\"], but not NAME. The following works: DATABASES = { 'default': { 'ENGINE': 'django.db.backends.sqlite3', 'NAME': 'django_tests_default.sqlite3', }, 'other",
      "claude_patch": "# django/db/backends/sqlite3/creation.py\n\ndef test_db_signature(self):\n    \"\"\"\n    Return a tuple that uniquely identifies a test database.\n\n    This takes into account the special memory test database name.\n    \"\"\"\n    test_database_name = self._get_test_db_name()\n    sig = [self.connection.settings_dict['NAME']]\n    if test_database_name != ':memory:':\n        sig.append(test_database_name)\n    return tuple(sig)",
      "generation_time": 16.585742712020874,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 8,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 2,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.7933333333333333,
        "style": 0.974,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%"
      ],
      "verification_time": 0.0503690242767334,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12125",
      "repo": "django/django",
      "problem_statement": "makemigrations produces incorrect path for inner classes\nDescription\n\t\nWhen you define a subclass from django.db.models.Field as an inner class of some other class, and use this field inside a django.db.models.Model class, then when you run manage.py makemigrations, a migrations file is created which refers to the inner class as if it were a top-level class of the module it is in.\nTo reproduce, create the following as your model:\nclass Outer(object):\n\tclass Inner(models.CharField):\n\t\tpass\nclass ",
      "hints_text": "This should be possible to do by relying on __qualname__ (instead of __name__) now that master is Python 3 only.\n\u200bPR\nI think we should focus on using __qualname__ during migration serialization as wel",
      "claude_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -263,7 +263,10 @@ class TypeSerializer(BaseSerializer):\n         return cls(value)\n \n     def serialize(self):\n-        special_cases = [\n+        # Use __qualname__ for proper nested class support (e.g. Outer.Inner)\n+        # Fall back to __name__ if __qualname__ is not available\n+        attr_name = getattr(self.value, '__qualname__', self.value.__name__)\n+        special_cases = [\n             (models.Model, \"models.Model\", []),\n             (type(None), 'type(None)', []),\n         ]\n@@ -271,7 +274,7 @@ class TypeSerializer(BaseSerializer):\n             if case is self.value:\n                 return string, set(imports)\n         if hasattr(self.value, \"__module__\"):\n-            module = self.value.__module__\n+            module = self.value.__module__\n             if module == builtins.__name__:\n-                return self.value.__name__, set()\n+                return attr_name, set()\n             else:\n-                return \"%s.%s\" % (module, self.value.__name__), {\"import %s\" % module}\n+                return \"%s.%s\" % (module, attr_name), {\"import %s\" % module}",
      "generation_time": 7.816658973693848,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.040441036224365234,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12184",
      "repo": "django/django",
      "problem_statement": "Optional URL params crash some view functions.\nDescription\n\t\nMy use case, running fine with Django until 2.2:\nURLConf:\nurlpatterns += [\n\t...\n\tre_path(r'^module/(?P<format>(html|json|xml))?/?$', views.modules, name='modules'),\n]\nView:\ndef modules(request, format='html'):\n\t...\n\treturn render(...)\nWith Django 3.0, this is now producing an error:\nTraceback (most recent call last):\n File \"/l10n/venv/lib/python3.6/site-packages/django/core/handlers/exception.py\", line 34, in inner\n\tresponse = get_resp",
      "hints_text": "Tracked regression in 76b993a117b61c41584e95149a67d8a1e9f49dd1.\nIt seems to work if you remove the extra parentheses: re_path(r'^module/(?P<format>html|json|xml)?/?$', views.modules, name='modules'), ",
      "claude_patch": "# django/urls/resolvers.py\n\nimport re\nfrom django.urls.resolvers import RoutePattern, RegexPattern\n\n\n# Patch for RegexPattern class\noriginal_regex_pattern_init = RegexPattern.__init__\n\ndef patched_regex_pattern_init(self, regex, name=None, is_endpoint=False):\n    original_regex_pattern_init(self, regex, name, is_endpoint)\n    # Override the regex property to filter out unnamed groups\n    self._original_regex = self._regex\n    self._filtered_regex_string = self._filter_unnamed_groups(self._regex_string)\n    \ndef _filter_unnamed_groups(self, pattern):\n    \"\"\"Convert unnamed groups to non-capturing groups.\"\"\"\n    # This regex finds groups that are not named (?P<name>...) and not already non-capturing (?:...)\n    # We need to be careful to only convert capturing groups that are not named\n    result = []\n    i = 0\n    while i < len(pattern):\n        if pattern[i:i+2] == '(?':\n            if pattern[i:i+3] == '(?P':\n                # Named group - keep as is\n                result.append(pattern[i])\n                i += 1\n            elif pattern[i:i+3] == '(?:':\n                # Non-capturing group - keep as is\n                result.append(pattern[i])\n                i += 1\n            else:\n                # Unnamed capturing group - convert to non-capturing\n                result.append('(?:')\n                i += 2\n        else:\n            result.append(pattern[i])\n            i += 1\n    return ''.join(result)\n\nRegexPattern._filter_unnamed_groups = _filter_unnamed_groups\n\n\n# Better approach: Fix in the match method\noriginal_match = RegexPattern.match\n\ndef patched_match(self, path):\n    match = self.regex.search(path)\n    if match:\n        # Extract only named groups for kwargs\n        kwargs = {}\n        for key, value in match.groupdict().items():\n            if value is not None:\n                kwargs[key] = value\n        # Don't include positional args from unnamed groups\n        args = ()\n        return path[match.end():], args, kwargs\n    return None\n\nRegexPattern.match = patched_match",
      "generation_time": 22.76774501800537,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 15,
      "critical_issues": 0,
      "high_issues": 5,
      "medium_issues": 4,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.44666666666666655,
        "style": 0.68,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 33.3%",
        "HIGH: ast_analysis - Public function 'patched_regex_pattern_init' missing docstring - production documentation required",
        "HIGH: edge_case_coverage - Low edge case coverage: 66.7%"
      ],
      "verification_time": 0.1831519603729248,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12284",
      "repo": "django/django",
      "problem_statement": "Model.get_FOO_display() does not work correctly with inherited choices.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nGiven a base model with choices A containing 3 tuples\nChild Model inherits the base model overrides the choices A and adds 2 more tuples\nget_foo_display does not work correctly for the new tuples added\nExample:\nclass A(models.Model):\n foo_choice = [(\"A\",\"output1\"),(\"B\",\"output2\")]\n field_foo = models.CharField(max_length=254,choices=foo_choice)\n class Meta:\n\t abstract =",
      "hints_text": "Thanks for this report. Can you provide models and describe expected behavior? Can you also check if it's not a duplicate of #30931?, that was fixed in Django 2.2.7.\nReplying to felixxm: Thanks for th",
      "claude_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -763,8 +763,12 @@ class Field(RegisterLookupMixin):\n         self.model = cls\n         if private_only:\n             cls._meta.add_field(self, private=True)\n         else:\n             cls._meta.add_field(self)\n         if self.choices is not None:\n-            if not hasattr(cls, 'get_%s_display' % self.name):\n+            # Only set get_FOO_display if it's not defined in the current class\n+            # (not inherited). This allows proper inheritance of choices.\n+            if 'get_%s_display' % self.name not in cls.__dict__:\n                 setattr(\n                     cls,\n                     'get_%s_display' % self.name,",
      "generation_time": 5.330243110656738,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04292011260986328,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12286",
      "repo": "django/django",
      "problem_statement": "translation.E004 shouldn't be raised on sublanguages when a base language is available.\nDescription\n\t\nAccording to Django documentation:\nIf a base language is available but the sublanguage specified is not, Django uses the base language. For example, if a user specifies de-at (Austrian German) but Django only has de available, Django uses de.\nHowever, when using Django 3.0.2, if my settings.py has\nLANGUAGE_CODE = \"de-at\"\nI get this error message:\nSystemCheckError: System check identified some is",
      "hints_text": "Thanks for this report. Regression in 4400d8296d268f5a8523cd02ddc33b12219b2535.",
      "claude_patch": "# django/core/checks/translation.py\n\nfrom django.conf import settings\nfrom django.utils.translation import LANGUAGE_SESSION_KEY, get_supported_language_variant\n\nfrom . import Error, Tags, register\n\n\n@register(Tags.translation)\ndef check_setting_language_code(app_configs, **kwargs):\n    \"\"\"Error if LANGUAGE_CODE setting is invalid.\"\"\"\n    tag = settings.LANGUAGE_CODE\n    if not isinstance(tag, str) or not tag:\n        return [\n            Error(\n                'You have provided an invalid value for the LANGUAGE_CODE setting: {!r}.'.format(tag),\n                id='translation.E001',\n            ),\n        ]\n    \n    # Check if the language code or its base language is available\n    try:\n        get_supported_language_variant(tag)\n    except LookupError:\n        return [\n            Error(\n                'You have provided a value for the LANGUAGE_CODE setting that is not in '\n                'the LANGUAGES setting.',\n                id='translation.E004',\n            ),\n        ]\n    \n    return []\n\n\n@register(Tags.translation)\ndef check_setting_languages(app_configs, **kwargs):\n    \"\"\"Error if LANGUAGES setting is invalid.\"\"\"\n    return [\n        Error(\n            'You have provided an invalid value for the LANGUAGES setting: {!r}.'.format(settings.LANGUAGES),\n            id='translation.E002',\n        )\n    ] if not isinstance(settings.LANGUAGES, (list, tuple)) else []\n\n\n@register(Tags.translation)\ndef check_setting_languages_bidi(app_configs, **kwargs):\n    \"\"\"Error if LANGUAGES_BIDI setting is invalid.\"\"\"\n    return [\n        Error(\n            'You have provided an invalid value for the LANGUAGES_BIDI setting: {!r}.'.format(settings.LANGUAGES_BIDI),\n            id='translation.E003',\n        )\n    ] if not isinstance(settings.LANGUAGES_BIDI, (list, tuple)) else []\n\n\n@register(Tags.translation)\ndef check_language_settings_consistent(app_configs, **kwargs):\n    \"\"\"Error if language settings are not consistent with each other.\"\"\"\n    available_tags = {tag for tag, _ in settings.LANGUAGES} | {'en-us'}\n    if settings.LANGUAGE_CODE not in available_tags:\n        # Check if base language is available\n        language_code = settings.LANGUAGE_CODE\n        base_language = language_code.split('-')[0].lower()\n        \n        # Check if any language with this base exists\n        has_base_language = any(\n            tag.split('-')[0].lower() == base_language\n            for tag in available_tags\n        )\n        \n        if not has_base_language:\n            return [\n                Error(\n                    'You have provided a value for the LANGUAGE_CODE setting that is not in '\n                    'the LANGUAGES setting.',\n                    id='translation.E004',\n                ),\n            ]\n    return []",
      "generation_time": 10.992879867553711,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 15,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 7,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.45,
        "style": 0.78,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path",
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.10839700698852539,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12308",
      "repo": "django/django",
      "problem_statement": "JSONField are not properly displayed in admin when they are readonly.\nDescription\n\t\nJSONField values are displayed as dict when readonly in the admin.\nFor example, {\"foo\": \"bar\"} would be displayed as {'foo': 'bar'}, which is not valid JSON.\nI believe the fix would be to add a special case in django.contrib.admin.utils.display_for_field to call the prepare_value of the JSONField (not calling json.dumps directly to take care of the InvalidJSONInput case).\n",
      "hints_text": "\u200bPR\nThe proposed patch is problematic as the first version coupled contrib.postgres with .admin and the current one is based off the type name which is brittle and doesn't account for inheritance. It ",
      "claude_patch": "import json\nfrom django.contrib.admin.utils import display_for_field\nfrom django.core.serializers.json import DjangoJSONEncoder\nfrom django.db import models\n\n# Patch for django/contrib/admin/utils.py\n\ndef display_for_field(value, field, empty_value_display):\n    from django.contrib.admin.templatetags.admin_list import _boolean_icon\n    from django.contrib.admin.utils import lookup_field\n    from django.db import models\n    from django.utils.html import format_html\n    from django.utils.safestring import mark_safe\n    import json\n    from django.core.serializers.json import DjangoJSONEncoder\n\n    if getattr(field, 'flatchoices', None):\n        return dict(field.flatchoices).get(value, empty_value_display)\n    # BooleanField needs special-case null-handling, so it comes before the\n    # general null test.\n    elif isinstance(field, models.BooleanField):\n        return _boolean_icon(value)\n    elif value is None:\n        return empty_value_display\n    elif isinstance(field, models.DateTimeField):\n        return formats.localize(timezone.template_localtime(value))\n    elif isinstance(field, (models.DateField, models.TimeField)):\n        return formats.localize(value)\n    elif isinstance(field, models.DecimalField):\n        return formats.number_format(value, field.decimal_places)\n    elif isinstance(field, (models.IntegerField, models.FloatField)):\n        return formats.number_format(value)\n    elif isinstance(field, models.FileField) and value:\n        return format_html('<a href=\"{}\">{}</a>', value.url, value)\n    elif isinstance(field, models.JSONField):\n        try:\n            # Use the field's encoder if available\n            encoder = getattr(field, 'encoder', DjangoJSONEncoder)\n            return json.dumps(value, ensure_ascii=False, cls=encoder)\n        except (TypeError, ValueError):\n            return value\n    else:\n        return display_for_value(value, empty_value_display)",
      "generation_time": 16.093302011489868,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 2,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.7221631061577262,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: ast_analysis - Public function 'display_for_field' missing docstring - production documentation required",
        "HIGH: loop_nesting - Extreme loop nesting: 10 levels"
      ],
      "verification_time": 0.20811724662780762,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12453",
      "repo": "django/django",
      "problem_statement": "`TransactionTestCase.serialized_rollback` fails to restore objects due to ordering constraints\nDescription\n\t\nI hit this problem in a fairly complex projet and haven't had the time to write a minimal reproduction case. I think it can be understood just by inspecting the code so I'm going to describe it while I have it in mind.\nSetting serialized_rollback = True on a TransactionTestCase triggers \u200brollback emulation. In practice, for each database:\nBaseDatabaseCreation.create_test_db calls connecti",
      "hints_text": "I've run into a problem related to this one (just reported as #31051), so I ended up looking into this problem as well. The original report still seems accurate to me, with the proposed solution valid",
      "claude_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex bca8376..8e5c9a5 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -4,7 +4,7 @@ import time\n from django.apps import apps\n from django.conf import settings\n from django.core import serializers\n-from django.db import router\n+from django.db import router, transaction\n from django.utils.six import StringIO\n from django.utils.six.moves import input\n \n@@ -128,8 +128,12 @@ class BaseDatabaseCreation(object):\n         the serialize_db_to_string method.\n         \"\"\"\n         data = StringIO(data)\n-        for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n-            obj.save()\n+        with transaction.atomic(using=self.connection.alias):\n+            with self.connection.constraint_checks_disabled():\n+                for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n+                    obj.save()\n+            # Check constraints after all objects are saved\n+            self.connection.check_constraints()\n \n     def _get_database_display_str(self, verbosity, database_name):\n         \"\"\"",
      "generation_time": 5.376755952835083,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid decimal literal (<unknown>, line 2)",
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.038564205169677734,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12470",
      "repo": "django/django",
      "problem_statement": "Inherited model doesn't correctly order by \"-pk\" when specified on Parent.Meta.ordering\nDescription\n\t\nGiven the following model definition:\nfrom django.db import models\nclass Parent(models.Model):\n\tclass Meta:\n\t\tordering = [\"-pk\"]\nclass Child(Parent):\n\tpass\nQuerying the Child class results in the following:\n>>> print(Child.objects.all().query)\nSELECT \"myapp_parent\".\"id\", \"myapp_child\".\"parent_ptr_id\" FROM \"myapp_child\" INNER JOIN \"myapp_parent\" ON (\"myapp_child\".\"parent_ptr_id\" = \"myapp_parent\".",
      "hints_text": null,
      "claude_patch": "# File: django/db/models/sql/query.py\n\nfrom django.db.models.sql.query import Query\n\n# Store the original add_ordering method\n_original_add_ordering = Query.add_ordering\n\ndef patched_add_ordering(self, *ordering):\n    \"\"\"\n    Add items from the 'ordering' sequence to the query's \"order by\"\n    clause. These items are either field names (not column names) --\n    possibly with a direction prefix ('-' or '?') -- or OrderBy\n    expressions.\n    \n    If 'ordering' is empty, clear all ordering from the query.\n    \"\"\"\n    errors = []\n    for item in ordering:\n        if isinstance(item, str):\n            if item == '?':\n                continue\n            if item.startswith('-'):\n                descending = True\n                item_without_prefix = item[1:]\n            else:\n                descending = False\n                item_without_prefix = item\n            \n            # Check if this is 'pk' and needs special handling\n            if item_without_prefix == 'pk':\n                # Get the actual primary key field\n                field = self.get_meta().pk\n                if field:\n                    # Reconstruct the ordering with the actual field name\n                    if descending:\n                        item = '-' + field.name\n                    else:\n                        item = field.name\n        \n        errors.extend(self.add_ordering_item(item))\n    \n    if errors:\n        raise FieldError('Invalid order_by arguments: %s' % errors)\n\n# Monkey patch is not ideal, but we need to fix the actual issue in the codebase\n# The real fix should be in django/db/models/sql/query.py\n\n# Actually, let's look at the proper location for the fix:\n\n# File: django/db/models/sql/compiler.py\nfrom django.db.models.sql.compiler import SQLCompiler\n\n_original_get_order_by = SQLCompiler.get_order_by\n\ndef patched_get_order_by(self):\n    \"\"\"\n    Return a list of 2-tuples of the form (expr, (sql, params, is_ref)) for the\n    ORDER BY clause.\n    \n    The order_by clause can alter the select clause (for example it can add\n    aliases to clauses that do not yet have one, or it can add totally new\n    select clauses).\n    \"\"\"\n    if self.query.extra_order_by:\n        ordering = self.query.extra_order_by\n    elif not self.query.default_ordering:\n        ordering = self.query.order_by\n    else:\n        ordering = (self.query.order_by or self.query.get_meta().ordering or [])\n    \n    if ordering:\n        # Resolve 'pk' to the actual primary key field name while preserving direction\n        resolved_ordering = []\n        for item in ordering:\n            if isinstance(item, str):\n                if item == 'pk':\n                    resolved_ordering.append(self.query.get_meta().pk.name)\n                elif item == '-pk':\n                    resolved_ordering.append('-' + self.query.get_meta().pk.name)\n                else:\n                    resolved_ordering.append(item)\n            else:\n                resolved_ordering.append(item)\n        ordering = resolved_ordering\n    \n    return _original_get_order_by(self)\n\n# The actual fix needs to be in the Options class or where ordering is resolved\n# File: django/db/models/options.py\n\nfrom django.db.models.options import Options\n\n_original_ordering_property = Options.ordering\n\n@property\ndef patched_ordering(self):\n    \"\"\"\n    Return the ordering with 'pk' resolved to the actual primary key field.\n    \"\"\"\n    ordering = self._ordering\n    if ordering:\n        resolved = []\n        for item in ordering:\n            if isinstance(item, str):\n                if item == 'pk':\n                    resolved.append(self.pk.name)\n                elif item == '-pk':\n                    resolved.append('-' + self.pk.name)\n                else:\n                    resolved.append(item)\n            else:\n                resolved.append(item)\n        return tuple(resolved)\n    return ordering\n\n# Apply the patch\nOptions.ordering = patched_ordering",
      "generation_time": 28.868751049041748,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 14,
      "critical_issues": 0,
      "high_issues": 6,
      "medium_issues": 4,
      "low_issues": 4,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 0.55,
        "style": 0.7,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: logic - Low logic score: 0.40",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.1767578125,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12497",
      "repo": "django/django",
      "problem_statement": "Wrong hint about recursive relationship.\nDescription\n\t \n\t\t(last modified by Matheus Cunha Motta)\n\t \nWhen there's more than 2 ForeignKeys in an intermediary model of a m2m field and no through_fields have been set, Django will show an error with the following hint:\nhint=(\n\t'If you want to create a recursive relationship, '\n\t'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\nBut 'symmetrical' and 'through' are m2m keyword arguments, not ForeignKey.\nThis was probably a small mistake where the",
      "hints_text": "Here's a PR: \u200bhttps://github.com/django/django/pull/12497 Edit: forgot to run tests and there was an error detected in the PR. I'll try to fix and run tests before submitting again.",
      "claude_patch": "# File: django/db/models/fields/related.py\n\n# Find and replace the incorrect hint in the ManyToManyField validation\n\n# The fix should be in the _check_relationship_model method or similar validation method\n# that checks for ambiguous relationships in through models\n\n# Original code would be something like:\n# hint=(\n#     'If you want to create a recursive relationship, '\n#     'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n# )\n\n# Should be changed to:\n# hint=(\n#     'If you want to create a recursive relationship, '\n#     'use ManyToManyField(\"%s\", through=\"%s\").'\n# )\n\n# Let's find the actual location and fix it:\n\nfrom django.core import checks\nfrom django.db import models\n\n\ndef _check_relationship_model(self, from_model=None, **kwargs):\n    if hasattr(self, 'remote_field') and self.remote_field.through and not self.remote_field.through._meta.auto_created:\n        from_model = from_model or self.model\n        if isinstance(self.remote_field.through, str):\n            return []\n        \n        # Check if there are multiple foreign keys to the same model\n        seen_from = sum(\n            from_model == getattr(field.remote_field, 'model', None)\n            for field in self.remote_field.through._meta.fields\n            if hasattr(field, 'remote_field')\n        )\n        seen_to = sum(\n            self.remote_field.model == getattr(field.remote_field, 'model', None)\n            for field in self.remote_field.through._meta.fields\n            if hasattr(field, 'remote_field')\n        )\n        \n        if seen_from > 1 and seen_to > 1:\n            errors = [\n                checks.Error(\n                    \"The model is used as an intermediate model by \"\n                    \"'%s.%s', but it has more than one foreign key \"\n                    \"to '%s', which is ambiguous. You must specify \"\n                    \"which foreign key Django should use via the \"\n                    \"through_fields keyword argument.\" % (\n                        from_model._meta.object_name,\n                        self.name,\n                        from_model._meta.object_name,\n                    ),\n                    hint=(\n                        'If you want to create a recursive relationship, '\n                        'use ManyToManyField(\"%s\", through=\"%s\").' % (\n                            from_model._meta.object_name,\n                            self.remote_field.through._meta.object_name,\n                        )\n                    ),\n                    obj=self,\n                    id='fields.E335',\n                )\n            ]\n            return errors\n        elif seen_from > 1 or seen_to > 1:\n            errors = [\n                checks.Error(\n                    \"The model is used as an intermediate model by \"\n                    \"'%s.%s', but it has more than one foreign key \"\n                    \"from/to '%s', which is ambiguous. You must specify \"\n                    \"which foreign key Django should use via the \"\n                    \"through_fields keyword argument.\" % (\n                        from_model._meta.object_name,\n                        self.name,\n                        from_model._meta.object_name if seen_from > 1 else self.remote_field.model._meta.object_name,\n                    ),\n                    hint=(\n                        'If you want to create a recursive relationship, '\n                        'use ManyToManyField(\"%s\", through=\"%s\").' % (\n                            from_model._meta.object_name,\n                            self.remote_field.through._meta.object_name,\n                        )\n                    ),\n                    obj=self,\n                    id='fields.E335',\n                )\n            ]\n            return errors\n    \n    return []",
      "generation_time": 15.84498381614685,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 13,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 5,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8233333333333333,
        "style": 0.42800000000000016,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: ast_analysis - Function '_check_relationship_model' too long (67 lines) - production maintainability concern",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.17656874656677246,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12589",
      "repo": "django/django",
      "problem_statement": "Django 3.0: \"GROUP BY\" clauses error with tricky field annotation\nDescription\n\t\nLet's pretend that we have next model structure with next model's relations:\nclass A(models.Model):\n\tbs = models.ManyToManyField('B',\n\t\t\t\t\t\t\t\trelated_name=\"a\",\n\t\t\t\t\t\t\t\tthrough=\"AB\")\nclass B(models.Model):\n\tpass\nclass AB(models.Model):\n\ta = models.ForeignKey(A, on_delete=models.CASCADE, related_name=\"ab_a\")\n\tb = models.ForeignKey(B, on_delete=models.CASCADE, related_name=\"ab_b\")\n\tstatus = models.IntegerField()\nclass C",
      "hints_text": "This is due to a collision of AB.status and the status annotation. The easiest way to solve this issue is to disable group by alias when a collision is detected with involved table columns. This can b",
      "claude_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 1234567890..abcdefghij 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1940,6 +1940,17 @@ class Query(BaseExpression):\n                 expressions.extend(expr.get_source_expressions())\n             for expr in expressions:\n                 cols = expr.get_group_by_cols()\n+                # Check if alias collides with any column name in joined tables\n+                if alias is not None:\n+                    for table_alias in self.alias_map:\n+                        try:\n+                            table = self.alias_map[table_alias].table\n+                            if hasattr(table, 'model'):\n+                                field_names = {f.column for f in table.model._meta.get_fields() if hasattr(f, 'column')}\n+                                if alias in field_names:\n+                                    alias = None\n+                                    break\n+                        except (AttributeError, TypeError):\n+                            continue\n                 group_by.extend(cols)\n         self.group_by = tuple(group_by)",
      "generation_time": 18.956820011138916,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.046054840087890625,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12700",
      "repo": "django/django",
      "problem_statement": "Settings are cleaned insufficiently.\nDescription\n\t\nPosting publicly after checking with the rest of the security team.\nI just ran into a case where django.views.debug.SafeExceptionReporterFilter.get_safe_settings() would return several un-cleansed values. Looking at cleanse_setting() I realized that we \u200bonly take care of `dict`s but don't take other types of iterables into account but \u200breturn them as-is.\nExample:\nIn my settings.py I have this:\nMY_SETTING = {\n\t\"foo\": \"value\",\n\t\"secret\": \"value\",\n",
      "hints_text": "Do I need to change both versions? Or just create a single implementation for current master branch?",
      "claude_patch": "def cleanse_setting(self, key, value):\n    \"\"\"\n    Cleanse an individual setting key/value of sensitive content. If the\n    value is a dictionary, recursively cleanse the keys in that dictionary.\n    \"\"\"\n    try:\n        if self.hidden_settings.search(key):\n            cleansed = self.cleansed_substitute\n        elif isinstance(value, dict):\n            cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}\n        elif isinstance(value, (list, tuple)):\n            cleansed = type(value)(\n                self.cleanse_setting('', item) if isinstance(item, dict)\n                else self.cleanse_setting('', item) if isinstance(item, (list, tuple))\n                else item\n                for item in value\n            )\n        else:\n            cleansed = value\n    except TypeError:\n        # If the key isn't regex-able, just return as-is.\n        cleansed = value\n\n    if callable(cleansed):\n        cleansed = self.callables_substitute\n\n    return cleansed",
      "generation_time": 9.582522869110107,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 7,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 1,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.9474900980183243,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path",
        "HIGH: loop_nesting - Extreme loop nesting: 4 levels"
      ],
      "verification_time": 0.04312300682067871,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-12708",
      "repo": "django/django",
      "problem_statement": "Migration crashes deleting an index_together if there is a unique_together on the same fields\nDescription\n\t\nHappens with Django 1.11.10\nSteps to reproduce:\n1) Create models with 2 fields, add 2 same fields to unique_together and to index_together\n2) Delete index_together -> Fail\nIt will fail at django/db/backends/base/schema.py, line 378, in _delete_composed_index(), ValueError: Found wrong number (2) of constraints for as this one will find two constraints, the _uniq and the _idx one. No way to",
      "hints_text": "Reproduced on master at 623139b5d1bd006eac78b375bcaf5948e695c3c6.\nI haven't looked under the hood on this yet, but could it be related to the ordering of the operations generated for the mgiration? on",
      "claude_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 1234567890..abcdefghij 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -365,7 +365,7 @@ class BaseDatabaseSchemaEditor:\n         \"\"\"\n         meta_constraint_names = {constraint.name for constraint in model._meta.constraints}\n         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n-        columns = [model._meta.get_field(field).column for field in fields]\n+        columns = [model._meta.get_field(field).column for field in fields] if fields else []\n         constraint_names = self._constraint_names(\n             model,\n             columns,\n@@ -374,13 +374,28 @@ class BaseDatabaseSchemaEditor:\n             foreign_key=foreign_key,\n             primary_key=primary_key,\n         )\n-        if len(constraint_names) != 1:\n+        # Filter out constraints that shouldn't be deleted based on the index parameter\n+        if index is not None:\n+            # When index=True, we only want to delete indexes (not unique constraints)\n+            # When index=False, we only want to delete unique constraints (not indexes)\n+            filtered_constraint_names = []\n+            for constraint_name in constraint_names:\n+                # Check if this is an index by seeing if it's in meta_index_names\n+                # or if it follows the index naming pattern\n+                is_index = (\n+                    constraint_name in meta_index_names or\n+                    '_idx' in constraint_name or\n+                    not ('_uniq' in constraint_name or constraint_name in meta_constraint_names)\n+                )\n+                if (index and is_index) or (not index and not is_index):\n+                    filtered_constraint_names.append(constraint_name)\n+            constraint_names = filtered_constraint_names\n+        \n+        if len(constraint_names) != 1:\n             raise ValueError(\n                 \"Found wrong number (%s) of constraints for %s(%s)\" %\n                 (\n                     len(constraint_names),\n                     model._meta.db_table,\n-                    \", \".join(columns),\n+                    \", \".join(columns) if columns else \"\",\n                 )\n             )\n         self.execute(self._delete_constraint_sql(self.sql_delete_index, model, constraint_names[0]))\ndiff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex 2345678901..bcdefghijk 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -350,7 +350,7 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         return constraint_names\n \n     def _delete_composed_index(self, model, fields, *args):\n-        meta_constraint_names = {constraint.name for constraint in model._meta.constraints}\n+        meta_constraint_names = {constraint.name for constraint in model._meta.constraints if hasattr(constraint, 'name')}\n         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n         columns = [model._meta.get_field(field).column for field in fields]\n         constraint_names = self._constraint_names(\n@@ -360,6 +360,21 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             index=True,\n         ) - meta_constraint_names - meta_index_names\n         if len(constraint_names) != 1:\n+            # Try to filter by index type if we have multiple constraints\n+            # This handles the case where both unique_together and index_together exist\n+            index_only_names = []\n+            for name in constraint_names:\n+                # Check if this is an index (not a unique constraint)\n+                # by examining the constraint in the database\n+                with self.connection.cursor() as cursor:\n+                    cursor.execute(\n+                        \"SELECT sql FROM sqlite_master WHERE type='index' AND name=%s\",\n+                        [name]\n+                    )\n+                    result = cursor.fetchone()\n+                    if result and result[0] and 'UNIQUE' not in result[0].upper():\n+                        index_only_names.append(name)\n+            constraint_names = index_only_names if index_only_names else constraint_names\n+        if len(constraint_names) != 1:\n             raise ValueError(\n                 \"Found wrong number (%s) of constraints for %s(%s)\" %\n                 (",
      "generation_time": 17.104320764541626,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: unterminated triple-quoted string literal (detected at line 82) (<unknown>, line 6)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.04997396469116211,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12747",
      "repo": "django/django",
      "problem_statement": "QuerySet.Delete - inconsistent result when zero objects deleted\nDescription\n\t\nThe result format of the QuerySet.Delete method is a tuple: (X, Y) \nX - is the total amount of deleted objects (including foreign key deleted objects)\nY - is a dictionary specifying counters of deleted objects for each specific model (the key is the _meta.label of the model and the value is counter of deleted objects of this model).\nExample: <class 'tuple'>: (2, {'my_app.FileAccess': 1, 'my_app.File': 1})\nWhen there ar",
      "hints_text": "I guess we could adapt the code not to include any key if the count is zero in the second case.",
      "claude_patch": "# File: django/db/models/deletion.py\n\ndef delete(self):\n    \"\"\"\n    Delete the instances in the current QuerySet.\n    \"\"\"\n    # ... existing code ...\n    \n    # Find the location where the deletion results are being compiled\n    # and ensure that models with zero deletions are not added to the dictionary\n    \n    # The fix should be in the Collector class's delete method\n    # We need to modify how deleted_counter is populated\n\n# Patch for django/db/models/deletion.py\n\nfrom django.db import models, router, transaction\nfrom django.db.models import signals, sql\n\nclass Collector:\n    # ... existing code ...\n    \n    def delete(self):\n        # ... existing setup code ...\n        \n        # The issue is in how we build the deleted_counter dictionary\n        # We should only include entries where the count is > 0\n        \n        deleted_counter = {}\n        \n        # ... existing deletion logic ...\n        \n        # When building the result, filter out zero counts\n        for model, instances in self.data.items():\n            count = len(instances)\n            if count > 0:  # Only add to counter if count > 0\n                deleted_counter[model._meta.label] = count\n        \n        return sum(deleted_counter.values()), deleted_counter\n\n# The actual fix location in django/db/models/deletion.py\n\n# Original problematic code is around line 440-450 in Collector.delete()\n# We need to modify the part that builds deleted_counter\n\n# Here's the specific patch:\n\ndef delete(self):\n    # ... existing code before the return statement ...\n    \n    # Build the deleted counter, excluding zero counts\n    deleted_counter = {}\n    for model, instances in self.data.items():\n        count = len(instances)\n        if count > 0:\n            deleted_counter[model._meta.label] = count\n    \n    # ... rest of existing code ...\n    \n    return sum(deleted_counter.values()), deleted_counter",
      "generation_time": 18.63441300392151,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 13,
      "critical_issues": 0,
      "high_issues": 4,
      "medium_issues": 5,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.7556192706675355,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: ast_analysis - Public function 'delete' missing docstring - production documentation required",
        "HIGH: edge_case_coverage - Low edge case coverage: 66.7%"
      ],
      "verification_time": 0.17224717140197754,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12856",
      "repo": "django/django",
      "problem_statement": "Add check for fields of UniqueConstraints.\nDescription\n\t \n\t\t(last modified by Marnanel Thurman)\n\t \nWhen a model gains a UniqueConstraint, makemigrations doesn't check that the fields named therein actually exist.\nThis is in contrast to the older unique_together syntax, which raises models.E012 if the fields don't exist.\nIn the attached demonstration, you'll need to uncomment \"with_unique_together\" in settings.py in order to show that unique_together raises E012.\n",
      "hints_text": "Demonstration\nAgreed. We can simply call cls._check_local_fields() for UniqueConstraint's fields. I attached tests.\nTests.\nHello Django Team, My name is Jannah Mandwee, and I am working on my final pr",
      "claude_patch": "diff --git a/django/db/models/constraints.py b/django/db/models/constraints.py\nindex 1234567..abcdefg 100644\n--- a/django/db/models/constraints.py\n+++ b/django/db/models/constraints.py\n@@ -1,6 +1,7 @@\n from enum import Enum\n \n from django.db.models.query_utils import Q\n+from django.db.models.utils import resolve_callables\n from django.db.models.sql.query import Query\n \n __all__ = ['BaseConstraint', 'CheckConstraint', 'Deferrable', 'UniqueConstraint']\n@@ -81,6 +82,27 @@ class CheckConstraint(BaseConstraint):\n     def __eq__(self, other):\n         if isinstance(other, CheckConstraint):\n             return self.name == other.name and self.check == other.check\n         return super().__eq__(other)\n \n+    def _check(self, **kwargs):\n+        errors = super()._check(**kwargs)\n+        errors.extend(self._check_check_constraint())\n+        return errors\n+\n+    def _check_check_constraint(self):\n+        from django.db import models\n+        errors = []\n+        for field_name in self.check.flatten():\n+            if not hasattr(field_name, 'split'):\n+                continue\n+            if field_name.split('__')[0] not in [f.name for f in self.model._meta.get_fields()]:\n+                errors.append(\n+                    models.E012(\n+                        \"'%s' refers to the nonexistent field '%s'.\" % (\n+                            self.name, field_name,\n+                        ),\n+                        obj=self.model,\n+                    )\n+                )\n+        return errors\n+\n \n class Deferrable(Enum):\n@@ -159,6 +181,29 @@ class UniqueConstraint(BaseConstraint):\n             return (\n                 self.name == other.name and\n                 self.fields == other.fields and\n                 self.condition == other.condition and\n                 self.deferrable == other.deferrable and\n                 self.include == other.include and\n                 self.opclasses == other.opclasses\n             )\n         return super().__eq__(other)\n+\n+    def _check(self, **kwargs):\n+        errors = super()._check(**kwargs)\n+        errors.extend(self._check_unique_constraint_fields())\n+        return errors\n+\n+    def _check_unique_constraint_fields(self):\n+        from django.db import models\n+        errors = []\n+        for field_name in self.fields:\n+            try:\n+                self.model._meta.get_field(field_name)\n+            except models.FieldDoesNotExist:\n+                errors.append(\n+                    models.E012(\n+                        \"'constraints' refers to the nonexistent field '%s'.\" % field_name,\n+                        obj=self.model,\n+                    )\n+                )\n+        return errors",
      "generation_time": 22.298759937286377,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.058094024658203125,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12908",
      "repo": "django/django",
      "problem_statement": "Union queryset should raise on distinct().\nDescription\n\t \n\t\t(last modified by Sielc Technologies)\n\t \nAfter using\n.annotate() on 2 different querysets\nand then .union()\n.distinct() will not affect the queryset\n\tdef setUp(self) -> None:\n\t\tuser = self.get_or_create_admin_user()\n\t\tSample.h.create(user, name=\"Sam1\")\n\t\tSample.h.create(user, name=\"Sam2 acid\")\n\t\tSample.h.create(user, name=\"Sam3\")\n\t\tSample.h.create(user, name=\"Sam4 acid\")\n\t\tSample.h.create(user, name=\"Dub\")\n\t\tSample.h.create(user, name=\"",
      "hints_text": "distinct() is not supported but doesn't raise an error yet. As \u200b\u200bper the documentation, \"only LIMIT, OFFSET, COUNT(*), ORDER BY, and specifying columns (i.e. slicing, count(), order_by(), and values()",
      "claude_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1234,6 +1234,8 @@ class QuerySet:\n         assert not self.query.is_sliced, \\\n             \"Cannot create distinct fields once a slice has been taken.\"\n         obj = self._chain()\n+        if obj.query.combinator:\n+            raise NotSupportedError('Calling distinct() after union() is not supported.')\n         obj.query.add_distinct_fields(*field_names)\n         return obj",
      "generation_time": 9.11375093460083,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04244804382324219,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12915",
      "repo": "django/django",
      "problem_statement": "Add get_response_async for ASGIStaticFilesHandler\nDescription\n\t\nIt looks like the StaticFilesHandlerMixin is missing the the async response function.\nWithout this, when trying to use the ASGIStaticFilesHandler, this is the traceback:\nException inside application: 'NoneType' object is not callable\nTraceback (most recent call last):\n File \".../lib/python3.7/site-packages/daphne/cli.py\", line 30, in asgi\n\tawait self.app(scope, receive, send)\n File \".../src/django/django/contrib/staticfiles/handlers",
      "hints_text": null,
      "claude_patch": "# django/contrib/staticfiles/handlers.py\n\nfrom django.core.handlers.asgi import ASGIHandler\nfrom django.core.handlers.wsgi import WSGIHandler\nfrom django.http import Http404\nfrom django.utils.functional import cached_property\nfrom django.contrib.staticfiles import finders\nfrom django.contrib.staticfiles.views import serve\nfrom asgiref.sync import sync_to_async\n\n\nclass StaticFilesHandlerMixin:\n    \"\"\"\n    Common methods used by WSGI and ASGI handlers.\n    \"\"\"\n    # May be used to differentiate between handler types (e.g., in a\n    # request_finished signal)\n    handles_files = True\n\n    def load_middleware(self):\n        # Middleware are already loaded for self.application; no need to reload\n        # them for self.\n        pass\n\n    def get_base_url(self):\n        utils_module = import_module('django.contrib.staticfiles.utils')\n        return utils_module.get_files_url()\n\n    @cached_property\n    def base_url(self):\n        return self.get_base_url()\n\n    def _should_handle(self, path):\n        \"\"\"\n        Check if the path should be handled. Ignore the path if:\n        * the host is provided as part of the base_url\n        * the request's path isn't under the media path (or equal)\n        \"\"\"\n        return path.startswith(self.base_url[2]) and not self.base_url[1]\n\n    def file_path(self, url):\n        \"\"\"\n        Return the relative path to the media file on disk for the given URL.\n        \"\"\"\n        relative_url = url[len(self.base_url[2]):]\n        return url2pathname(relative_url)\n\n    def serve(self, request):\n        \"\"\"Serve the request path.\"\"\"\n        return serve(request, self.file_path(request.path), insecure=True)\n\n    def get_response(self, request):\n        try:\n            return self.serve(request)\n        except Http404 as e:\n            return response_for_exception(request, e)\n\n    async def get_response_async(self, request):\n        try:\n            return await sync_to_async(self.serve, thread_sensitive=False)(request)\n        except Http404 as e:\n            return await sync_to_async(response_for_exception, thread_sensitive=False)(request, e)\n\n\nclass StaticFilesHandler(StaticFilesHandlerMixin, WSGIHandler):\n    \"\"\"\n    WSGI middleware that intercepts calls to the static files directory, as\n    defined by the STATIC_URL setting, and serves those files.\n    \"\"\"\n    def __init__(self, application):\n        self.application = application\n        self.base_url = urlparse(self.get_base_url())\n        super().__init__()\n\n    def __call__(self, environ, start_response):\n        if not self._should_handle(get_path_info(environ)):\n            return self.application(environ, start_response)\n        return super().__call__(environ, start_response)\n\n\nclass ASGIStaticFilesHandler(StaticFilesHandlerMixin, ASGIHandler):\n    \"\"\"\n    ASGI application which wraps another and intercepts requests for static\n    files, passing them off to Django's static file serving.\n    \"\"\"\n    def __init__(self, application):\n        self.application = application\n        self.base_url = urlparse(self.get_base_url())\n        super().__init__()\n\n    async def __call__(self, scope, receive, send):\n        # Only even look at HTTP requests\n        if scope['type'] == 'http' and self._should_handle(scope['path']):\n            # Serve static content\n            # (the one thing super() doesn't do is __call__, apparently)\n            return await super().__call__(scope, receive, send)\n        # Hand off to the main app\n        return await self.application(scope, receive, send)\n\n\ndef import_module(name):\n    \"\"\"Import a module by name.\"\"\"\n    from importlib import import_module as _import_module\n    return _import_module(name)\n\n\ndef urlparse(url):\n    \"\"\"Parse a URL into components.\"\"\"\n    from urllib.parse import urlparse as _urlparse\n    return _urlparse(url)\n\n\ndef url2pathname(path):\n    \"\"\"Convert URL path to filesystem path.\"\"\"\n    from urllib.request import url2pathname as _url2pathname\n    return _url2pathname(path)\n\n\ndef get_path_info(environ):\n    \"\"\"Get the path info from WSGI environ.\"\"\"\n    from django.core.handlers.wsgi import get_path_info as _get_path_info\n    return _get_path_info(environ)\n\n\ndef response_for_exception(request, exc):\n    \"\"\"Get response for an exception.\"\"\"\n    from django.core.handlers.exception import response_for_exception as _response_for_exception\n    return _response_for_exception(request, exc)",
      "generation_time": 20.18037509918213,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 37,
      "critical_issues": 0,
      "high_issues": 8,
      "medium_issues": 21,
      "low_issues": 8,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.496,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: missing_input_validation - Function 'response_for_exception' missing input validation for production safety",
        "HIGH: missing_edge_case - Function 'response_for_exception' missing None value handling",
        "HIGH: contract_violation - Function 'response_for_exception' docstring mentions exceptions but none are raised"
      ],
      "verification_time": 0.23186516761779785,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-12983",
      "repo": "django/django",
      "problem_statement": "Make django.utils.text.slugify() strip dashes and underscores\nDescription\n\t \n\t\t(last modified by Elinaldo do Nascimento Monteiro)\n\t \nBug generation slug\nExample:\nfrom django.utils import text\ntext.slugify(\"___This is a test ---\")\noutput: ___this-is-a-test-\nImprovement after correction\nfrom django.utils import text\ntext.slugify(\"___This is a test ---\")\noutput: this-is-a-test\n\u200bPR\n",
      "hints_text": "The current version of the patch converts all underscores to dashes which (as discussed on the PR) isn't an obviously desired change. A discussion is needed to see if there's consensus about that chan",
      "claude_patch": "import re\nimport unicodedata\n\n\ndef slugify(value, allow_unicode=False):\n    \"\"\"\n    Convert to ASCII if 'allow_unicode' is False. Convert spaces or repeated\n    dashes to single dashes. Remove characters that aren't alphanumerics,\n    underscores, or hyphens. Convert to lowercase. Also strip leading and\n    trailing whitespace, dashes, and underscores.\n    \"\"\"\n    value = str(value)\n    if allow_unicode:\n        value = unicodedata.normalize('NFKC', value)\n    else:\n        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n    value = re.sub(r'[^\\w\\s-]', '', value.lower())\n    return re.sub(r'[-\\s]+', '-', value).strip('-_')",
      "generation_time": 5.27709698677063,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 10,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 2,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8333333333333334,
        "style": 0.9319999999999999,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%"
      ],
      "verification_time": 0.041522979736328125,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-13028",
      "repo": "django/django",
      "problem_statement": "Queryset raises NotSupportedError when RHS has filterable=False attribute.\nDescription\n\t \n\t\t(last modified by Nicolas Baccelli)\n\t \nI'm migrating my app to django 3.0.7 and I hit a strange behavior using a model class with a field labeled filterable\nclass ProductMetaDataType(models.Model):\n\tlabel = models.CharField(max_length=255, unique=True, blank=False, null=False)\n\tfilterable = models.BooleanField(default=False, verbose_name=_(\"filterable\"))\n\tclass Meta:\n\t\tapp_label = \"adminpricing\"\n\t\tverbose",
      "hints_text": "Thanks for the report, that's a nice edge case. We should be able to fix this by checking if rhs is an expression: diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index ce18",
      "claude_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..ad981377a0 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1124,7 +1124,7 @@ class Query(BaseExpression):\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        if hasattr(expression, 'resolve_expression') and not getattr(expression, 'filterable', True):\n             raise NotSupportedError(\n                 expression.__class__.__name__ + ' is disallowed in the filter '\n                 'clause.'",
      "generation_time": 3.5461058616638184,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.038374900817871094,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13033",
      "repo": "django/django",
      "problem_statement": "Self referencing foreign key doesn't correctly order by a relation \"_id\" field.\nDescription\n\t\nInitially discovered on 2.2.10 but verified still happens on 3.0.6. Given the following models:\nclass OneModel(models.Model):\n\tclass Meta:\n\t\tordering = (\"-id\",)\n\tid = models.BigAutoField(primary_key=True)\n\troot = models.ForeignKey(\"OneModel\", on_delete=models.CASCADE, null=True)\n\toneval = models.BigIntegerField(null=True)\nclass TwoModel(models.Model):\n\tid = models.BigAutoField(primary_key=True)\n\trecord ",
      "hints_text": "This is with a postgres backend. Fairly vanilla Django. Some generic middleware installed (cors, csrf, auth, session). Apps are: INSTALLED_APPS = ( \"django.contrib.contenttypes\", \"django.contrib.auth\"",
      "claude_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex abbb1e37cb..a8f5b61fbe 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -727,7 +727,7 @@ class SQLCompiler:\n             # If we get to this point and the field is a relation to another model,\n             # append the default ordering for that model unless it is the pk\n             # shortcut or the attribute name of the field that is specified.\n-            if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk':\n+            if field.is_relation and opts.ordering and getattr(field, 'attname', None) != pieces[-1] and name != 'pk':\n                 # Firstly, avoid infinite loops.\n                 already_seen = already_seen or set()\n                 join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)",
      "generation_time": 4.399239778518677,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.03932809829711914,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13158",
      "repo": "django/django",
      "problem_statement": "QuerySet.none() on combined queries returns all results.\nDescription\n\t\nI came across this issue on Stack Overflow. I'm not 100% sure it's a bug, but it does seem strange. With this code (excuse the bizarre example filtering):\nclass Publication(models.Model):\n\tpass\nclass Article(models.Model):\n\tpublications = models.ManyToManyField(to=Publication, blank=True, null=True)\nclass ArticleForm(forms.ModelForm):\n\tpublications = forms.ModelMultipleChoiceField(\n\t\tPublication.objects.filter(id__lt=2) | Pub",
      "hints_text": "Thanks for the report. QuerySet.none() doesn't work properly on combined querysets, it returns all results instead of an empty queryset.",
      "claude_patch": "# File: django/db/models/query.py\n\ndef none(self):\n    \"\"\"Return an empty QuerySet.\"\"\"\n    if self.query.combinator:\n        clone = self._chain()\n        clone.query.set_empty()\n        return clone\n    clone = self._chain()\n    clone.query.set_empty()\n    return clone",
      "generation_time": 17.514339208602905,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 3,
      "low_issues": 3,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.7266666666666667,
        "style": 0.874,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 63.3%",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.049137115478515625,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13220",
      "repo": "django/django",
      "problem_statement": "Allow ValidationErrors to equal each other when created identically\nDescription\n\t \n\t\t(last modified by kamni)\n\t \nCurrently ValidationErrors (django.core.exceptions.ValidationError) that have identical messages don't equal each other, which is counter-intuitive, and can make certain kinds of testing more complicated. Please add an __eq__ method that allows two ValidationErrors to be compared. \nIdeally, this would be more than just a simple self.messages == other.messages. It would be most helpful",
      "hints_text": "I probably wouldn't want to limit the comparison to an error's message but rather to its full set of attributes (message, code, params). While params is always pushed into message when iterating over ",
      "claude_patch": "def __eq__(self, other):\n    if not isinstance(other, ValidationError):\n        return NotImplemented\n    \n    # Compare error_dict if both have it\n    if hasattr(self, 'error_dict') and hasattr(other, 'error_dict'):\n        if set(self.error_dict.keys()) != set(other.error_dict.keys()):\n            return False\n        for key in self.error_dict.keys():\n            self_errors = self.error_dict[key]\n            other_errors = other.error_dict[key]\n            if len(self_errors) != len(other_errors):\n                return False\n            # Compare as sets to be order-independent\n            self_set = {(e.message, e.code, tuple(sorted(e.params.items())) if e.params else None) for e in self_errors}\n            other_set = {(e.message, e.code, tuple(sorted(e.params.items())) if e.params else None) for e in other_errors}\n            if self_set != other_set:\n                return False\n        return True\n    \n    # Compare error_list if both have it\n    if hasattr(self, 'error_list') and hasattr(other, 'error_list'):\n        if len(self.error_list) != len(other.error_list):\n            return False\n        # Compare as sets to be order-independent\n        self_set = {(e.message, e.code, tuple(sorted(e.params.items())) if e.params else None) for e in self.error_list}\n        other_set = {(e.message, e.code, tuple(sorted(e.params.items())) if e.params else None) for e in other.error_list}\n        return self_set == other_set\n    \n    # If one has error_dict and other has error_list, they're not equal\n    if hasattr(self, 'error_dict') != hasattr(other, 'error_dict'):\n        return False\n    if hasattr(self, 'error_list') != hasattr(other, 'error_list'):\n        return False\n    \n    # Fallback to comparing messages\n    return self.messages == other.messages\n\ndef __hash__(self):\n    # Since we're implementing __eq__, we should make the object unhashable\n    # to avoid issues with dict/set usage, as ValidationError is mutable\n    raise TypeError(\"unhashable type: 'ValidationError'\")",
      "generation_time": 9.32982873916626,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 12,
      "critical_issues": 0,
      "high_issues": 5,
      "medium_issues": 2,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.45,
        "style": 0.7112853916011771,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.10",
        "HIGH: edge_case_coverage - Low edge case coverage: 50.0%"
      ],
      "verification_time": 0.05811190605163574,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13230",
      "repo": "django/django",
      "problem_statement": "Add support for item_comments to syndication framework\nDescription\n\t\nAdd comments argument to feed.add_item() in syndication.views so that item_comments can be defined directly without having to take the detour via item_extra_kwargs .\nAdditionally, comments is already explicitly mentioned in the feedparser, but not implemented in the view.\n",
      "hints_text": null,
      "claude_patch": "diff --git a/django/contrib/syndication/views.py b/django/contrib/syndication/views.py\nindex 1234567890..abcdef1234 100644\n--- a/django/contrib/syndication/views.py\n+++ b/django/contrib/syndication/views.py\n@@ -127,6 +127,7 @@ class Feed:\n     item_author_link = None\n     item_author_email = None\n     item_enclosures = ()\n+    item_comments = None\n \n     item_pubdate = None\n     item_updateddate = None\n@@ -203,6 +204,11 @@ class Feed:\n             title_tmp = title_template.render(context, request)\n         return title_tmp\n \n+    def _get_dynamic_attr(self, attname, obj, default=None):\n+        try:\n+            attr = getattr(self, attname)\n+        except AttributeError:\n+            return default\n+        if callable(attr):\n+            # Check co_argcount rather than try/excepting the function and\n+            # catching the TypeError, because something inside the function\n+            # may raise the TypeError. This technique is more accurate.\n+            try:\n+                code = attr.__code__\n+            except AttributeError:\n+                code = attr.__call__.__code__\n+            if code.co_argcount == 2:  # one argument is 'self'\n+                return attr(obj)\n+            else:\n+                return attr()\n+        return attr\n+\n     def __get_dynamic_attr(self, attname, obj, default=None):\n         try:\n             attr = getattr(self, attname)\n@@ -265,6 +271,7 @@ class Feed:\n                 author_link=author_link,\n                 author_email=author_email,\n                 categories=self._get_dynamic_attr(\"item_categories\", item),\n+                comments=self._get_dynamic_attr(\"item_comments\", item),\n                 item_copyright=self._get_dynamic_attr(\"item_copyright\", item),\n                 **self.item_extra_kwargs(item)\n             )\ndiff --git a/django/utils/feedgenerator.py b/django/utils/feedgenerator.py\nindex 2345678901..bcdef12345 100644\n--- a/django/utils/feedgenerator.py\n+++ b/django/utils/feedgenerator.py\n@@ -77,6 +77,7 @@ class SyndicationFeed:\n         author_link=None,\n         author_email=None,\n         categories=(),\n+        comments=None,\n         item_copyright=None,\n         **kwargs\n     ):\n@@ -96,6 +97,7 @@ class SyndicationFeed:\n             \"author_link\": author_link,\n             \"author_email\": author_email,\n             \"categories\": categories or (),\n+            \"comments\": comments,\n             \"item_copyright\": item_copyright,\n         }\n         self.items.append(item)\n@@ -293,6 +295,8 @@ class RssFeed(SyndicationFeed):\n             handler.addQuickElement(\"guid\", item[\"unique_id\"], attrs=attrs)\n         if item[\"ttl\"] is not None:\n             handler.addQuickElement(\"ttl\", item[\"ttl\"])\n+        if item[\"comments\"] is not None:\n+            handler.addQuickElement(\"comments\", item[\"comments\"])\n \n         # Enclosures.\n         for enclosure in item[\"enclosures\"]:",
      "generation_time": 14.380729913711548,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.04968905448913574,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13265",
      "repo": "django/django",
      "problem_statement": "AlterOrderWithRespectTo() with ForeignKey crash when _order is included in Index().\nDescription\n\t\n\tclass Meta:\n\t\tdb_table = 'look_image'\n\t\torder_with_respect_to = 'look'\n\t\tindexes = [\n\t\t\tmodels.Index(fields=['look', '_order']),\n\t\t\tmodels.Index(fields=['created_at']),\n\t\t\tmodels.Index(fields=['updated_at']),\n\t\t]\nmigrations.CreateModel(\n\t\t\tname='LookImage',\n\t\t\tfields=[\n\t\t\t\t('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n\t\t\t\t('look', models.ForeignK",
      "hints_text": "Thanks for this report. IMO order_with_respect_to should be included in CreateModel()'s options, I'm not sure why it is in a separate operation when it refers to a ForeignKey.\nI reproduced the issue a",
      "claude_patch": "# django/db/migrations/autodetector.py\n\ndef _sort_migrations(self, operations):\n    \"\"\"\n    Reorder operations to ensure AlterOrderWithRespectTo comes before\n    AddIndex operations that reference the _order field.\n    \"\"\"\n    from django.db.migrations.operations import AddIndex, AlterOrderWithRespectTo\n    \n    # Find all AlterOrderWithRespectTo operations and their positions\n    alter_order_ops = []\n    add_index_ops = []\n    \n    for i, operation in enumerate(operations):\n        if isinstance(operation, AlterOrderWithRespectTo):\n            alter_order_ops.append((i, operation))\n        elif isinstance(operation, AddIndex):\n            add_index_ops.append((i, operation))\n    \n    # Check if any AddIndex references _order field\n    for add_idx_pos, add_idx_op in add_index_ops:\n        if '_order' in add_idx_op.index.fields:\n            # Find corresponding AlterOrderWithRespectTo for same model\n            for alter_pos, alter_op in alter_order_ops:\n                if alter_op.name_lower == add_idx_op.model_name_lower:\n                    # If AddIndex comes before AlterOrderWithRespectTo, we need to reorder\n                    if add_idx_pos < alter_pos:\n                        # Move AlterOrderWithRespectTo before AddIndex\n                        operations.insert(add_idx_pos, operations.pop(alter_pos))\n                        # Recursively sort in case there are multiple such operations\n                        return self._sort_migrations(operations)\n    \n    return operations\n\n\n# Patch the generate_altered_options method in django/db/migrations/autodetector.py\ndef generate_altered_options(self):\n    \"\"\"\n    Work out if any non-schema-affecting options have changed and make an\n    operation to represent them in state changes (in case Python code in\n    migrations needs them).\n    \"\"\"\n    models_to_check = self.kept_model_keys.union(\n        set(self.old_model_keys).intersection(self.new_model_keys)\n    )\n\n    for app_label, model_name in sorted(models_to_check):\n        old_model_name = self.renamed_models.get(\n            (app_label, model_name), model_name\n        )\n        old_model_state = self.from_state.models[app_label, old_model_name]\n        new_model_state = self.to_state.models[app_label, model_name]\n        old_options = old_model_state.options\n        new_options = new_model_state.options\n\n        option_keys = {\n            key\n            for key in self.ALTER_OPTION_KEYS\n            if key in old_options or key in new_options\n        }\n\n        if option_keys:\n            options_changed = False\n            for key in option_keys:\n                if old_options.get(key) != new_options.get(key):\n                    options_changed = True\n                    break\n\n            if options_changed:\n                self.add_operation(\n                    app_label,\n                    operations.AlterModelOptions(\n                        name=model_name,\n                        options={\n                            key: new_options.get(key)\n                            for key in option_keys\n                            if key not in (\"order_with_respect_to\",)\n                        },\n                    ),\n                    dependencies=[(app_label, model_name, None, True)],\n                )\n\n\n# Patch the generate_altered_order_with_respect_to method\ndef generate_altered_order_with_respect_to(self):\n    for app_label, model_name in sorted(\n        self.kept_model_keys.union(self.kept_proxy_keys)\n    ):\n        old_model_name = self.renamed_models.get(\n            (app_label, model_name), model_name\n        )\n        old_model_state = self.from_state.models[app_label, old_model_name]\n        new_model_state = self.to_state.models[app_label, model_name]\n        \n        old_order_with_respect_to = old_model_state.options.get(\n            \"order_with_respect_to\"\n        )\n        new_order_with_respect_to = new_model_state.options.get(\n            \"order_with_respect_to\"\n        )\n        \n        if old_order_with_respect_to != new_order_with_respect_to:\n            # Determine dependencies - should come before any index operations\n            dependencies = []\n            if new_order_with_respect_to:\n                dependencies.append((app_label, model_name, None, True))\n                # Add dependency on the related field if it's a ForeignKey\n                related_field_name = new_order_with_respect_to\n                for field_name, field in new_model_state.fields:\n                    if field_name == related_field_name:\n                        if hasattr(field, 'remote_field') and field.remote_field:\n                            related_app_label, related_model_name = (\n                                field.remote_field.model.split('.')\n                                if isinstance(field.remote_field.model, str) and '.' in field.remote_field.model\n                                else (app_label, field.remote_field.model)\n                            )\n                            dependencies.append(\n                                (related_app_label, related_model_name, None, True)\n                            )\n                        break\n            else:\n                dependencies.append((app_label, model_name, None, True))\n            \n            self.add_operation(\n                app_label,\n                operations.AlterOrderWithRespectTo(\n                    name=model_name,\n                    order_with_respect_to=new_order_with_respect_to,\n                ),\n                dependencies=dependencies,\n            )\n\n\n# Patch the _generate_added_indexes method to add proper dependencies\ndef _generate_added_indexes(self):\n    for app_label, model_name in sorted(self.kept_model_keys):\n        old_model_name = self.renamed_models.get(\n            (app_label, model_name), model_name\n        )\n        old_model_state = self.from_state.models[app_label, old_model_name]\n        new_model_state = self.to_state.models[app_label, model_name]\n\n        old_indexes = old_model_state.options.get(\"indexes\", [])\n        new_indexes = new_model_state.options.get(\"indexes\", [])\n        added_indexes = [idx for idx in new_indexes if idx not in old_indexes]\n\n        for index in added_indexes:\n            dependencies = []\n            # Check if index references _order field\n            if hasattr(index, 'fields') and '_order' in index.fields:\n                # Add dependency to ensure AlterOrderWithRespectTo runs first\n                new_order_with_respect_to = new_model_state.options.get(\n                    \"order_with_respect_to\"\n                )\n                if new_order_with_respect_to:\n                    # This index depends on the _order field being created\n                    dependencies.append((app_label, model_name, \"_order\", True))\n            \n            self.add_operation(\n                app_label,\n                operations.AddIndex(\n                    model_name=model_name,\n                    index=index,\n                ),\n                dependencies=dependencies or [(app_label, model_name, None, True)],\n            )\n\n\n# Main patch to django/db/migrations/autodetector.py\nfrom django.db.migrations.autodetector import MigrationAutodetector\n\noriginal_arrange_for_graph = MigrationAutodetector.arrange_for_graph\n\ndef patched_arrange_for_graph(self, changes, graph, migration_name=None):\n    \"\"\"\n    Patch to ensure AlterOrderWithRespectTo operations come before\n    AddIndex operations that reference _order field.\n    \"\"\"\n    from django.db.migrations.operations import AddIndex, AlterOrderWithRespectTo\n    \n    # First, call the original method\n    result = original_arrange_for_graph(self, changes, graph, migration_name)\n    \n    # Then reorder operations in each app's migrations\n    for app_label, app_migrations in result.items():\n        for migration in app_migrations:\n            operations = migration.operations\n            \n            # Find AlterOrderWithRespectTo and AddIndex operations\n            reordered = False\n            for i in range(len(operations)):\n                if isinstance(operations[i], AddIndex):\n                    add_index_op = operations[i]\n                    # Check if this index references _order\n                    if hasattr(add_index_op.index, 'fields') and '_order' in add_index_op.index.fields:\n                        # Look for AlterOrderWithRespectTo for the same model after this operation\n                        for j in range(i + 1, len(operations)):\n                            if isinstance(operations[j], AlterOrderWithRespectTo):\n                                alter_op = operations[j]\n                                if alter_op.name_lower == add_index_op.model_name_lower:\n                                    # Move AlterOrderWithRespectTo before AddIndex\n                                    operations.insert(i, operations.pop(j))\n                                    reordered = True\n                                    break\n                        if reordered:\n                            break\n    \n    return result\n\nMigrationAutodetector.arrange_for_graph = patched_arrange_for_graph",
      "generation_time": 35.62756109237671,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 24,
      "critical_issues": 0,
      "high_issues": 11,
      "medium_issues": 5,
      "low_issues": 8,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.3640000000000001,
        "performance": 0.838
      },
      "key_issues": [
        "HIGH: performance_bottleneck - Performance bottleneck: Deep nested loops (3 levels)",
        "HIGH: performance_bottleneck - Performance bottleneck: Deep nested loops (4 levels)",
        "HIGH: exception_coverage - Low exception handling coverage: 40.0%"
      ],
      "verification_time": 0.22493410110473633,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13315",
      "repo": "django/django",
      "problem_statement": "limit_choices_to on a ForeignKey can render duplicate options in formfield\nDescription\n\t\nIf you pass a Q object as limit_choices_to on a ForeignKey field involving a join, you may end up with duplicate options in your form.\nSee regressiontest in patch for a clear view on the problem.\n",
      "hints_text": "Replying to SmileyChris: I've updated the patch to resolve the conflicts I've had since you flagged this one as \"Ready for checkin\". No real change.\nupdate resolving conflict\nIs there something I can ",
      "claude_patch": "# django/forms/models.py\n\ndef apply_limit_choices_to_to_formfield(formfield):\n    \"\"\"Apply limit_choices_to to a formfield.\"\"\"\n    if hasattr(formfield, 'queryset') and hasattr(formfield, 'limit_choices_to'):\n        limit_choices_to = formfield.limit_choices_to\n        if limit_choices_to is not None:\n            if isinstance(limit_choices_to, dict):\n                formfield.queryset = formfield.queryset.filter(**limit_choices_to)\n            else:\n                formfield.queryset = formfield.queryset.filter(limit_choices_to)\n\n\n# django/db/models/fields/related.py\n\ndef formfield(self, **kwargs):\n    \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n    db = kwargs.pop('using', None)\n    if isinstance(self.remote_field.model, str):\n        raise ValueError(\"Cannot create form field for %r yet, because \"\n                         \"its related model %r has not been loaded yet\" %\n                         (self.name, self.remote_field.model))\n    defaults = {\n        'form_class': forms.ModelChoiceField,\n        'queryset': self.remote_field.model._default_manager.using(db),\n        'to_field_name': self.remote_field.field_name,\n    }\n    defaults.update(kwargs)\n    \n    # Apply limit_choices_to\n    if self.remote_field.limit_choices_to:\n        limit_choices_to = self.remote_field.limit_choices_to\n        if callable(limit_choices_to):\n            limit_choices_to = limit_choices_to()\n        if isinstance(limit_choices_to, dict):\n            defaults['queryset'] = defaults['queryset'].filter(**limit_choices_to)\n        else:\n            # Q object or other complex query\n            defaults['queryset'] = defaults['queryset'].filter(limit_choices_to)\n    \n    return super().formfield(**defaults)\n\n\n# django/forms/models.py - ModelChoiceIterator modification\n\nclass ModelChoiceIterator:\n    def __init__(self, field):\n        self.field = field\n        self.queryset = field.queryset\n\n    def __iter__(self):\n        if self.field.empty_label is not None:\n            yield (\"\", self.field.empty_label)\n        queryset = self.queryset\n        # Ensure that the queryset is evaluated, and that we only iterate\n        # over unique primary keys to avoid duplicates from joins\n        seen_pks = set()\n        for obj in queryset:\n            pk = obj.pk\n            if pk not in seen_pks:\n                seen_pks.add(pk)\n                yield self.choice(obj)\n\n    def __len__(self):\n        # Count unique PKs to handle duplicates from joins\n        seen_pks = set()\n        for obj in self.queryset:\n            seen_pks.add(obj.pk)\n        count = len(seen_pks)\n        return count + (1 if self.field.empty_label is not None else 0)\n\n    def __bool__(self):\n        return self.field.empty_label is not None or bool(self.queryset)\n\n    def choice(self, obj):\n        return (self.field.prepare_value(obj), self.field.label_from_instance(obj))\n\n\n# django/forms/models.py - ModelChoiceField modification\n\nclass ModelChoiceField(ChoiceField):\n    \"\"\"A ChoiceField whose choices are a model QuerySet.\"\"\"\n    # This class is a lot like its parent, but the choices are\n    # ModelChoiceIterator and there's validation for model instances.\n    default_error_messages = {\n        'invalid_choice': _('Select a valid choice. That choice is not one of'\n                            ' the available choices.'),\n    }\n    iterator = ModelChoiceIterator\n\n    def __init__(self, queryset, *, empty_label=\"---------\",\n                 required=True, widget=None, label=None, initial=None,\n                 help_text='', to_field_name=None, limit_choices_to=None,\n                 **kwargs):\n        if required and (initial is not None):\n            self.empty_label = None\n        else:\n            self.empty_label = empty_label\n        \n        # Call Field.__init__() instead of ChoiceField.__init__() because\n        # we don't need to set self.choices.\n        Field.__init__(\n            self, required=required, widget=widget, label=label,\n            initial=initial, help_text=help_text, **kwargs\n        )\n        self.queryset = queryset\n        self.limit_choices_to = limit_choices_to\n        self.to_field_name = to_field_name\n\n    def __deepcopy__(self, memo):\n        result = super().__deepcopy__(memo)\n        # Need to force a new ModelChoiceIterator to be created, bug #11183\n        if self.queryset is not None:\n            result.queryset = self.queryset.all()\n        return result\n\n    def _get_queryset(self):\n        return self._queryset\n\n    def _set_queryset(self, queryset):\n        self._queryset = None if queryset is None else queryset\n        self.widget.choices = self.choices\n\n    queryset = property(_get_queryset, _set_queryset)\n\n    # this method will be used to create object labels by the QuerySetIterator.\n    # Override it to customize the label.\n    def label_from_instance(self, obj):\n        \"\"\"\n        Convert objects into strings and generate the labels for the choices\n        presented by this object. Subclasses can override this method to\n        customize the display of the choices.\n        \"\"\"\n        return str(obj)\n\n    def _get_choices(self):\n        # If self._choices is set, then somebody must have manually set\n        # the property self.choices. In this case, just return self._choices.\n        if hasattr(self, '_choices'):\n            return self._choices\n\n        # Otherwise, execute the QuerySet in self.queryset to determine the\n        # choices dynamically. Return a fresh ModelChoiceIterator that has not been\n        # consumed. Note that we're instantiating a new ModelChoiceIterator *each*\n        # time _get_choices() is called (and, thus, each time self.choices is\n        # accessed) so that we can ensure the QuerySet has not been consumed. This\n        # construct might look complicated but it allows for lazy evaluation of\n        # the queryset.\n        return self.iterator(self)\n\n    choices = property(_get_choices, ChoiceField._set_choices)\n\n    def prepare_value(self, value):\n        if hasattr(value, '_meta'):\n            if self.to_field_name:\n                return value.serializable_value(self.to_field_name)\n            else:\n                return value.pk\n        return super().prepare_value(value)\n\n    def to_python(self, value):\n        if value in self.empty_values:\n            return None\n        try:\n            key = self.to_field_name or 'pk'\n            if isinstance(value, self.queryset.model):\n                value = getattr(value, key)\n            # Use .get() with the to_field_name to avoid duplicates\n            value = self.queryset.get(**{key: value})\n        except (ValueError, TypeError, self.queryset.model.DoesNotExist):\n            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n        except self.queryset.model.MultipleObjectsReturned:\n            # Handle the case where limit_choices_to with joins causes duplicates\n            # Get the first matching object\n            key = self.to_field_name or 'pk'\n            value = self.queryset.filter(**{key: value}).first()\n            if value is None:\n                raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n        return value\n\n    def validate(self, value):\n        \"\"\"Validate that the input is in self.queryset.\"\"\"\n        return Field.validate(self, value)\n\n    def has_changed(self, initial, data):\n        if self.disabled:\n            return False\n        initial_value = initial if initial is not None else ''\n        data_value = data if data is not None else ''\n        return str(self.prepare_value(initial_value)) != str(data_value)",
      "generation_time": 35.10947012901306,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 27,
      "critical_issues": 0,
      "high_issues": 8,
      "medium_issues": 13,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.2540000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 41.2%",
        "HIGH: ast_analysis - Public function 'choice' missing docstring - production documentation required",
        "HIGH: logic - Low logic score: 0.00"
      ],
      "verification_time": 0.07753705978393555,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13321",
      "repo": "django/django",
      "problem_statement": "Decoding an invalid session data crashes.\nDescription\n\t \n\t\t(last modified by Matt Hegarty)\n\t \nHi\nI recently upgraded my staging server to 3.1. I think that there was an old session which was still active.\nOn browsing to any URL, I get the crash below. It looks similar to \u200bthis issue.\nI cannot login at all with Chrome - each attempt to access the site results in a crash. Login with Firefox works fine.\nThis is only happening on my Staging site, which is running Gunicorn behind nginx proxy.\nInterna",
      "hints_text": "I tried to run clearsessions, but that didn't help. The only workaround was to delete all rows in the django_session table.\nThanks for this report, however I cannot reproduce this issue. Can you provi",
      "claude_patch": "diff --git a/django/contrib/sessions/backends/base.py b/django/contrib/sessions/backends/base.py\nindex 1234567890..abcdef1234 100644\n--- a/django/contrib/sessions/backends/base.py\n+++ b/django/contrib/sessions/backends/base.py\n@@ -123,7 +123,11 @@ class SessionBase:\n             return self._legacy_decode(session_data)\n \n     def _legacy_decode(self, session_data):\n-        encoded_data = base64.b64decode(session_data.encode('ascii'))\n+        try:\n+            encoded_data = base64.b64decode(session_data.encode('ascii'))\n+        except (binascii.Error, ValueError):\n+            # Invalid base64 or padding, return empty session\n+            return {}\n         try:\n             # could produce ValueError if there is no ':'\n             hash, serialized = encoded_data.split(b':', 1)",
      "generation_time": 5.3733649253845215,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04645800590515137,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13401",
      "repo": "django/django",
      "problem_statement": "Abstract model field should not be equal across models\nDescription\n\t\nConsider the following models:\nclass A(models.Model):\n\tclass Meta:\n\t\tabstract = True\n\tmyfield = IntegerField()\nclass B(A):\n\tpass\nclass C(A):\n\tpass\nIf I pull the fields of B and C into a shared set, one will be de-duplicated away, because they compare as equal. I found this surprising, though in practice using a list was sufficient for my need. The root of the issue is that they compare equal, as fields only consider self.creati",
      "hints_text": null,
      "claude_patch": "from django.db.models.fields import Field\n\n# Store original methods\n_original_eq = Field.__eq__\n_original_hash = Field.__hash__\n_original_lt = Field.__lt__\n\ndef _new_eq(self, other):\n    # Short-circuit if not the same type\n    if not isinstance(other, Field):\n        return NotImplemented\n    \n    # If both fields have models and they're different, they're not equal\n    if self.model is not None and other.model is not None and self.model != other.model:\n        return False\n    \n    # Otherwise use creation_counter comparison\n    return self.creation_counter == other.creation_counter\n\ndef _new_hash(self):\n    # Include model in hash if it exists\n    if self.model is not None:\n        return hash((self.creation_counter, self.model))\n    return hash(self.creation_counter)\n\ndef _new_lt(self, other):\n    # Short-circuit if not the same type\n    if not isinstance(other, Field):\n        return NotImplemented\n    \n    # First compare by creation_counter to maintain existing ordering\n    if self.creation_counter != other.creation_counter:\n        return self.creation_counter < other.creation_counter\n    \n    # If creation_counters are equal, compare by model\n    # Handle None cases\n    if self.model is None and other.model is None:\n        return False\n    if self.model is None:\n        return True\n    if other.model is None:\n        return False\n    \n    # Both have models, compare them\n    # Use model's full name for consistent ordering\n    self_model_name = f\"{self.model._meta.app_label}.{self.model._meta.object_name}\"\n    other_model_name = f\"{other.model._meta.app_label}.{other.model._meta.object_name}\"\n    return self_model_name < other_model_name\n\n# Apply the patches\nField.__eq__ = _new_eq\nField.__hash__ = _new_hash\nField.__lt__ = _new_lt",
      "generation_time": 9.021902799606323,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 10,
      "critical_issues": 0,
      "high_issues": 4,
      "medium_issues": 1,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.45,
        "style": 0.6946281481158763,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 66.7%",
        "HIGH: logic - Low logic score: 0.20",
        "HIGH: production_readiness - Low production readiness: 73.3%"
      ],
      "verification_time": 0.1731278896331787,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13447",
      "repo": "django/django",
      "problem_statement": "Added model class to app_list context\nDescription\n\t \n\t\t(last modified by Raffaele Salmaso)\n\t \nI need to manipulate the app_list in my custom admin view, and the easiest way to get the result is to have access to the model class (currently the dictionary is a serialized model).\nIn addition I would make the _build_app_dict method public, as it is used by the two views index and app_index.\n",
      "hints_text": null,
      "claude_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 1234567890..abcdefghij 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -420,7 +420,7 @@ class AdminSite:\n         \"\"\"\n         return []\n \n-    def _build_app_dict(self, request, label=None):\n+    def build_app_dict(self, request, label=None):\n         \"\"\"\n         Build the app dictionary. The optional `label` parameter filters models\n         of a specific app.\n@@ -456,6 +456,7 @@ class AdminSite:\n                         \"object_name\": model._meta.object_name,\n                         \"perms\": perms,\n                         \"admin_url\": None,\n+                        \"model\": model,\n                     }\n                     if perms.get(\"change\") or perms.get(\"view\"):\n                         model_dict[\"view_only\"] = not perms.get(\"change\")\n@@ -499,6 +500,13 @@ class AdminSite:\n \n         return app_dict\n \n+    def _build_app_dict(self, request, label=None):\n+        \"\"\"\n+        Deprecated. Use build_app_dict() instead.\n+        \"\"\"\n+        import warnings\n+        warnings.warn(\"_build_app_dict() is deprecated. Use build_app_dict() instead.\", DeprecationWarning, stacklevel=2)\n+        return self.build_app_dict(request, label)\n+\n     def get_app_list(self, request, app_label=None):\n         \"\"\"\n         Return a sorted list of all the installed apps that have been\n@@ -506,7 +514,7 @@ class AdminSite:\n         \"\"\"\n         app_dict = self._build_app_dict(request, app_label)\n \n-        # Sort the apps alphabetically.\n+        # Sort the apps alphabetically\n         app_list = sorted(app_dict.values(), key=lambda x: x[\"name\"].lower())\n \n         # Sort the models alphabetically within each app.",
      "generation_time": 9.34922194480896,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: unmatched '}' (<unknown>, line 19)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.03889107704162598,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13448",
      "repo": "django/django",
      "problem_statement": "Test runner setup_databases crashes with \"TEST\": {\"MIGRATE\": False}.\nDescription\n\t\nI'm trying to upgrade a project from Django 3.0 to Django 3.1 and wanted to try out the new \"TEST\": {\"MIGRATE\": False} database setting.\nSadly I'm running into an issue immediately when running ./manage.py test.\nRemoving the \"TEST\": {\"MIGRATE\": False} line allows the tests to run. So this is not blocking the upgrade for us, but it would be nice if we were able to use the new feature to skip migrations during testi",
      "hints_text": "Thanks for this report, now I see that we need to synchronize all apps when MIGRATE is False, see comment. I've totally missed this when reviewing f5ebdfce5c417f9844e86bccc2f12577064d4bad. We can remo",
      "claude_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex 503f7f56fd..8e5c3c0338 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -1,6 +1,7 @@\n import os\n import sys\n from io import StringIO\n+from unittest import mock\n \n from django.apps import apps\n from django.conf import settings\n@@ -60,13 +61,28 @@ class BaseDatabaseCreation:\n         )\n \n         if test_settings.get('MIGRATE', True):\n-            # We report migrate messages at one level lower than that requested.\n-            # This ensures we get output at the default verbosity level but not\n-            # at level 0.\n+            call_command(\n+                'migrate',\n+                verbosity=max(verbosity - 1, 0),\n+                interactive=False,\n+                database=self.connection.alias,\n+                run_syncdb=True,\n+            )\n+        else:\n+            # Disable migrations for all apps by mocking MIGRATION_MODULES\n+            # to return None for all apps, which causes syncdb to be used.\n+            migration_modules = {\n+                app.label: None\n+                for app in apps.get_app_configs()\n+            }\n+            with mock.patch.object(\n+                settings,\n+                'MIGRATION_MODULES',\n+                migration_modules,\n+            ):\n+                call_command(\n+                    'migrate',\n+                    verbosity=max(verbosity - 1, 0),\n+                    interactive=False,\n+                    database=self.connection.alias,\n+                    run_syncdb=True,\n+                )\n \n         # We then serialize the current state of the database into a string",
      "generation_time": 8.26960802078247,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 1,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4066666666666666,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid decimal literal (<unknown>, line 2)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.007505893707275391,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13551",
      "repo": "django/django",
      "problem_statement": "Changing user's email could invalidate password reset tokens\nDescription\n\t\nSequence:\nHave account with email address foo@\u2026\nPassword reset request for that email (unused)\nfoo@\u2026 account changes their email address\nPassword reset email is used\nThe password reset email's token should be rejected at that point, but in fact it is allowed.\nThe fix is to add the user's email address into \u200bPasswordResetTokenGenerator._make_hash_value()\nNothing forces a user to even have an email as per AbstractBaseUser. ",
      "hints_text": null,
      "claude_patch": "from django.contrib.auth.tokens import PasswordResetTokenGenerator\n\nclass PasswordResetTokenGenerator(PasswordResetTokenGenerator):\n    def _make_hash_value(self, user, timestamp):\n        \"\"\"\n        Hash the user's primary key, email, and some user state\n        that's sure to change after a password reset to produce a token\n        that is invalidated when it's used:\n        1. The password field will change upon a password reset (even if the\n           same password is chosen, due to password salting).\n        2. The last_login field will usually be updated very shortly after\n           a password reset.\n        3. The email field will change if the user changes their email.\n        Failing those things, settings.PASSWORD_RESET_TIMEOUT eventually\n        invalidates the token.\n        \"\"\"\n        # Truncate microseconds so that tokens are consistent even if the\n        # database doesn't support microseconds.\n        login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n        email_field = user.get_email_field_name()\n        email = getattr(user, email_field, '') or ''\n        return f'{user.pk}{user.password}{login_timestamp}{timestamp}{email}'\n\ndefault_token_generator = PasswordResetTokenGenerator()",
      "generation_time": 8.058881998062134,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.99,
      "verification_verdict": "PASS",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 0,
      "medium_issues": 0,
      "low_issues": 9,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.7993171349454022,
        "performance": 1.0
      },
      "key_issues": [],
      "verification_time": 0.203902006149292,
      "patch_quality_estimate": "HIGH"
    },
    {
      "instance_id": "django__django-13590",
      "repo": "django/django",
      "problem_statement": "Upgrading 2.2>3.0 causes named tuples used as arguments to __range to error.\nDescription\n\t\nI noticed this while upgrading a project from 2.2 to 3.0.\nThis project passes named 2-tuples as arguments to range queryset filters. This works fine on 2.2. On 3.0 it causes the following error: TypeError: __new__() missing 1 required positional argument: 'far'.\nThis happens because django.db.models.sql.query.Query.resolve_lookup_value goes into the tuple elements to resolve lookups and then attempts to re",
      "hints_text": null,
      "claude_patch": "# File: django/db/models/sql/query.py\n\ndef resolve_lookup_value(self, value, can_reuse, allow_joins):\n    if hasattr(value, 'resolve_expression'):\n        value = value.resolve_expression(self, can_reuse, allow_joins)\n    elif isinstance(value, (list, tuple)):\n        # The items of the iterable may be expressions and therefore need\n        # to be resolved independently.\n        type_ = type(value)\n        resolved_values = (\n            self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n            for sub_value in value\n        )\n        # Unpack the generator for named tuples and other tuple subclasses\n        # that don't accept an iterable in their constructor\n        try:\n            value = type_(resolved_values)\n        except TypeError:\n            # If the constructor doesn't accept an iterable (e.g., named tuples),\n            # unpack the values as positional arguments\n            value = type_(*resolved_values)\n    return value",
      "generation_time": 7.77909779548645,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 8,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 3,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.8609678897260713,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.04889082908630371,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-13658",
      "repo": "django/django",
      "problem_statement": "ManagementUtility instantiates CommandParser without passing already-computed prog argument\nDescription\n\t\nManagementUtility \u200bgoes to the trouble to parse the program name from the argv it's passed rather than from sys.argv: \n\tdef __init__(self, argv=None):\n\t\tself.argv = argv or sys.argv[:]\n\t\tself.prog_name = os.path.basename(self.argv[0])\n\t\tif self.prog_name == '__main__.py':\n\t\t\tself.prog_name = 'python -m django'\nBut then when it needs to parse --pythonpath and --settings, it \u200buses the program ",
      "hints_text": "Tentatively accepted, looks valid but I was not able to reproduce and invalid message (even with mocking sys.argv), so a regression test is crucial.",
      "claude_patch": "# django/core/management/__init__.py\n\ndef execute_from_command_line(argv=None):\n    \"\"\"Run a ManagementUtility.\"\"\"\n    utility = ManagementUtility(argv)\n    utility.execute()\n\n\nclass ManagementUtility:\n    \"\"\"\n    Encapsulate the logic of the django-admin and manage.py utilities.\n    \"\"\"\n    def __init__(self, argv=None):\n        self.argv = argv or sys.argv[:]\n        self.prog_name = os.path.basename(self.argv[0])\n        if self.prog_name == '__main__.py':\n            self.prog_name = 'python -m django'\n        self.settings_exception = None\n\n    def main_help_text(self, commands_only=False):\n        \"\"\"Return the script's main help text, as a string.\"\"\"\n        if commands_only:\n            usage = sorted(get_commands())\n        else:\n            usage = [\n                \"\",\n                \"Type '%s help <subcommand>' for help on a specific subcommand.\" % self.prog_name,\n                \"\",\n                \"Available subcommands:\",\n            ]\n            commands_dict = defaultdict(lambda: [])\n            for name, app in get_commands().items():\n                if app == 'django.core':\n                    app = 'django'\n                else:\n                    app = app.rpartition('.')[-1]\n                commands_dict[app].append(name)\n            style = color_style()\n            for app in sorted(commands_dict):\n                usage.append(\"\")\n                usage.append(style.NOTICE(\"[%s]\" % app))\n                for name in sorted(commands_dict[app]):\n                    usage.append(\"    %s\" % name)\n            # Output an extra note if settings are not properly configured\n            if self.settings_exception is not None:\n                usage.append(style.NOTICE(\n                    \"Note that only Django core commands are listed \"\n                    \"as settings are not properly configured (error: %s).\"\n                    % self.settings_exception))\n\n        return '\\n'.join(usage)\n\n    def fetch_command(self, subcommand):\n        \"\"\"\n        Try to fetch the given subcommand, printing a message with the\n        appropriate command called from the command line (usually\n        \"django-admin\" or \"manage.py\") if it can't be found.\n        \"\"\"\n        # Get commands outside of try block to prevent swallowing exceptions\n        commands = get_commands()\n        try:\n            app_name = commands[subcommand]\n        except KeyError:\n            if os.environ.get('DJANGO_SETTINGS_MODULE'):\n                # If `subcommand` is missing due to misconfigured settings, the\n                # following line will retrigger an ImproperlyConfigured exception\n                # (get_commands() swallows the original one) so the user is\n                # informed about it.\n                settings.INSTALLED_APPS\n            elif not settings.configured:\n                sys.stderr.write(\"No Django settings specified.\\n\")\n            possible_matches = get_close_matches(subcommand, commands)\n            sys.stderr.write('Unknown command: %r' % subcommand)\n            if possible_matches:\n                sys.stderr.write('. Did you mean %s?' % possible_matches[0])\n            sys.stderr.write(\"\\nType '%s help' for usage.\\n\" % self.prog_name)\n            sys.exit(1)\n        if isinstance(app_name, BaseCommand):\n            # If the command is already loaded, use it directly.\n            klass = app_name\n        else:\n            klass = load_command_class(app_name, subcommand)\n        return klass\n\n    def execute(self):\n        \"\"\"\n        Given the command-line arguments, figure out which subcommand is being\n        run, create a parser appropriate to that command, and run it.\n        \"\"\"\n        try:\n            subcommand = self.argv[1]\n        except IndexError:\n            subcommand = 'help'  # Display help if no arguments were given.\n\n        # Preprocess options to extract --settings and --pythonpath.\n        # These options could affect the commands that are available, so they\n        # must be processed early.\n        parser = CommandParser(\n            prog=self.prog_name,\n            usage='%(prog)s subcommand [options] [args]',\n            add_help=False,\n            allow_abbrev=False,\n        )\n        parser.add_argument('--settings')\n        parser.add_argument('--pythonpath')\n        parser.add_argument('--traceback', action='store_true')\n        parser.add_argument('--no-color', action='store_true')\n        parser.add_argument('--force-color', action='store_true')\n        parser.add_argument('--skip-checks', action='store_true')\n        self.autocomplete()\n\n        try:\n            options, args = parser.parse_known_args(self.argv[2:])\n            handle_default_options(options)\n        except CommandError:\n            pass  # Ignore any option errors at this point.\n\n        try:\n            settings.INSTALLED_APPS\n        except ImproperlyConfigured as exc:\n            self.settings_exception = exc\n        except ImportError as exc:\n            self.settings_exception = exc\n\n        if settings.configured:\n            # Start the auto-reloader even if the code is broken.\n            # The hardcoded condition is a code smell but we can't rely on a\n            # flag on the command class because we haven't located it yet.\n            if subcommand == 'runserver' and '--noreload' not in self.argv:\n                try:\n                    autoreload.check_errors(django.setup)()\n                except Exception:\n                    # The exception will be raised later in the child process\n                    # started by the autoreloader. Pretend it didn't happen by\n                    # loading an empty list of applications.\n                    apps.all_models = defaultdict(dict)\n                    apps.app_configs = {}\n                    apps.apps_ready = apps.models_ready = apps.ready = True\n\n                    # Remove options not compatible with the built-in runserver\n                    # (e.g. options for the contrib.staticfiles' runserver).\n                    # Changes here require manually testing as described in\n                    # #27522.\n                    _parser = self.fetch_command('runserver').create_parser('django', 'runserver')\n                    _options, _args = _parser.parse_known_args(self.argv[2:])\n                    for _arg in _args:\n                        self.argv.remove(_arg)\n\n            # In all other cases, django.setup() is required to succeed.\n            else:\n                django.setup()\n\n        self.autocomplete()\n\n        if subcommand == 'help':\n            if '--commands' in args:\n                sys.stdout.write(self.main_help_text(commands_only=True) + '\\n')\n            elif not options.args:\n                sys.stdout.write(self.main_help_text() + '\\n')\n            else:\n                self.fetch_command(options.args[0]).print_help(self.prog_name, options.args[0])\n        # Special-cases: We want 'django-admin --version' and\n        # 'django-admin --help' to work, for backwards compatibility.\n        elif subcommand == 'version' or self.argv[1:] == ['--version']:\n            sys.stdout.write(django.get_version() + '\\n')\n        elif self.argv[1:] in (['--help'], ['-h']):\n            sys.stdout.write(self.main_help_text() + '\\n')\n        else:\n            self.fetch_command(subcommand).run_from_argv(self.argv)\n\n    def autocomplete(self):\n        \"\"\"\n        Output completion suggestions for BASH.\n\n        The output of this function is passed to BASH's `COMREPLY` variable and\n        treated as completion suggestions. `COMREPLY` expects a space\n        separated string as the result.\n\n        The `COMP_WORDS` and `COMP_CWORD` BASH environment variables are used\n        to get information about the cli input. Please refer to the BASH\n        man-page for more information about this variables.\n\n        Subcommand options are saved as pairs. A pair consists of\n        the long option string (e.g. '--exclude') and a boolean\n        value indicating if the option requires arguments. When printing to\n        stdout, an equal sign is appended to options which require arguments.\n\n        Note: If debugging this function, it is recommended to write the debug\n        output in a separate file. Otherwise the debug output will be treated\n        and formatted as potential completion suggestions.\n        \"\"\"\n        # Don't complete if user hasn't sourced bash_completion file.\n        if 'DJANGO_AUTO_COMPLETE' not in os.environ:\n            return\n\n        cwords = os.environ['COMP_WORDS'].split()[1:]\n        cword = int(os.environ['COMP_CWORD'])\n\n        try:\n            curr = cwords[cword - 1]\n        except IndexError:\n            curr = ''\n\n        subcommands = [*get_commands(), 'help']\n        options = [('--help', False)]\n\n        # subcommand\n        if cword == 1:\n            print(' '.join(sorted(filter(lambda x: x.startswith(curr), subcommands))))\n        # subcommand options\n        # special case: the 'help' subcommand has no options\n        elif cwords[0] in subcommands and cwords[0] != 'help':\n            subcommand_cls = self.fetch_command(cwords[0])\n            # special case: add the names of installed apps to options\n            if cwords[0] in ('dumpdata', 'sqlmigrate', 'sqlsequencereset', 'test'):\n                try:\n                    app_configs = apps.get_app_configs()\n                    # Get the last part of the dotted path as the app name.\n                    options.extend((app_config.label, 0) for app_config in app_configs)\n                except ImportError:\n                    # Fail silently if DJANGO_SETTINGS_MODULE isn't set. The\n                    # user will find out once they execute the command.\n                    pass\n            parser = subcommand_cls.create_parser('', cwords[0])\n            options.extend(\n                (min(s_opt.option_strings), s_opt.nargs != 0)\n                for s_opt in parser._actions if s_opt.option_strings\n            )\n            # filter out previously specified options from available options\n            prev_opts = {x.split('=')[0] for x in cwords[1:cword - 1]}\n            options = (opt for opt in options if opt[0] not in prev_opts)\n\n            # filter options by current input\n            options = sorted((k, v) for k, v in options if k.startswith(curr))\n            for opt_label, require_arg in options:\n                # append '=' to options which require args\n                if require_arg:\n                    opt_label += '='\n                print(opt_label)\n        # Exit code of the bash completion function is never passed back to\n        # the user, so it's safe to always exit with 0.\n        # For more details see #25420.\n        sys.exit(0)",
      "generation_time": 50.81069803237915,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 26,
      "critical_issues": 0,
      "high_issues": 13,
      "medium_issues": 8,
      "low_issues": 5,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 0.4,
        "style": 0.248,
        "performance": 0.95
      },
      "key_issues": [
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected"
      ],
      "verification_time": 0.09540581703186035,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13660",
      "repo": "django/django",
      "problem_statement": "shell command crashes when passing (with -c) the python code with functions.\nDescription\n\t\nThe examples below use Python 3.7 and Django 2.2.16, but I checked that the code is the same on master and works the same in Python 3.8.\nHere's how \u200bpython -c works:\n$ python -c <<EOF \" \nimport django\ndef f():\n\t\tprint(django.__version__)\nf()\"\nEOF\n2.2.16\nHere's how \u200bpython -m django shell -c works (paths shortened for clarify):\n$ python -m django shell -c <<EOF \"\nimport django\ndef f():\n\t\tprint(django.__vers",
      "hints_text": "\u200bPR includes tests and documents the new feature in the release notes (but not in the main docs since it seems more like a bug fix than a new feature to me).",
      "claude_patch": "diff --git a/django/core/management/commands/shell.py b/django/core/management/commands/shell.py\nindex 1234567890..abcdefghij 100644\n--- a/django/core/management/commands/shell.py\n+++ b/django/core/management/commands/shell.py\n@@ -83,12 +83,12 @@ class Command(BaseCommand):\n     def handle(self, **options):\n         # Execute the command and exit.\n         if options['command']:\n-            exec(options['command'])\n+            exec(options['command'], {})\n             return\n \n         # Execute stdin if it has anything to read and exit.\n         # Not supported on Windows due to select.select() limitations.\n         if sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:\n-            exec(sys.stdin.read())\n+            exec(sys.stdin.read(), {})\n             return\n \n         available_shells = [options['interface']] if options['interface'] else self.shells",
      "generation_time": 4.478078842163086,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.0,
      "verification_verdict": "FAIL",
      "issues_found": 23,
      "critical_issues": 7,
      "high_issues": 4,
      "medium_issues": 1,
      "low_issues": 11,
      "agent_scores": {
        "security": 0.1,
        "correctness": 0.5399999999999998,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: exec_execution - exec() enables arbitrary code execution",
        "CRITICAL: exec_execution - exec() enables arbitrary code execution",
        "CRITICAL: exec_execution - exec() enables arbitrary code execution"
      ],
      "verification_time": 0.007102012634277344,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13710",
      "repo": "django/django",
      "problem_statement": "Use Admin Inline verbose_name as default for Inline verbose_name_plural\nDescription\n\t\nDjango allows specification of a verbose_name and a verbose_name_plural for Inline classes in admin views. However, verbose_name_plural for an Inline is not currently based on a specified verbose_name. Instead, it continues to be based on the model name, or an a verbose_name specified in the model's Meta class. This was confusing to me initially (I didn't understand why I had to specify both name forms for an I",
      "hints_text": "Please push your patch as a \u200bDjango pull request.",
      "claude_patch": "# django/contrib/admin/options.py\n\n# Find the BaseModelAdmin or InlineModelAdmin class and modify the __init__ method\n# to handle verbose_name_plural defaulting\n\n# Patch for django/contrib/admin/options.py\n\nimport copy\nfrom django.contrib.admin import options\n\n# Store the original __init__ method\n_original_inline_init = options.InlineModelAdmin.__init__\n\ndef _patched_inline_init(self, parent_model, admin_site):\n    # Check if verbose_name was explicitly set on this inline class\n    # before calling parent __init__\n    has_explicit_verbose_name = hasattr(self.__class__, 'verbose_name') and \\\n        'verbose_name' in self.__class__.__dict__\n    \n    explicit_verbose_name = None\n    if has_explicit_verbose_name:\n        explicit_verbose_name = self.__class__.verbose_name\n    \n    # Check if verbose_name_plural was explicitly set\n    has_explicit_verbose_name_plural = hasattr(self.__class__, 'verbose_name_plural') and \\\n        'verbose_name_plural' in self.__class__.__dict__\n    \n    # Call original init\n    _original_inline_init(self, parent_model, admin_site)\n    \n    # If verbose_name was explicitly set but verbose_name_plural was not,\n    # default verbose_name_plural to verbose_name + 's'\n    if has_explicit_verbose_name and not has_explicit_verbose_name_plural:\n        if explicit_verbose_name is not None:\n            # Use Django's default pluralization (just add 's')\n            self.verbose_name_plural = explicit_verbose_name + 's'\n\n# Apply the patch\noptions.InlineModelAdmin.__init__ = _patched_inline_init",
      "generation_time": 25.75110125541687,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 2,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8766666666666667,
        "style": 0.7427794552463665,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.21849870681762695,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-13757",
      "repo": "django/django",
      "problem_statement": "Using __isnull=True on a KeyTransform should not match JSON null on SQLite and Oracle\nDescription\n\t\nThe KeyTransformIsNull lookup borrows the logic from HasKey for isnull=False, which is correct. If isnull=True, the query should only match objects that do not have the key. The query is correct for MariaDB, MySQL, and PostgreSQL. However, on SQLite and Oracle, the query also matches objects that have the key with the value null, which is incorrect.\nTo confirm, edit tests.model_fields.test_jsonfie",
      "hints_text": null,
      "claude_patch": "# django/db/models/fields/json.py\n\nclass KeyTransformIsNull(lookups.IsNull):\n    def as_sql(self, compiler, connection):\n        # Borrowed from HasKey\n        if not self.rhs:\n            return HasKey(\n                self.lhs.lhs,\n                self.lhs.key_name,\n            ).as_sql(compiler, connection)\n        \n        # For isnull=True, we need to check that the key doesn't exist\n        # On SQLite and Oracle, we need to be careful not to match JSON null values\n        sql, params = self.lhs.as_sql(compiler, connection)\n        \n        if connection.vendor in ('sqlite', 'oracle'):\n            # For SQLite and Oracle, we need to explicitly check that the key doesn't exist\n            # rather than just checking for SQL NULL, because JSON null is different from missing key\n            key_lookup = HasKey(\n                self.lhs.lhs,\n                self.lhs.key_name,\n            )\n            key_sql, key_params = key_lookup.as_sql(compiler, connection)\n            # Negate the HasKey check to ensure the key doesn't exist\n            return 'NOT %s' % key_sql, key_params\n        else:\n            # For other databases (PostgreSQL, MySQL, MariaDB), the default behavior is correct\n            return '%s IS NULL' % sql, params\n\n    def as_oracle(self, compiler, connection):\n        if not self.rhs:\n            return HasKey(\n                self.lhs.lhs,\n                self.lhs.key_name,\n            ).as_oracle(compiler, connection)\n        \n        # For isnull=True on Oracle, check that the key doesn't exist\n        key_lookup = HasKey(\n            self.lhs.lhs,\n            self.lhs.key_name,\n        )\n        key_sql, key_params = key_lookup.as_oracle(compiler, connection)\n        return 'NOT %s' % key_sql, key_params\n\n    def as_sqlite(self, compiler, connection):\n        if not self.rhs:\n            return HasKey(\n                self.lhs.lhs,\n                self.lhs.key_name,\n            ).as_sqlite(compiler, connection)\n        \n        # For isnull=True on SQLite, check that the key doesn't exist\n        key_lookup = HasKey(\n            self.lhs.lhs,\n            self.lhs.key_name,\n        )\n        key_sql, key_params = key_lookup.as_sqlite(compiler, connection)\n        return 'NOT %s' % key_sql, key_params",
      "generation_time": 11.212202072143555,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 0,
      "high_issues": 6,
      "medium_issues": 8,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.6063411635819781,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 33.3%",
        "HIGH: ast_analysis - Public function 'as_sql' missing docstring - production documentation required",
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%"
      ],
      "verification_time": 0.05196380615234375,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13768",
      "repo": "django/django",
      "problem_statement": "Log exceptions handled in Signal.send_robust()\nDescription\n\t\nAs pointed out by \u200bHaki Benita on Twitter, by default Signal.send_robust() doesn't have any log messages for exceptions raised in receivers. Since Django logs exceptions in other similar situations, such as missing template variables, I think it would be worth adding a logger.exception() call in the except clause of send_robust() . Users would then see such exceptions in their error handling tools, e.g. Sentry, and be able to figure ou",
      "hints_text": "I would like to work on this issue. PS. i am new to this django. so any advice would be appreciated",
      "claude_patch": "import logging\n\nlogger = logging.getLogger('django.dispatch')\n\n# In django/dispatch/dispatcher.py, modify the send_robust method:\n\ndef send_robust(self, sender, **named):\n    \"\"\"\n    Send signal from sender to all connected receivers catching errors.\n\n    Arguments:\n\n        sender\n            The sender of the signal. Can be any Python object (normally one\n            registered with a connect if you actually want something to\n            occur).\n\n        named\n            Named arguments which will be passed to receivers.\n\n    Return a list of tuple pairs [(receiver, response), ... ].\n\n    If any receiver raises an error (specifically any subclass of\n    Exception), return the error instance as the result for that receiver.\n    \"\"\"\n    if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS:\n        return []\n\n    # Call each receiver with whatever arguments it can accept.\n    # Return a list of tuple pairs [(receiver, response), ... ].\n    responses = []\n    for receiver in self._live_receivers(sender):\n        try:\n            response = receiver(signal=self, sender=sender, **named)\n        except Exception as err:\n            logger.exception(\n                'Error calling %s in Signal.send_robust() (%s)',\n                receiver.__qualname__ if hasattr(receiver, '__qualname__') else receiver,\n                err\n            )\n            responses.append((receiver, err))\n        else:\n            responses.append((receiver, response))\n    return responses",
      "generation_time": 9.004919052124023,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 8,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 1,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.8943917920040904,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: contract_violation - Function 'send_robust' docstring mentions exceptions but none are raised",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.05097079277038574,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-13925",
      "repo": "django/django",
      "problem_statement": "models.W042 is raised on inherited manually specified primary key.\nDescription\n\t\nI have models which inherit from other models, and they should inherit the primary key. This works fine with Django 3.1. However, if I install Django 3.2 alpha, when I run make_migrations I get the following error messages:\nSystem check identified some issues:\nWARNINGS:\naccounts.ReservedUsername: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'",
      "hints_text": "Hello Uri, thanks for testing out the alpha and the report. These models should not use auto-created primary keys! I already defined the primary key in the ancestor of the model. For example class Ent",
      "claude_patch": "# django/db/models/base.py\n\ndef _check_default_pk(cls):\n    if (\n        not cls._meta.abstract\n        and cls._meta.pk is not None\n        and isinstance(cls._meta.pk, AutoField)\n        and cls._meta.pk.model == cls._meta.concrete_model\n        and not (\n            settings.is_overridden('DEFAULT_AUTO_FIELD')\n            or cls._meta.app_config\n            and cls._meta.app_config._is_default_auto_field_overridden\n        )\n    ):\n        return [\n            checks.Warning(\n                f\"Auto-created primary key used when not defining a primary key type, by default \"\n                f\"'{settings.DEFAULT_AUTO_FIELD}'.\",\n                hint=(\n                    f\"Configure the DEFAULT_AUTO_FIELD setting or the \"\n                    f\"{cls._meta.app_config.__class__.__name__}.default_auto_field attribute \"\n                    f\"to point to a subclass of AutoField, e.g. \"\n                    f\"'django.db.models.BigAutoField'.\"\n                ),\n                obj=cls,\n                id='models.W042',\n            )\n        ]\n    return []",
      "generation_time": 13.712924003601074,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 8,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 1,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.7618104745084572,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.041818857192993164,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-13933",
      "repo": "django/django",
      "problem_statement": "ModelChoiceField does not provide value of invalid choice when raising ValidationError\nDescription\n\t \n\t\t(last modified by Aaron Wiegel)\n\t \nCompared with ChoiceField and others, ModelChoiceField does not show the value of the invalid choice when raising a validation error. Passing in parameters with the invalid value and modifying the default error message for the code invalid_choice should fix this.\nFrom source code:\nclass ModelMultipleChoiceField(ModelChoiceField):\n\t\"\"\"A MultipleChoiceField who",
      "hints_text": "This message has been the same literally forever b2b6fc8e3c78671c8b6af2709358c3213c84d119. \u200bGiven that ChoiceField passes the value when raising the error, if you set \u200berror_messages you should be abl",
      "claude_patch": "# File: django/forms/models.py\n\n# The patch modifies the ModelChoiceField class to include the value parameter\n# when raising the invalid_choice ValidationError\n\n# Find the ModelChoiceField class and update its default_error_messages and to_python method\n\n# In the ModelChoiceField class, change:\n# 1. Update default_error_messages to include %(value)s placeholder\n# 2. Update the to_python method to pass the value parameter when raising ValidationError\n\n# Original code around line 1200-1250 in django/forms/models.py\n\nclass ModelChoiceField(ChoiceField):\n    \"\"\"A ChoiceField whose choices are a model QuerySet.\"\"\"\n    # This class is a subclass of ChoiceField for purity, but it doesn't\n    # actually use any of ChoiceField's implementation.\n    default_error_messages = {\n        'invalid_choice': _('Select a valid choice. %(value)s is not one of'\n                            ' the available choices.'),\n    }\n    iterator = ModelChoiceIterator\n\n    def __init__(self, queryset, *, empty_label=\"---------\",\n                 required=True, widget=None, label=None, initial=None,\n                 help_text='', to_field_name=None, limit_choices_to=None,\n                 blank=False, **kwargs):\n        # Call Field instead of ChoiceField __init__() because we don't need\n        # ChoiceField.__init__().\n        Field.__init__(\n            self, required=required, widget=widget, label=label,\n            initial=initial, help_text=help_text, **kwargs\n        )\n        if (\n            (required and initial is not None) or\n            (isinstance(self.widget, RadioSelect) and not blank)\n        ):\n            self.empty_label = None\n        else:\n            self.empty_label = empty_label\n        self.queryset = queryset\n        self.limit_choices_to = limit_choices_to   # limit the queryset later.\n        self.to_field_name = to_field_name\n\n    def __deepcopy__(self, memo):\n        result = super(ChoiceField, self).__deepcopy__(memo)\n        # Need to force a new ModelChoiceIterator to be created, bug #11183\n        if self.queryset is not None:\n            result.queryset = self.queryset.all()\n        return result\n\n    def _get_queryset(self):\n        return self._queryset\n\n    def _set_queryset(self, queryset):\n        self._queryset = None if queryset is None else queryset.all()\n        self.widget.choices = self.choices\n\n    queryset = property(_get_queryset, _set_queryset)\n\n    # this method is copied from ChoiceField\n    def to_python(self, value):\n        if value in self.empty_values:\n            return None\n        try:\n            key = self.to_field_name or 'pk'\n            if isinstance(value, self.queryset.model):\n                value = getattr(value, key)\n            value = self.queryset.get(**{key: value})\n        except (ValueError, TypeError, self.queryset.model.DoesNotExist):\n            raise ValidationError(\n                self.error_messages['invalid_choice'],\n                code='invalid_choice',\n                params={'value': value},\n            )\n        return value\n\n    def validate(self, value):\n        return Field.validate(self, value)\n\n    def has_changed(self, initial, data):\n        if self.disabled:\n            return False\n        initial_value = initial if initial is not None else ''\n        data_value = data if data is not None else ''\n        return str(self.prepare_value(initial_value)) != str(data_value)",
      "generation_time": 16.597212076187134,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 20,
      "critical_issues": 0,
      "high_issues": 6,
      "medium_issues": 8,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.41600000000000004,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 28.6%",
        "HIGH: ast_analysis - Public function 'to_python' missing docstring - production documentation required",
        "HIGH: logic - Low logic score: 0.60"
      ],
      "verification_time": 0.05062389373779297,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-13964",
      "repo": "django/django",
      "problem_statement": "Saving parent object after setting on child leads to data loss for parents with non-numeric primary key.\nDescription\n\t \n\t\t(last modified by Charlie DeTar)\n\t \nGiven a model with a foreign key relation to another model that has a non-auto CharField as its primary key:\nclass Product(models.Model):\n\tsku = models.CharField(primary_key=True, max_length=50)\nclass Order(models.Model):\n\tproduct = models.ForeignKey(Product, on_delete=models.CASCADE)\nIf the relation is initialized on the parent with an emp",
      "hints_text": "Thanks for this report. product_id is an empty string in \u200b_prepare_related_fields_for_save() that's why pk from a related object is not used. We could use empty_values: diff --git a/django/db/models/b",
      "claude_patch": "# In django/db/models/base.py, modify the _prepare_related_fields_for_save method\n\ndef _prepare_related_fields_for_save(self, operation_name):\n    # Ensure that a model instance without a PK hasn't been assigned to\n    # a ForeignKey or OneToOneField on this model. If the field is\n    # nullable, allowing the save() would result in silent data loss.\n    for field in self._meta.concrete_fields:\n        # If the related field isn't cached, then an instance hasn't been\n        # assigned and there's no need to worry about this check.\n        if field.is_relation and field.is_cached(self):\n            obj = getattr(self, field.name, None)\n            if not obj:\n                continue\n            # A pk may have been assigned manually to a model instance not\n            # saved to the database (or auto-generated in a case like\n            # UUIDField), but we allow the save to proceed and rely on the\n            # database to raise an IntegrityError if applicable. If\n            # constraints aren't supported by the database, there's the\n            # unavoidable risk of data corruption.\n            if obj.pk is None:\n                # Remove the object from a related instance cache.\n                if not field.remote_field.multiple:\n                    field.remote_field.delete_cached_value(obj)\n                raise ValueError(\n                    \"%s() prohibited to prevent data loss due to unsaved \"\n                    \"related object '%s'.\" % (operation_name, field.name)\n                )\n            elif getattr(self, field.attname) in field.empty_values:\n                # Use pk from related object if it has been saved after\n                # an assignment.\n                setattr(self, field.attname, obj.pk)\n            # If the relationship's pk/to_field was changed, clear the\n            # cached relationship.\n            if getattr(obj, field.target_field.attname) != getattr(\n                self, field.attname\n            ):\n                field.delete_cached_value(self)",
      "generation_time": 14.598794221878052,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 7,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 1,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.7710765396524809,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path",
        "HIGH: loop_nesting - Extreme loop nesting: 4 levels"
      ],
      "verification_time": 0.04889082908630371,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-14016",
      "repo": "django/django",
      "problem_statement": "\"TypeError: cannot pickle\" when applying | operator to a Q object\nDescription\n\t \n\t\t(last modified by Daniel Izquierdo)\n\t \nUsing a reference to a non-pickleable type of object such as dict_keys in a Q object makes the | operator fail:\n>>> from django.db.models import Q\n>>> Q(x__in={}.keys())\n<Q: (AND: ('x__in', dict_keys([])))>\n>>> Q() | Q(x__in={}.keys())\nTraceback (most recent call last):\n...\nTypeError: cannot pickle 'dict_keys' object\nEven though this particular example could be solved by doin",
      "hints_text": "Thanks for this report. Regression in bb0b6e526340e638522e093765e534df4e4393d2.",
      "claude_patch": "# django/db/models/query_utils.py\n\nimport copy\nimport functools\nimport inspect\nfrom collections import namedtuple\n\nfrom django.core.exceptions import FieldError\nfrom django.db.models.constants import LOOKUP_SEP\n\n\nclass Q:\n    \"\"\"\n    Encapsulate filters as objects that can then be combined logically (using\n    `&` and `|`).\n    \"\"\"\n    # Connection types\n    AND = 'AND'\n    OR = 'OR'\n    default = AND\n    conditional = True\n\n    def __init__(self, *args, _connector=None, _negated=False, **kwargs):\n        self.children = list(args) + sorted(kwargs.items())\n        self.connector = _connector or self.default\n        self.negated = _negated\n\n    def _combine(self, other, conn):\n        if not isinstance(other, Q):\n            raise TypeError(other)\n\n        # If the other Q() is empty, ignore it and just use `self`.\n        if not other:\n            return copy.deepcopy(self)\n        # Or if this Q is empty, ignore it and just use `other`.\n        elif not self:\n            return copy.deepcopy(other)\n\n        obj = type(self)()\n        obj.connector = conn\n        obj.add(self, conn)\n        obj.add(other, conn)\n        return obj\n\n    def __or__(self, other):\n        return self._combine(other, self.OR)\n\n    def __and__(self, other):\n        return self._combine(other, self.AND)\n\n    def __invert__(self):\n        obj = type(self)()\n        obj.add(self, self.AND)\n        obj.negated = not self.negated\n        return obj\n\n    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n        # We must promote any new joins to left outer joins so that when Q is\n        # used as an expression, rows aren't filtered due to joins.\n        clause, joins = query._add_q(\n            self, reuse, allow_joins=allow_joins, split_subq=False,\n            check_filterable=False,\n        )\n        return clause\n\n    def deconstruct(self):\n        path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__)\n        args, kwargs = (), {}\n        if len(self.children) == 1 and not isinstance(self.children[0], Q):\n            child = self.children[0]\n            kwargs = {child[0]: child[1]}\n        else:\n            args = tuple(self.children)\n            if self.connector != self.default:\n                kwargs = {'_connector': self.connector}\n        if self.negated:\n            kwargs['_negated'] = True\n        return path, args, kwargs\n\n    def _normalize_value(self, value):\n        \"\"\"\n        Normalize values to ensure they are pickleable.\n        Convert dict_keys, dict_values, dict_items and other non-pickleable\n        iterables to lists.\n        \"\"\"\n        # Check if it's a dict_keys, dict_values, or dict_items\n        value_type = type(value).__name__\n        if value_type in ('dict_keys', 'dict_values', 'dict_items'):\n            return list(value)\n        # Check if it's another type of iterable that might not be pickleable\n        # but exclude strings and bytes\n        if hasattr(value, '__iter__') and not isinstance(value, (str, bytes)):\n            try:\n                # Try to pickle it\n                import pickle\n                pickle.dumps(value)\n            except (TypeError, AttributeError):\n                # If it fails, try to convert to list\n                try:\n                    return list(value)\n                except (TypeError, ValueError):\n                    # If conversion fails, return as-is and let it fail later\n                    pass\n        return value\n\n    def _normalize_children(self, children):\n        \"\"\"Normalize all children to ensure values are pickleable.\"\"\"\n        normalized = []\n        for child in children:\n            if isinstance(child, Q):\n                # Recursively normalize Q objects\n                normalized_q = type(child)(_connector=child.connector, _negated=child.negated)\n                normalized_q.children = self._normalize_children(child.children)\n                normalized.append(normalized_q)\n            elif isinstance(child, tuple) and len(child) == 2:\n                # Normalize the value in (key, value) tuples\n                key, value = child\n                normalized.append((key, self._normalize_value(value)))\n            else:\n                normalized.append(child)\n        return normalized\n\n    def add(self, node, conn):\n        \"\"\"\n        Combine this tree and the node with the connector. If the node is\n        of the same type as this tree, it can be merged using the\n        connector. Otherwise, it must be added as a child.\n        \"\"\"\n        if node in self.children and conn == self.connector:\n            return\n        \n        # Normalize children before adding to ensure pickleable values\n        if isinstance(node, Q):\n            normalized_node = type(node)(_connector=node.connector, _negated=node.negated)\n            normalized_node.children = self._normalize_children(node.children)\n            node = normalized_node\n        \n        if len(self.children) < 2:\n            self.children.append(node)\n            return\n\n        if self.connector == conn:\n            # We can reuse self.connector\n            if isinstance(node, Q) and not node.negated and (node.connector == conn or len(node) == 1):\n                # We can merge the children directly into this tree\n                self.children.extend(node.children)\n            else:\n                self.children.append(node)\n        else:\n            # We need to create a new tree\n            obj = type(self)(_connector=conn)\n            obj.children = self.children[:]\n            self.connector = conn\n            self.children = [obj, node]\n\n    def __bool__(self):\n        return bool(self.children)\n\n    def __contains__(self, other):\n        return other in self.children\n\n    def __eq__(self, other):\n        return self.__class__ == other.__class__ and (\n            self.connector, self.negated, self.children\n        ) == (other.connector, other.negated, other.children)\n\n    def __hash__(self):\n        return hash((self.__class__, self.connector, self.negated, tuple(self.children)))\n\n    def __len__(self):\n        return len(self.children)\n\n    def __iter__(self):\n        return iter(self.children)\n\n    def __repr__(self):\n        template = '(NOT (%s: %s))' if self.negated else '(%s: %s)'\n        return template % (self.connector, ', '.join(str(c) for c in self.children))\n\n    def __deepcopy__(self, memodict):\n        obj = type(self)(_connector=self.connector, _negated=self.negated)\n        # Normalize children during deepcopy to ensure pickleable values\n        obj.children = self._normalize_children(copy.deepcopy(self.children, memodict))\n        return obj",
      "generation_time": 30.840433835983276,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 26,
      "critical_issues": 0,
      "high_issues": 10,
      "medium_issues": 9,
      "low_issues": 7,
      "agent_scores": {
        "security": 0.75,
        "correctness": 0.4,
        "style": 0.2460000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: dangerous_import - High-risk import: pickle (risk level: 2)",
        "HIGH: vulnerable_dependency - Vulnerable dependency: pickle - Arbitrary code execution during deserialization"
      ],
      "verification_time": 0.2056262493133545,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14017",
      "repo": "django/django",
      "problem_statement": "Q(...) & Exists(...) raises a TypeError\nDescription\n\t\nExists(...) & Q(...) works, but Q(...) & Exists(...) raise a TypeError\nHere's a minimal example:\nIn [3]: Exists(Product.objects.all()) & Q()\nOut[3]: <Q: (AND: <django.db.models.expressions.Exists object at 0x7fc18dd0ed90>, (AND: ))>\nIn [4]: Q() & Exists(Product.objects.all())\n---------------------------------------------------------------------------\nTypeError\t\t\t\t\t\t\t\t Traceback (most recent call last)\n<ipython-input-4-21d3dea0fcb9> in <module",
      "hints_text": "Reproduced on 3.1.6. The exception is raised by this two lines in the Q._combine, which are not present in the Combinable._combine from which Exists inherit. if not isinstance(other, Q): raise TypeErr",
      "claude_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -91,6 +91,9 @@ class Q(tree.Node):\n     def __and__(self, other):\n         return self._combine(other, self.AND)\n \n+    def __rand__(self, other):\n+        return self._combine(other, self.AND)\n+\n     def __invert__(self):\n         obj = type(self)()\n         obj.add(self, self.AND)\n@@ -100,6 +103,9 @@ class Q(tree.Node):\n     def __or__(self, other):\n         return self._combine(other, self.OR)\n \n+    def __ror__(self, other):\n+        return self._combine(other, self.OR)\n+\n     def __xor__(self, other):\n         return self._combine(other, self.XOR)",
      "generation_time": 4.795194149017334,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.03834104537963867,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14155",
      "repo": "django/django",
      "problem_statement": "ResolverMatch.__repr__() doesn't handle functools.partial() nicely.\nDescription\n\t \n\t\t(last modified by Nick Pope)\n\t \nWhen a partial function is passed as the view, the __repr__ shows the func argument as functools.partial which isn't very helpful, especially as it doesn't reveal the underlying function or arguments provided.\nBecause a partial function also has arguments provided up front, we need to handle those specially so that they are accessible in __repr__.\nISTM that we can simply unwrap fu",
      "hints_text": null,
      "claude_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 1234567890..abcdefghij 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -1,6 +1,7 @@\n \"\"\"\n This module converts requested URLs to callback view functions.\n \"\"\"\n+import functools\n import inspect\n import re\n import string\n@@ -32,6 +33,18 @@ class ResolverMatch:\n         self._func_path = None\n         self.url_name = url_name\n         self.route = route\n+        \n+        # Unwrap functools.partial objects to get the underlying function\n+        # and merge the partial's arguments with the captured arguments\n+        if isinstance(func, functools.partial):\n+            # Merge partial's kwargs with captured kwargs (captured kwargs take precedence)\n+            partial_kwargs = func.keywords.copy()\n+            partial_kwargs.update(kwargs)\n+            # Prepend partial's args to captured args\n+            args = func.args + args\n+            kwargs = partial_kwargs\n+            # Get the underlying function\n+            func = func.func\n \n     def __getitem__(self, index):\n         return (self.func, self.args, self.kwargs)[index]",
      "generation_time": 6.858582019805908,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.042634010314941406,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14238",
      "repo": "django/django",
      "problem_statement": "DEFAULT_AUTO_FIELD subclass check fails for subclasses of BigAutoField and SmallAutoField.\nDescription\n\t\nSet DEFAULT_AUTO_FIELD = \"example.core.models.MyBigAutoField\" , with contents of example.core.models:\nfrom django.db import models\nclass MyBigAutoField(models.BigAutoField):\n\tpass\nclass MyModel(models.Model):\n\tpass\nDjango then crashes with:\nTraceback (most recent call last):\n File \"/..././manage.py\", line 21, in <module>\n\tmain()\n File \"/..././manage.py\", line 17, in main\n\texecute_from_command",
      "hints_text": null,
      "claude_patch": "# django/db/models/fields/__init__.py\n\nclass AutoFieldMeta(type):\n    \"\"\"\n    Metaclass to maintain backward inheritance compatibility for AutoField.\n\n    It is intended that AutoFieldMixin become public API when it is possible to\n    create a non-integer automatically-generated field using column defaults\n    stored in the database.\n\n    In many areas Django also relies on using isinstance() to check for an\n    automatically-generated field as a subclass of AutoField. A new flag needs\n    to be implemented on Field to be used instead.\n\n    When these issues have been addressed, this metaclass could be used to\n    deprecate inheritance from AutoField and use of isinstance() with AutoField\n    for detecting automatically-generated fields.\n    \"\"\"\n\n    @property\n    def _subclasses(cls):\n        return (\n            BigAutoField,\n            SmallAutoField,\n        )\n\n    def __instancecheck__(cls, instance):\n        if cls is AutoField:\n            return isinstance(instance, cls._subclasses) or super().__instancecheck__(instance)\n        return super().__instancecheck__(instance)\n\n    def __subclasscheck__(cls, subclass):\n        if cls is AutoField:\n            # Check if subclass is a subclass of any of the _subclasses\n            for auto_field_class in cls._subclasses:\n                if issubclass(subclass, auto_field_class):\n                    return True\n            return super().__subclasscheck__(subclass)\n        return super().__subclasscheck__(subclass)",
      "generation_time": 10.189722061157227,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 13,
      "critical_issues": 0,
      "high_issues": 4,
      "medium_issues": 3,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4066666666666666,
        "style": 0.7452347994927053,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 66.7%",
        "HIGH: edge_case_coverage - Low edge case coverage: 33.3%",
        "HIGH: production_readiness - Low production readiness: 67.8%"
      ],
      "verification_time": 0.041773080825805664,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14382",
      "repo": "django/django",
      "problem_statement": "django-admin startapp with trailing slash in directory name results in error\nDescription\n\t\nBash tab-completion appends trailing slashes to directory names. django-admin startapp name directory/ results in the error:\nCommandError: '' is not a valid app directory. Please make sure the directory is a valid identifier.\nThe error is caused by \u200bline 77 of django/core/management/templates.py by calling basename() on the path with no consideration for a trailing slash:\nself.validate_name(os.path.basenam",
      "hints_text": "OK, yes, this seems a case we could handle. I didn't look into exactly why but it works for startproject: $ django-admin startproject ticket32734 testing/ Thanks for the report. Do you fancy making a ",
      "claude_patch": "# Patch for django/core/management/templates.py\n\n# The fix is to strip trailing path separators before calling basename\n# This should be applied around line 77 in django/core/management/templates.py\n\n# Original code:\n# self.validate_name(os.path.basename(target), 'directory')\n\n# Fixed code:\nself.validate_name(os.path.basename(target.rstrip(os.sep)), 'directory')",
      "generation_time": 3.4881458282470703,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 3,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 0,
      "low_issues": 2,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.04325413703918457,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-14411",
      "repo": "django/django",
      "problem_statement": "Label for ReadOnlyPasswordHashWidget points to non-labelable element.\nDescription\n\t \n\t\t(last modified by David Sanders)\n\t \nIn the admin, the label element for the ReadOnlyPasswordHashWidget widget has a 'for' attribute which points to a non-labelable element, since the widget just renders text, not an input. There's no labelable element for the widget, so the label shouldn't have a 'for' attribute.\n",
      "hints_text": null,
      "claude_patch": "from django.contrib.auth.forms import ReadOnlyPasswordHashWidget\n\n# Patch the ReadOnlyPasswordHashWidget to not render a labelable element\noriginal_init = ReadOnlyPasswordHashWidget.__init__\n\ndef patched_init(self, attrs=None):\n    original_init(self, attrs)\n    # Set is_hidden to False but ensure no 'id' is rendered\n    # by not setting an id_for_label\n    \noriginal_get_context = ReadOnlyPasswordHashWidget.get_context\n\ndef patched_get_context(self, name, value, attrs):\n    context = original_get_context(self, name, value, attrs)\n    # Remove the 'id' attribute from widget attrs to prevent label 'for' attribute\n    if 'attrs' in context['widget'] and context['widget']['attrs']:\n        context['widget']['attrs'].pop('id', None)\n    return context\n\n# Check if id_for_label method exists and patch it\nif hasattr(ReadOnlyPasswordHashWidget, 'id_for_label'):\n    def patched_id_for_label(self, id_):\n        # Return None so that the label doesn't get a 'for' attribute\n        return None\n    \n    ReadOnlyPasswordHashWidget.id_for_label = patched_id_for_label\nelse:\n    # Add the method if it doesn't exist\n    def patched_id_for_label(self, id_):\n        return None\n    \n    ReadOnlyPasswordHashWidget.id_for_label = patched_id_for_label\n\nReadOnlyPasswordHashWidget.__init__ = patched_init\nReadOnlyPasswordHashWidget.get_context = patched_get_context",
      "generation_time": 8.060074090957642,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 9,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.43333333333333335,
        "style": 0.8233676313289201,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%",
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.21846723556518555,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14534",
      "repo": "django/django",
      "problem_statement": "BoundWidget.id_for_label ignores id set by ChoiceWidget.options\nDescription\n\t\nIf you look at the implementation of BoundField.subwidgets\nclass BoundField:\n\t...\n\tdef subwidgets(self):\n\t\tid_ = self.field.widget.attrs.get('id') or self.auto_id\n\t\tattrs = {'id': id_} if id_ else {}\n\t\tattrs = self.build_widget_attrs(attrs)\n\t\treturn [\n\t\t\tBoundWidget(self.field.widget, widget, self.form.renderer)\n\t\t\tfor widget in self.field.widget.subwidgets(self.html_name, self.value(), attrs=attrs)\n\t\t]\none sees that s",
      "hints_text": "Hey Jacob \u2014 Sounds right: I didn't look in-depth but, if you can put your example in a test case it will be clear enough in the PR. Thanks.\nThanks Carlton, I will create a pull request asap.\nHere is a",
      "claude_patch": "# Patch for django/forms/boundfield.py\n\nclass BoundWidget:\n    def id_for_label(self):\n        return self.data['attrs'].get('id', '')",
      "generation_time": 2.61582088470459,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 3,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.8233333333333334,
        "style": 0.822,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%"
      ],
      "verification_time": 0.04136514663696289,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-14580",
      "repo": "django/django",
      "problem_statement": "Missing import statement in generated migration (NameError: name 'models' is not defined)\nDescription\n\t\nI found a bug in Django's latest release: 3.2.4. \nGiven the following contents of models.py:\nfrom django.db import models\nclass MyField(models.TextField):\n\tpass\nclass MyBaseModel(models.Model):\n\tclass Meta:\n\t\tabstract = True\nclass MyMixin:\n\tpass\nclass MyModel(MyMixin, MyBaseModel):\n\tname = MyField(primary_key=True)\nThe makemigrations command will generate the following migration file:\n# Genera",
      "hints_text": "I could reproduce the issue with 3.2.4, 2.2.24 and the main branch. For what it's worth, the issue doesn't occur if the class MyModel does inherit from MyMixin.\nMyBaseModel is not necessary to reprodu",
      "claude_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex e19c881cda..6e78462e95 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -273,7 +273,7 @@ class TupleSerializer(BaseSequenceSerializer):\n class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n-            (models.Model, \"models.Model\", []),\n+            (models.Model, \"models.Model\", ['from django.db import models']),\n             (type(None), 'type(None)', []),\n         ]\n         for case, string, imports in special_cases:",
      "generation_time": 3.5239970684051514,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid decimal literal (<unknown>, line 2)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04036974906921387,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14608",
      "repo": "django/django",
      "problem_statement": "Add `nonform` CSS class for non form errors in FormSets\nDescription\n\t \n\t\t(last modified by Ties Jan Hefting)\n\t \nForms add the nonfield CSS class for non field errors in ErrorList instances. This is documented in a section on \u200brendering form error messages. Similarly, in FormSets I'd expect to see the nonform CSS class added for non form errors. This would allow a custom ErrorList to make a distinction in form field errors, non field errors (forms) and non form errors (FormSets) when rendering er",
      "hints_text": "Seems reasonable (similar to #11776).\n\u200bPR",
      "claude_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 1234567890..abcdefghij 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -320,7 +320,7 @@ class BaseFormSet:\n         \"\"\"Return an ErrorList of errors that aren't associated with a particular\n         form -- i.e., from formset.clean(). Return an empty ErrorList if there\n         are none.\"\"\"\n-        return self._non_form_errors\n+        return self.error_class(self._non_form_errors, error_class='nonform')\n \n     @property\n     def errors(self):",
      "generation_time": 8.753127813339233,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.04375100135803223,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14667",
      "repo": "django/django",
      "problem_statement": "QuerySet.defer() doesn't clear deferred field when chaining with only().\nDescription\n\t\nConsidering a simple Company model with four fields: id, name, trade_number and country. If we evaluate a queryset containing a .defer() following a .only(), the generated sql query selects unexpected fields. For example: \nCompany.objects.only(\"name\").defer(\"name\")\nloads all the fields with the following query:\nSELECT \"company\".\"id\", \"company\".\"name\", \"company\".\"trade_number\", \"company\".\"country\" FROM \"company",
      "hints_text": "Replying to Manuel Baclet: Considering a simple Company model with four fields: id, name, trade_number and country. If we evaluate a queryset containing a .defer() following a .only(), the generated s",
      "claude_patch": "# django/db/models/query.py\n\ndef defer(self, *fields):\n    \"\"\"\n    Defer the loading of data for certain fields until they are accessed.\n    Add the set of deferred fields to any existing set.\n    \"\"\"\n    self._not_support_combined_queries(\"defer\")\n    if self._fields is not None:\n        raise TypeError(\"Cannot call defer() after .values() or .values_list()\")\n    clone = self._chain()\n    if fields == (None,):\n        clone.query.clear_deferred_loading()\n    else:\n        clone.query.add_deferred_loading(fields)\n    return clone\n\n\n# django/db/models/sql/query.py\n\ndef add_deferred_loading(self, field_names):\n    \"\"\"\n    Add the given list of model field names to the set of fields to\n    exclude from loading from the database when automatic column selection\n    is done. Add the new fields to any existing field names that\n    are deferred (or removed from any existing field names that are marked\n    as the only ones for immediate loading).\n    \"\"\"\n    # Fields on related models are stored in the literal double-underscore\n    # format, so that we can use a set datastructure. We do the foo__bar\n    # splitting and handling when computing the SQL column names (as part of\n    # get_columns()).\n    field_names = set(field_names)\n    if not field_names:\n        return\n    \n    if self.deferred_loading[1]:\n        # We're in \"only\" mode. If we're deferring fields that were\n        # specified in only(), we need to handle this specially.\n        existing = set(self.deferred_loading[0])\n        # Find fields that are being deferred that were in the only() set\n        fields_to_remove = existing.intersection(field_names)\n        \n        if fields_to_remove:\n            # Remove these fields from the only() set\n            remaining_only = existing.difference(field_names)\n            # Fields being deferred that weren't in only() set\n            additional_defers = field_names.difference(existing)\n            \n            if not remaining_only:\n                # All only() fields have been deferred, switch to defer mode\n                # The deferred set should be the additional fields being deferred\n                self.deferred_loading = (additional_defers, False)\n            else:\n                # Some only() fields remain\n                self.deferred_loading = (remaining_only, True)\n        else:\n            # None of the deferred fields were in only() set, just add them\n            # This means we're adding more fields to defer beyond the only() set\n            # We need to switch to defer mode with all non-only fields plus these new ones\n            self.deferred_loading = (existing.union(field_names), True)\n    else:\n        # We're in \"defer\" mode. Add to the deferred set.\n        self.deferred_loading = (\n            self.deferred_loading[0].union(field_names),\n            False,\n        )",
      "generation_time": 24.173648834228516,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 11,
      "critical_issues": 0,
      "high_issues": 4,
      "medium_issues": 3,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4866666666666666,
        "style": 0.862,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 50.0%",
        "HIGH: edge_case_coverage - Low edge case coverage: 50.0%",
        "HIGH: production_readiness - Low production readiness: 76.7%"
      ],
      "verification_time": 0.05282902717590332,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14672",
      "repo": "django/django",
      "problem_statement": "Missing call `make_hashable` on `through_fields` in `ManyToManyRel`\nDescription\n\t\nIn 3.2 identity property has been added to all ForeignObjectRel to make it possible to compare them. A hash is derived from said identity and it's possible because identity is a tuple. To make limit_choices_to hashable (one of this tuple elements), \u200bthere's a call to make_hashable.\nIt happens that through_fields can be a list. In such case, this make_hashable call is missing in \u200bManyToManyRel.\nFor some reason it on",
      "hints_text": null,
      "claude_patch": "# django/db/models/fields/reverse_related.py\n\nfrom django.db.models.query_utils import make_hashable\n\n# Find the ManyToManyRel class and update its identity property\n# The issue is that through_fields can be a list, which is not hashable\n\nclass ManyToManyRel(ForeignObjectRel):\n    \"\"\"\n    Used by ManyToManyField to store information about the relation.\n\n    ``_meta.get_fields()`` returns this class to provide access to the field\n    flags for the reverse relation.\n    \"\"\"\n\n    def __init__(\n        self,\n        field,\n        to,\n        related_name=None,\n        related_query_name=None,\n        limit_choices_to=None,\n        symmetrical=True,\n        through=None,\n        through_fields=None,\n        db_constraint=True,\n    ):\n        super().__init__(\n            field,\n            to,\n            related_name=related_name,\n            related_query_name=related_query_name,\n            limit_choices_to=limit_choices_to,\n        )\n\n        if through and not db_constraint:\n            raise ValueError(\"Can't supply a through model and db_constraint=False\")\n        self.through = through\n\n        if through_fields and not through:\n            raise ValueError(\"Cannot specify through_fields without a through model\")\n        self.through_fields = through_fields\n\n        self.symmetrical = symmetrical\n        self.db_constraint = db_constraint\n\n    def get_related_field(self):\n        \"\"\"\n        Return the field in the 'to' object to which this relationship is tied.\n        Provided for symmetry with ManyToOneRel.\n        \"\"\"\n        opts = self.through._meta\n        if self.through_fields:\n            field = opts.get_field(self.through_fields[0])\n        else:\n            for field in opts.fields:\n                rel = getattr(field, \"remote_field\", None)\n                if rel and rel.model == self.model:\n                    break\n        return field.foreign_related_fields[0]\n\n    @property\n    def identity(self):\n        return super().identity + (\n            self.through,\n            make_hashable(self.through_fields),\n        )",
      "generation_time": 11.385819911956787,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 19,
      "critical_issues": 0,
      "high_issues": 6,
      "medium_issues": 6,
      "low_issues": 7,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.65,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: ast_analysis - Public function 'identity' missing docstring - production documentation required",
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%"
      ],
      "verification_time": 0.17528104782104492,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14730",
      "repo": "django/django",
      "problem_statement": "Prevent developers from defining a related_name on symmetrical ManyToManyFields\nDescription\n\t\nIn ManyToManyField, if the symmetrical argument is passed, or if it's a self-referential ManyToMany relationship, the related field on the target model is not created. However, if a developer passes in the related_name not understanding this fact, they may be confused until they find the information about symmetrical relationship. Thus, it is proposed to raise an error when the user defines a ManyToMany",
      "hints_text": "I have a PR that implements this incoming.\n\u200bhttps://github.com/django/django/pull/14730\nOK, I guess we can do something here \u2014 it probably is a source of confusion. The same issue was raised in #18021",
      "claude_patch": "# django/db/models/fields/related.py\n\n# Add this import at the top of the file if not already present\nfrom django.core import checks\n\n# Add this method to the ManyToManyField class\n\ndef _check_relationship_model(self):\n    errors = super()._check_relationship_model()\n    errors.extend(self._check_symmetrical_related_name())\n    return errors\n\ndef _check_symmetrical_related_name(self):\n    \"\"\"\n    Check that related_name is not specified on symmetrical ManyToManyFields.\n    \"\"\"\n    if self.remote_field.symmetrical and self.remote_field.related_name is not None:\n        return [\n            checks.Error(\n                'related_name has no effect on ManyToManyField with symmetrical=True.',\n                hint=(\n                    'Remove the related_name argument or set symmetrical=False. '\n                    'For symmetrical relationships, both sides of the relationship '\n                    'are identical, so related_name is not used.'\n                ),\n                obj=self,\n                id='fields.E332',\n            )\n        ]\n    return []",
      "generation_time": 5.980330944061279,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 9,
      "critical_issues": 0,
      "high_issues": 4,
      "medium_issues": 0,
      "low_issues": 5,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 0.8066666666666665,
        "style": 0.8985627884908447,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: edge_case_coverage - Low edge case coverage: 50.0%",
        "HIGH: production_readiness - Low production readiness: 80.0%"
      ],
      "verification_time": 0.10272812843322754,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14752",
      "repo": "django/django",
      "problem_statement": "Refactor AutocompleteJsonView to support extra fields in autocomplete response\nDescription\n\t \n\t\t(last modified by mrts)\n\t \nAdding data attributes to items in ordinary non-autocomplete foreign key fields that use forms.widgets.Select-based widgets is relatively easy. This enables powerful and dynamic admin site customizations where fields from related models are updated immediately when users change the selected item.\nHowever, adding new attributes to autocomplete field results currently requires",
      "hints_text": "Makes sense to me.",
      "claude_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 1234567890..abcdef1234 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -1,88 +1,95 @@\n from django.apps import apps\n from django.core.exceptions import FieldDoesNotExist, PermissionDenied\n from django.http import Http404, JsonResponse\n from django.views.generic.list import BaseListView\n \n \n class AutocompleteJsonView(BaseListView):\n     \"\"\"Handle AutocompleteWidget's AJAX requests for data.\"\"\"\n \n     paginate_by = 20\n     admin_site = None\n \n     def get(self, request, *args, **kwargs):\n         \"\"\"\n         Return a JsonResponse with search results as defined by term, page,\n         and model_admin attributes.\n         \"\"\"\n         (\n             self.term,\n             self.model_admin,\n             self.source_field,\n             to_field_name,\n         ) = self.process_request(request)\n \n         if not self.has_perm(request):\n             raise PermissionDenied\n \n         self.object_list = self.get_queryset()\n         context = self.get_context_data()\n         return JsonResponse(\n             {\n                 \"results\": [\n-                    {\"id\": str(getattr(obj, to_field_name)), \"text\": str(obj)}\n+                    self.serialize_result(obj, to_field_name)\n                     for obj in context[\"object_list\"]\n                 ],\n                 \"pagination\": {\"more\": context[\"page_obj\"].has_next()},\n             }\n         )\n \n     def get_paginator(self, *args, **kwargs):\n         \"\"\"Use the ModelAdmin's paginator.\"\"\"\n         return self.model_admin.get_paginator(\n             self.request, *args, **kwargs\n         )\n \n     def get_queryset(self):\n         \"\"\"Return queryset based on ModelAdmin.get_search_results().\"\"\"\n         qs = self.model_admin.get_queryset(self.request)\n         qs = qs.complex_filter(self.source_field.get_limit_choices_to())\n         qs, search_use_distinct = self.model_admin.get_search_results(\n             self.request, qs, self.term\n         )\n         if search_use_distinct:\n             qs = qs.distinct()\n         return qs\n \n     def process_request(self, request):\n         \"\"\"\n         Validate request integrity, extract and return request parameters.\n \n         Since the subsequent view permission check requires the target model\n         admin, which is determined here, raise PermissionDenied if the\n         requested app, model or field are malformed.\n \n         Raise Http404 if the target model admin is not configured properly with\n         search_fields.\n         \"\"\"\n         term = request.GET.get(\"term\", \"\")\n         try:\n             app_label = request.GET[\"app_label\"]\n             model_name = request.GET[\"model_name\"]\n             field_name = request.GET[\"field_name\"]\n         except KeyError as e:\n             raise PermissionDenied from e\n \n         # Retrieve objects from parameters.\n         try:\n             source_model = apps.get_model(app_label, model_name)\n         except LookupError as e:\n             raise PermissionDenied from e\n \n         try:\n             source_field = source_model._meta.get_field(field_name)\n         except FieldDoesNotExist as e:\n             raise PermissionDenied from e\n         try:\n             remote_model = source_field.remote_field.model\n         except AttributeError as e:\n             raise PermissionDenied from e\n         try:\n             model_admin = self.admin_site._registry[remote_model]\n         except KeyError as e:\n             raise PermissionDenied from e\n \n         # Validate suitability of objects.\n         if not model_admin.get_search_fields(request):\n             raise Http404(\n                 \"%s must have search_fields for the autocomplete_view.\"\n                 % type(model_admin).__qualname__\n             )\n \n         to_field_name = getattr(\n             source_field.remote_field, \"field_name\", remote_model._meta.pk.attname\n         )\n         to_field_name = remote_model._meta.get_field(to_field_name).attname\n         if not model_admin.to_field_allowed(request, to_field_name):\n             raise PermissionDenied\n \n         return term, model_admin, source_field, to_field_name\n \n     def has_perm(self, request, obj=None):\n         \"\"\"Check if user has permission to access the related model.\"\"\"\n         return self.model_admin.has_view_permission(request, obj=obj)\n+\n+    def serialize_result(self, obj, to_field_name):\n+        \"\"\"\n+        Convert the provided model object to a dictionary that is added to the\n+        results list.\n+        \"\"\"\n+        return {\"id\": str(getattr(obj, to_field_name)), \"text\": str(obj)}",
      "generation_time": 19.889448404312134,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.0,
      "verification_verdict": "ERROR",
      "issues_found": 1,
      "critical_issues": 1,
      "high_issues": 0,
      "medium_issues": 0,
      "low_issues": 0,
      "agent_scores": {},
      "key_issues": [
        "CRITICAL: system_error - Verification failed: sequence item 1: expected str instance, NoneType found"
      ],
      "verification_time": 0.046730995178222656,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14787",
      "repo": "django/django",
      "problem_statement": "method_decorator() should preserve wrapper assignments\nDescription\n\t\nthe function that is passed to the decorator is a partial object and does not have any of the attributes expected from a function i.e. __name__, __module__ etc...\nconsider the following case\ndef logger(func):\n\t@wraps(func)\n\tdef inner(*args, **kwargs):\n\t\ttry:\n\t\t\tresult = func(*args, **kwargs)\n\t\texcept Exception as e:\n\t\t\tresult = str(e)\n\t\tfinally:\n\t\t\tlogger.debug(f\"{func.__name__} called with args: {args} and kwargs: {kwargs} res",
      "hints_text": null,
      "claude_patch": "import functools\nfrom functools import WRAPPER_ASSIGNMENTS, WRAPPER_UPDATES\n\ndef _update_method_wrapper(wrapper, decorator):\n    \"\"\"\n    Update the wrapper function to look more like the decorated function by\n    copying attributes from the decorator if available.\n    \"\"\"\n    # Get the actual function from partial if needed\n    func = decorator\n    while isinstance(func, functools.partial):\n        func = func.func\n    \n    # Copy standard wrapper assignments\n    for attr in WRAPPER_ASSIGNMENTS:\n        try:\n            value = getattr(func, attr)\n        except AttributeError:\n            pass\n        else:\n            setattr(wrapper, attr, value)\n    \n    # Copy standard wrapper updates\n    for attr in WRAPPER_UPDATES:\n        try:\n            getattr(wrapper, attr).update(getattr(func, attr, {}))\n        except AttributeError:\n            pass\n    \n    # Set __wrapped__ to the actual function\n    wrapper.__wrapped__ = func\n    \n    return wrapper\n\ndef method_decorator(decorator, name=''):\n    \"\"\"\n    Convert a function decorator into a method decorator\n    \"\"\"\n    # If decorator is a partial, we need to handle it specially\n    if isinstance(decorator, functools.partial):\n        # Get the actual decorator function\n        actual_decorator = decorator.func\n        # Get the partial's args and kwargs\n        partial_args = decorator.args\n        partial_kwargs = decorator.keywords\n        \n        def _decorator(func):\n            # Apply the decorator with the partial's arguments\n            decorated = actual_decorator(*partial_args, **partial_kwargs)(func)\n            # Update wrapper assignments from the original function\n            return functools.wraps(func)(lambda *args, **kwargs: decorated(*args, **kwargs))\n        \n        return _decorator\n    \n    def _dec(func):\n        if hasattr(decorator, '__name__'):\n            update_wrapper = functools.wraps(func)\n        else:\n            # If decorator doesn't have __name__, create a custom wrapper updater\n            def update_wrapper(wrapper):\n                return _update_method_wrapper(wrapper, func)\n        \n        def _wrapper(*args, **kwargs):\n            @decorator\n            def bound_func(*args2, **kwargs2):\n                return func(*args, **kwargs)\n            return bound_func(*args, **kwargs)\n        \n        return update_wrapper(_wrapper)\n    \n    if not name:\n        return _dec\n    \n    def _multi_dec(cls):\n        method = getattr(cls, name)\n        setattr(cls, name, _dec(method))\n        return cls\n    \n    return _multi_dec",
      "generation_time": 11.66682481765747,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 4,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.68,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: empty_exception_handler - Empty exception handler - production systems need error logging",
        "HIGH: exception_coverage - Low exception handling coverage: 37.5%"
      ],
      "verification_time": 0.054305076599121094,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14855",
      "repo": "django/django",
      "problem_statement": "Wrong URL generated by get_admin_url for readonly field in custom Admin Site\nDescription\n\t\nWhen a model containing a ForeignKey field is viewed (or edited) in a custom Admin Site, and that ForeignKey field is listed in readonly_fields, the url generated for the link is /admin/... instead of /custom-admin/....\nThis appears to be caused by the following line in django.contrib.admin.helpers get_admin_url:\nurl = reverse(url_name, args=[quote(remote_obj.pk)])\nOther parts of the admin use the current_",
      "hints_text": "Hey Ken, yes seems right. Good spot. Looks like this should have been part of b79088306513d5ed76d31ac40ab3c15f858946ea for #31181 (which was Django 3.2) \u200bhere. However, I don't know if there are any s",
      "claude_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex 1234567890..abcdef1234 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -234,7 +234,10 @@ class AdminReadonlyField:\n                 url_name = 'admin:%s_%s_change' % (\n                     remote_obj._meta.app_label, remote_obj._meta.model_name)\n                 try:\n-                    url = reverse(url_name, args=[quote(remote_obj.pk)])\n+                    url = reverse(\n+                        url_name,\n+                        args=[quote(remote_obj.pk)],\n+                        current_app=self.model_admin.admin_site.name,\n+                    )\n                     return format_html('<a href=\"{}\">{}</a>', url, display_value)\n                 except NoReverseMatch:\n                     pass",
      "generation_time": 4.947149038314819,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.05891585350036621,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14915",
      "repo": "django/django",
      "problem_statement": "ModelChoiceIteratorValue is not hashable.\nDescription\n\t\nRecently I migrated from Django 3.0 to Django 3.1. In my code, I add custom data-* attributes to the select widget options. After the upgrade some of those options broke. Error is {TypeError}unhashable type: 'ModelChoiceIteratorValue'.\nExample (this one breaks):\n\tdef create_option(self, name, value, label, selected, index, subindex=None, attrs=None):\n\t\tcontext = super().create_option(name, value, label, selected, index, subindex, attrs)\n\t\ti",
      "hints_text": "Thanks for the ticket. Agreed, we could make ModelChoiceIteratorValue hashable by adding: def __hash__(self): return hash(self.value) For now you can use value.value as \u200bdocumented in the \"Backwards i",
      "claude_patch": "from django.forms.models import ModelChoiceIteratorValue\n\n# Add __hash__ method to ModelChoiceIteratorValue class\noriginal_init = ModelChoiceIteratorValue.__init__\n\ndef __hash__(self):\n    return hash(self.value)\n\nModelChoiceIteratorValue.__hash__ = __hash__",
      "generation_time": 5.9455671310424805,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 7,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 1,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.9133333333333333,
        "style": 0.822,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%"
      ],
      "verification_time": 0.18407511711120605,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-14997",
      "repo": "django/django",
      "problem_statement": "Remaking table with unique constraint crashes on SQLite.\nDescription\n\t\nIn Django 4.0a1, this model:\nclass Tag(models.Model):\n\tname = models.SlugField(help_text=\"The tag key.\")\n\tvalue = models.CharField(max_length=150, help_text=\"The tag value.\")\n\tclass Meta:\n\t\tordering = [\"name\", \"value\"]\n\t\tconstraints = [\n\t\t\tmodels.UniqueConstraint(\n\t\t\t\t\"name\",\n\t\t\t\t\"value\",\n\t\t\t\tname=\"unique_name_value\",\n\t\t\t)\n\t\t]\n\tdef __str__(self):\n\t\treturn f\"{self.name}={self.value}\"\nwith these migrations, using sqlite:\nclass ",
      "hints_text": "Thanks for the report. Regression in 3aa545281e0c0f9fac93753e3769df9e0334dbaa.\nThanks for the report! Looks like we don't check if an alias is set on the Col before we update it to new_table in Expres",
      "claude_patch": "# django/db/models/expressions.py\n\nclass Col(Expression):\n    # ... existing code ...\n    \n    def rename_table_references(self, old_table, new_table):\n        if self.alias == old_table:\n            # Only rename if we don't have an explicit alias set\n            # When alias is set, it means this Col is being used in a context\n            # where the table reference should be preserved (like in a constraint)\n            return self.__class__(\n                new_table, self.target, self.output_field\n            )\n        return self\n\n    # ... existing code ...",
      "generation_time": 31.01772427558899,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 11,
      "critical_issues": 0,
      "high_issues": 4,
      "medium_issues": 3,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.6366666666666666,
        "style": 0.822,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 63.3%",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.0598759651184082,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-14999",
      "repo": "django/django",
      "problem_statement": "RenameModel with db_table should be a noop.\nDescription\n\t\nA RenameModel operation that already has db_table defined must be a noop.\nIn Postgres, it drops and recreates foreign key constraints. In sqlite it recreates the table (as expected for a table renaming).\n",
      "hints_text": null,
      "claude_patch": "# django/db/migrations/operations/models.py\n\ndef database_forwards(self, app_label, schema_editor, from_state, to_state):\n    new_model = to_state.apps.get_model(app_label, self.new_name)\n    if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n        old_model = from_state.apps.get_model(app_label, self.old_name)\n        # Check if both models have the same db_table\n        old_db_table = old_model._meta.db_table\n        new_db_table = new_model._meta.db_table\n        \n        # If db_table is explicitly set and unchanged, this is a noop\n        if old_db_table == new_db_table:\n            return\n            \n        # Move the main table\n        schema_editor.alter_db_table(\n            new_model,\n            old_model._meta.db_table,\n            new_model._meta.db_table,\n        )\n        # Alter the fields pointing to us\n        for related_object in old_model._meta.related_objects:\n            if related_object.related_model == old_model:\n                model = new_model\n                related_key = (app_label, self.new_name_lower)\n            else:\n                model = related_object.related_model\n                related_key = (\n                    related_object.related_model._meta.app_label,\n                    related_object.related_model._meta.model_name,\n                )\n            to_field = to_state.models[related_key].fields[\n                related_object.field.name\n            ]\n            schema_editor.alter_field(\n                model,\n                related_object.field,\n                to_field,\n            )\n        # Rename M2M fields whose name is based on this model's name.\n        fields = zip(\n            old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n        )\n        for old_field, new_field in fields:\n            # Skip self-referential fields as these are renamed above.\n            if (\n                new_field.model == new_field.related_model\n                or not new_field.remote_field.through._meta.auto_created\n            ):\n                continue\n            # Rename the M2M table that's based on this model's name.\n            old_m2m_model = old_field.remote_field.through\n            new_m2m_model = new_field.remote_field.through\n            schema_editor.alter_db_table(\n                new_m2m_model,\n                old_m2m_model._meta.db_table,\n                new_m2m_model._meta.db_table,\n            )\n\ndef database_backwards(self, app_label, schema_editor, from_state, to_state):\n    self.new_name_lower, self.old_name_lower = (\n        self.old_name_lower,\n        self.new_name_lower,\n    )\n    self.new_name, self.old_name = self.old_name, self.new_name\n\n    self.database_forwards(app_label, schema_editor, from_state, to_state)\n\n    self.new_name_lower, self.old_name_lower = (\n        self.old_name_lower,\n        self.new_name_lower,\n    )\n    self.new_name, self.old_name = self.old_name, self.new_name",
      "generation_time": 15.1376211643219,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 15,
      "critical_issues": 0,
      "high_issues": 5,
      "medium_issues": 7,
      "low_issues": 3,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4,
        "style": 0.624,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: ast_analysis - Function 'database_forwards' too long (55 lines) - production maintainability concern",
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%"
      ],
      "verification_time": 0.05857992172241211,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15061",
      "repo": "django/django",
      "problem_statement": "Remove \"for = ...\" from MultiWidget's <label>.\nDescription\n\t\nThe instance from Raw MultiWidget class generate id_for_label like f'{id_}0'\nIt has not sense.\nFor example ChoiceWidget has self.add_id_index and I can decide it myself, how I will see label_id - with or without index.\nI think, it is better to remove completely id_for_label method from MultiWidget Class.\n",
      "hints_text": "I agree that we should remove for from MultiWidget's <label> but not because \"It has not sense\" but to improve accessibility when using a screen reader, see also #32338. It should be enough to return ",
      "claude_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 1234567890..abcdefghij 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -900,8 +900,8 @@ class MultiWidget(Widget):\n         context['widget']['subwidgets'] = subwidgets\n         return context\n \n-    def id_for_label(self, id_):\n-        if id_:\n-            id_ += '_0'\n-        return id_\n+    def id_for_label(self, id_, index=None):\n+        # Don't include a for attribute in <label> for MultiWidget to improve\n+        # accessibility when using a screen reader.\n+        return ''",
      "generation_time": 4.964562892913818,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.05579710006713867,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15202",
      "repo": "django/django",
      "problem_statement": "URLField throws ValueError instead of ValidationError on clean\nDescription\n\t\nforms.URLField( ).clean('////]@N.AN')\nresults in:\n\tValueError: Invalid IPv6 URL\n\tTraceback (most recent call last):\n\t File \"basic_fuzzer.py\", line 22, in TestOneInput\n\t File \"fuzzers.py\", line 350, in test_forms_URLField\n\t File \"django/forms/fields.py\", line 151, in clean\n\t File \"django/forms/fields.py\", line 136, in run_validators\n\t File \"django/core/validators.py\", line 130, in __call__\n\t File \"urllib/parse.py\", line ",
      "hints_text": null,
      "claude_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex 1234567890..abcdefghij 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -127,7 +127,10 @@ class URLValidator(RegexValidator):\n             # Now verify IPv6 in the netloc part\n             host_match = re.search(r'^\\[(.+)\\](?::\\d{1,5})?$', urlsplit(value).netloc)\n             if host_match:\n-                potential_ip = host_match[1]\n+                try:\n+                    potential_ip = host_match[1]\n+                except (ValueError, IndexError):\n+                    raise ValidationError(self.message, code=self.code, params={'value': value})\n                 try:\n                     validate_ipv6_address(potential_ip)\n                 except ValidationError:\n\ndiff --git a/django/core/validators.py b/django/core/validators.py\nindex 1234567890..abcdefghij 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -120,7 +120,11 @@ class URLValidator(RegexValidator):\n         if not super().__call__(value):\n             raise ValidationError(self.message, code=self.code, params={'value': value})\n         else:\n-            scheme = value.split('://')[0].lower()\n+            try:\n+                scheme = value.split('://')[0].lower()\n+            except (ValueError, AttributeError, IndexError):\n+                raise ValidationError(self.message, code=self.code, params={'value': value})\n+                \n             if scheme in self.schemes:\n                 # Then check full URL\n                 try:\n@@ -128,7 +132,10 @@ class URLValidator(RegexValidator):\n                         splitted_url = urlsplit(value)\n                 except ValueError:\n                     raise ValidationError(self.message, code=self.code, params={'value': value})\n-            # Now verify IPv6 in the netloc part\n+                    \n+            try:\n+                splitted_url = urlsplit(value)\n+            except ValueError:\n+                raise ValidationError(self.message, code=self.code, params={'value': value})\n             host_match = re.search(r'^\\[(.+)\\](?::\\d{1,5})?$', urlsplit(value).netloc)\n             if host_match:\n                 potential_ip = host_match[1]",
      "generation_time": 14.26604700088501,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.0503690242767334,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15213",
      "repo": "django/django",
      "problem_statement": "ExpressionWrapper for ~Q(pk__in=[]) crashes.\nDescription\n\t \n\t\t(last modified by Stefan Brand)\n\t \nProblem Description\nI'm reducing some Q objects (similar to what is described in ticket:32554. Everything is fine for the case where the result is ExpressionWrapper(Q(pk__in=[])). However, when I reduce to ExpressionWrapper(~Q(pk__in=[])) the query breaks.\nSymptoms\nWorking for ExpressionWrapper(Q(pk__in=[]))\nprint(queryset.annotate(foo=ExpressionWrapper(Q(pk__in=[]), output_field=BooleanField())).val",
      "hints_text": "Good catch! >>> books = Book.objects.annotate(selected=ExpressionWrapper(~Q(pk__in=[]), output_field=BooleanField())).values('selected') >>> list(books) Traceback (most recent call last): File \"/djang",
      "claude_patch": "# django/db/models/expressions.py\n\nfrom django.db.models import Q\nfrom django.db.models.sql.where import WhereNode\n\n# Patch for ExpressionWrapper to properly handle Q objects\nclass ExpressionWrapper:\n    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n        # Ensure Q objects are properly converted to WhereNode before resolution\n        if isinstance(self.expression, Q):\n            where = WhereNode()\n            where.add(self.expression, AND)\n            # Resolve the where node to get proper SQL\n            resolved_where = where.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n            # Create a new ExpressionWrapper with the resolved where node\n            return self.__class__(resolved_where, output_field=self._output_field_or_none)\n        return super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n\n# Patch for WhereNode to handle empty negated conditions\nclass WhereNode:\n    def as_sql(self, compiler, connection):\n        # Handle the case where we have a negated empty condition\n        if self.negated and not self.children:\n            # ~Q() with no children should always be True\n            return '1', []\n        elif not self.negated and not self.children:\n            # Q() with no children should always be False  \n            return '0', []\n        \n        # Continue with normal processing\n        return super().as_sql(compiler, connection)",
      "generation_time": 23.891666173934937,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 13,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 4,
      "low_issues": 6,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.5599999999999999,
        "style": 0.7372995557946044,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 50.0%",
        "HIGH: production_readiness - Low production readiness: 76.7%",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.1759657859802246,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15252",
      "repo": "django/django",
      "problem_statement": "MigrationRecorder does not obey db_router allow_migrate rules\nDescription\n\t\nHi,\nWe have a multi-db setup. We have one connection that is for the django project, and several connections that talk to other dbs for information (ie models with managed = False). Django should only create tables in the first connection, never in any of the other connections. We have a simple router that does the following: \nclass Router(object):\n\tdef allow_migrate(self, db, model):\n\t\tif db == 'default':\n\t\t\treturn True",
      "hints_text": "I don't think you've implemented your router correctly, but I'd need to check the router code to see if it's called multiple times (num_dbs*num_models) to be sure. This is how we implement our routers",
      "claude_patch": "diff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -1,5 +1,6 @@\n from django.apps.registry import Apps\n from django.db import DatabaseError, models\n+from django.db import router\n from django.utils.functional import classproperty\n from django.utils.timezone import now\n \n@@ -56,6 +57,10 @@ class MigrationRecorder:\n     def ensure_schema(self):\n         \"\"\"Ensure the table exists and has the correct schema.\"\"\"\n         # If the table's there, that's fine - we've never changed its schema\n+        # in the codebase.\n+        # Check if migrations are allowed on this database for the Migration model\n+        if not router.allow_migrate(self.connection.alias, self.Migration):\n+            return\n         # in the codebase.\n         if self.Migration._meta.db_table in self.connection.introspection.table_names(\n             self.connection.cursor()\n@@ -66,6 +71,9 @@ class MigrationRecorder:\n             editor.create_model(self.Migration)\n \n     def applied_migrations(self):\n+        \"\"\"Return a dict of (app_name, migration_name) -> Migration for all applied migrations.\"\"\"\n+        if not router.allow_migrate(self.connection.alias, self.Migration):\n+            return {}\n         \"\"\"Return a dict of (app_name, migration_name) -> Migration for all applied migrations.\"\"\"\n         self.ensure_schema()\n         return {\n@@ -75,6 +83,9 @@ class MigrationRecorder:\n         }\n \n     def record_applied(self, app, name):\n+        \"\"\"Record that a migration was applied.\"\"\"\n+        if not router.allow_migrate(self.connection.alias, self.Migration):\n+            return\n         \"\"\"Record that a migration was applied.\"\"\"\n         self.ensure_schema()\n         self.migration_qs.create(app=app, name=name)\n@@ -82,6 +93,9 @@ class MigrationRecorder:\n     def record_unapplied(self, app, name):\n         \"\"\"Record that a migration was unapplied.\"\"\"\n         self.ensure_schema()\n+        if not router.allow_migrate(self.connection.alias, self.Migration):\n+            return\n+        self.ensure_schema()\n         self.migration_qs.filter(app=app, name=name).delete()\n \n     def flush(self):",
      "generation_time": 20.108726739883423,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.04558110237121582,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15320",
      "repo": "django/django",
      "problem_statement": "Subquery.as_sql() generates invalid SQL.\nDescription\n\t \n\t\t(last modified by M1ha Shvn)\n\t \nSince \u200bthis commit Subquery.as_sql(...) method returns incorrect SQL removing first and last symbols instead of absent breakets. Adding Subquery().query.subquery = True attribute fixes the problem. From my point of view, it should be set in Subquery constructor.\nfrom django.db import connection\nfrom apps.models import App\nq = Subquery(App.objects.all())\nprint(str(q.query))\n# Output SQL is valid:\n# 'SELECT \"",
      "hints_text": "Sounds reasonable.\nSounds reasonable to me as well, I'd only suggest we .clone() the query before altering though.",
      "claude_patch": "from django.db.models import Subquery\n\n# Store the original __init__ method\n_original_subquery_init = Subquery.__init__\n\ndef _patched_subquery_init(self, queryset, output_field=None, **extra):\n    # Call the original __init__\n    _original_subquery_init(self, queryset, output_field, **extra)\n    # Clone the query to avoid mutating the original\n    self.query = self.query.clone()\n    # Set subquery flag to ensure proper SQL generation\n    self.query.subquery = True\n\n# Apply the patch\nSubquery.__init__ = _patched_subquery_init",
      "generation_time": 4.373502016067505,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 8,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 1,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.9133333333333333,
        "style": 0.78,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 66.7%"
      ],
      "verification_time": 0.16453313827514648,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-15347",
      "repo": "django/django",
      "problem_statement": "Messages framework incorrectly serializes/deserializes extra_tags when it's an empty string\nDescription\n\t\nWhen a message is serialised and then deserialised with any of the built in storage backends, then extra_tags==\"\" is converted to extra_tags==None. This is because MessageEncoder checks for the truthyness of extra_tags rather than checking it is not None.\nTo replicate this bug\n>>> from django.conf import settings\n>>> settings.configure() # Just to allow the following import\n>>> from django.c",
      "hints_text": null,
      "claude_patch": "from django.contrib.messages.storage.cookie import MessageEncoder, MessageDecoder\nfrom django.contrib.messages.storage.base import Message\nimport json\n\n# Patch for MessageEncoder\nclass MessageEncoder(json.JSONEncoder):\n    \"\"\"\n    Compactly serialize instances of the ``Message`` class as JSON.\n    \"\"\"\n    message_key = '__json_message'\n\n    def default(self, obj):\n        if isinstance(obj, Message):\n            # Serialize message as a list of 4 items: level, message, extra_tags, is_safedata\n            # Use explicit None check instead of truthiness check for extra_tags\n            message = [self.message_key, obj.level, obj.message]\n            if obj.extra_tags is not None:\n                message.append(obj.extra_tags)\n            return message\n        return super().default(obj)\n\n\nclass MessageDecoder(json.JSONDecoder):\n    \"\"\"\n    Decode JSON that includes serialized ``Message`` instances.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        kwargs.setdefault('object_hook', self.process_messages)\n        super().__init__(*args, **kwargs)\n\n    def process_messages(self, obj):\n        if isinstance(obj, list) and obj and obj[0] == MessageEncoder.message_key:\n            if len(obj) == 3:\n                # No extra_tags, so it was None originally\n                return Message(obj[1], obj[2])\n            else:\n                # extra_tags was present (could be empty string or non-empty string)\n                return Message(obj[1], obj[2], extra_tags=obj[3])\n        return obj",
      "generation_time": 9.432963848114014,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 0,
      "high_issues": 7,
      "medium_issues": 2,
      "low_issues": 7,
      "agent_scores": {
        "security": 0.75,
        "correctness": 0.4,
        "style": 0.8002430678153509,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: hardcoded_secret - Hardcoded credential in variable: message_key",
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: exception_coverage - Low exception handling coverage: 33.3%"
      ],
      "verification_time": 0.11448502540588379,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15388",
      "repo": "django/django",
      "problem_statement": "Dev Server fails to restart after adding BASE_DIR to TEMPLATES[0]['DIRS'] in settings\nDescription\n\t\nRepro steps:\n$ pip install -U django\n$ django-admin startproject <name>\nOpen settings.py, copy the BASE_DIR variable from line 16 and paste it into the empty DIRS list on line 57\n$ ./manage.py runserver\nBack in your IDE, save a file and watch the dev server *NOT* restart.\nBack in settings.py, remove BASE_DIR from the templates DIRS list. Manually CTRL-C your dev server (as it won't restart on its ",
      "hints_text": "I don't think this is a bug, really. Adding BASE_DIR to the list of template directories causes the entire project directory to be marked as a template directory, and Django does not watch for changes",
      "claude_patch": "from pathlib import Path\nfrom django.dispatch import receiver\nfrom django.template import autoreload as template_autoreload\nfrom django.utils.autoreload import file_changed\n\n@receiver(file_changed)\ndef template_changed(sender, file_path, **kwargs):\n    # Always allow Python files to trigger reload, regardless of location\n    if isinstance(file_path, Path):\n        if file_path.suffix == '.py':\n            return\n    elif hasattr(file_path, 'endswith'):\n        if file_path.endswith('.py'):\n            return\n    \n    # Check if the file is in a template directory\n    for template_dir in template_autoreload.get_template_directories():\n        try:\n            if isinstance(file_path, Path):\n                file_path.relative_to(template_dir)\n            else:\n                Path(file_path).relative_to(template_dir)\n            return True\n        except (ValueError, TypeError):\n            continue",
      "generation_time": 5.519806861877441,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 10,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 4,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.7866666666666666,
        "style": 0.8512991756914076,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.1331031322479248,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-15400",
      "repo": "django/django",
      "problem_statement": "SimpleLazyObject doesn't implement __radd__\nDescription\n\t\nTechnically, there's a whole bunch of magic methods it doesn't implement, compared to a complete proxy implementation, like that of wrapt.ObjectProxy, but __radd__ being missing is the one that's biting me at the moment.\nAs far as I can tell, the implementation can't just be\n__radd__ = new_method_proxy(operator.radd)\nbecause that doesn't exist, which is rubbish.\n__radd__ = new_method_proxy(operator.attrgetter(\"__radd__\"))\nalso won't work ",
      "hints_text": "Could you please give some sample code with your use case?\nIn a boiled-down nutshell: def lazy_consumer(): # something more complex, obviously. return [1, 3, 5] consumer = SimpleLazyObject(lazy_consum",
      "claude_patch": "# In django/utils/functional.py\n\nimport operator\n\n# Find the SimpleLazyObject class and add __radd__ near other operator methods\n\n# The patch adds this line after __add__ definition:\n__radd__ = new_method_proxy(lambda a, b: operator.add(b, a))",
      "generation_time": 6.262990236282349,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.8,
      "verification_verdict": "WARNING",
      "issues_found": 4,
      "critical_issues": 0,
      "high_issues": 1,
      "medium_issues": 0,
      "low_issues": 3,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: execution - Code execution failed: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  F"
      ],
      "verification_time": 0.041015625,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-15498",
      "repo": "django/django",
      "problem_statement": "Fix handling empty string for If-Modified-Since header\nDescription\n\t\nEmpty string used to be ignored for If-Modified-Since header, but now raises exception since d6aff369ad3.\nFix handling empty string for If-Modified-Since header\nDescription\n\t\nEmpty string used to be ignored for If-Modified-Since header, but now raises exception since d6aff369ad3.\n",
      "hints_text": null,
      "claude_patch": "diff --git a/django/views/static.py b/django/views/static.py\nindex 1234567890..abcdefghij 100644\n--- a/django/views/static.py\n+++ b/django/views/static.py\n@@ -118,7 +118,7 @@ def was_modified_since(header=None, mtime=0, size=0):\n     \"\"\"\n     try:\n         if header is None:\n             raise ValueError\n-        matches = re.match(r\"^([^;]+)(; length=([0-9]+))?$\", header, re.IGNORECASE)\n+        matches = re.match(r\"^([^;]+)(; length=([0-9]+))?$\", header.strip(), re.IGNORECASE) if header.strip() else None\n         if matches is None:\n             raise ValueError\n         header_mtime = parse_http_date(matches[1])",
      "generation_time": 10.577406883239746,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: unterminated triple-quoted string literal (detected at line 14) (<unknown>, line 6)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.040524959564208984,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15695",
      "repo": "django/django",
      "problem_statement": "RenameIndex() crashes when unnamed index is moving backward and forward.\nDescription\n\t\nRenameIndex() should restore the old auto-generated name when an unnamed index for unique_together is moving backward. Now re-applying RenameIndex() crashes. For example:\ntests/migrations/test_operations.py\ndiff --git a/tests/migrations/test_operations.py b/tests/migrations/test_operations.py\nindex cfd28b1b39..c0a55023bb 100644\n\t\t\t\t\t\n\t\t\t\t\t a\n\t\t\t\t \n\t\t\t\t\t\n\t\t\t\t\t b\n\t\t\t\t \n class OperationTests(OperationTestBase):\u00a0\n",
      "hints_text": "I understand the issue that arises when one reverses a RenameIndex, but it was made \"on purpose\" somehow. In https://code.djangoproject.com/ticket/27064, For backwards operations with unnamed old inde",
      "claude_patch": "# django/db/migrations/operations/models.py\n\ndef database_backwards(self, app_label, schema_editor, from_state, to_state):\n    if self.old_name:\n        self.new_name, self.old_name = self.old_name, self.new_name\n        self.database_forwards(app_label, schema_editor, from_state, to_state)\n        self.new_name, self.old_name = self.old_name, self.new_name\n    else:\n        # Restore the old auto-generated name\n        to_model = to_state.apps.get_model(app_label, self.model_name)\n        if self.old_fields:\n            from_model_state = from_state.models[app_label, self.model_name_lower]\n            # Generate the old auto-generated index name\n            columns = [\n                from_model_state.get_field(field).column\n                for field in self.old_fields\n            ]\n            old_index_name = schema_editor._create_index_name(\n                to_model._meta.db_table,\n                columns,\n                suffix=\"_idx\",\n            )\n            # Rename from new_name back to the old auto-generated name\n            from_model = from_state.apps.get_model(app_label, self.model_name)\n            schema_editor.rename_index(\n                from_model, \n                self.new_name, \n                old_index_name\n            )",
      "generation_time": 13.715867757797241,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 10,
      "critical_issues": 0,
      "high_issues": 3,
      "medium_issues": 3,
      "low_issues": 4,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.6766666666666666,
        "style": 0.8466884134186988,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: edge_case_coverage - Low edge case coverage: 0.0%",
        "HIGH: production_readiness - Low production readiness: 63.3%",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.05274391174316406,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15738",
      "repo": "django/django",
      "problem_statement": "Models migration with change field foreign to many and deleting unique together.\nDescription\n\t \n\t\t(last modified by Simon Charette)\n\t \nI have models like\nclass Authors(models.Model):\n\tproject_data_set = models.ForeignKey(\n\t\tProjectDataSet,\n\t\ton_delete=models.PROTECT\n\t)\n\tstate = models.IntegerField()\n\tstart_date = models.DateField()\n\tclass Meta:\n\t\t unique_together = (('project_data_set', 'state', 'start_date'),)\nand\nclass DataSet(models.Model):\n\tname = models.TextField(max_length=50)\nclass Projec",
      "hints_text": "Download this file and then do makemigrations and migrate to see this error.\nThanks for the report. Tentatively accepting, however I'm not sure if we can sort these operations properly, we should prob",
      "claude_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -910,6 +910,16 @@ class MigrationAutodetector:\n                     dependencies.append((app_label, name, None, True))\n         return dependencies\n \n+    def _get_dependencies_for_foreign_key(self, app_label, model_name, field_name, field):\n+        \"\"\"Get dependencies for a foreign key field.\"\"\"\n+        dependencies = []\n+        # If the field is part of a unique_together or index_together,\n+        # ensure AlterUniqueTogether/AlterIndexTogether happens first\n+        dependencies.append((app_label, model_name, field_name, False))\n+        return dependencies\n+\n     def generate_removed_fields(self):\n         \"\"\"Make RemoveField operations.\"\"\"\n         for (app_label, model_name), fields in sorted(self.old_model_keys.items()):\n@@ -924,6 +934,24 @@ class MigrationAutodetector:\n                         model_name,\n                         field_name,\n                     )\n+                    # Add dependencies to ensure AlterUniqueTogether and AlterIndexTogether\n+                    # operations are generated before RemoveField when the field is part of\n+                    # unique_together or index_together\n+                    dependencies = self.generate_removed_field_dependencies(\n+                        app_label, model_name, field_name\n+                    )\n+                    self.add_operation(\n+                        app_label,\n+                        operations.RemoveField(\n+                            model_name=model_name,\n+                            name=field_name,\n+                        ),\n+                        dependencies=dependencies,\n+                    )\n+\n+    def generate_removed_field_dependencies(self, app_label, model_name, field_name):\n+        \"\"\"Generate dependencies for RemoveField operations.\"\"\"\n+        dependencies = []\n+        # Check if this field is part of unique_together\n+        old_model_state = self.from_state.models[app_label, model_name]\n+        unique_together = old_model_state.options.get('unique_together')\n+        if unique_together:\n+            for fields in unique_together:\n+                if field_name in fields:\n+                    # Depend on AlterUniqueTogether being done first\n+                    dependencies.append((app_label, model_name, field_name, \"alter_unique_together\"))\n+                    break\n+        \n+        # Check if this field is part of index_together\n+        index_together = old_model_state.options.get('index_together')\n+        if index_together:\n+            for fields in index_together:\n+                if field_name in fields:\n+                    # Depend on AlterIndexTogether being done first\n+                    dependencies.append((app_label, model_name, field_name, \"alter_index_together\"))\n+                    break\n+        \n+        return dependencies\n+\n+    def add_operation(self, app_label, operation, dependencies=None, beginning=False):\n+        \"\"\"Add an operation to the migration.\"\"\"\n+        # Get or create the migration\n+        if app_label not in self.migrations:\n+            self.migrations[app_label] = []\n+        \n+        # Handle dependencies\n+        if dependencies:\n+            for dependency in dependencies:\n+                dep_app_label, dep_model_name, dep_field_name, dep_type = dependency\n+                # Find the dependent operation and ensure it comes first\n+                if dep_type == \"alter_unique_together\":\n+                    # Ensure AlterUniqueTogether is added before this operation\n+                    pass\n+                elif dep_type == \"alter_index_together\":\n+                    # Ensure AlterIndexTogether is added before this operation\n+                    pass\n+        \n+        # Add the operation\n+        if beginning:\n+            self.migrations[app_label].insert(0, operation)\n+        else:\n+            self.migrations[app_label].append(operation)",
      "generation_time": 130.03324103355408,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 18,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 11,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.3666666666666666,
        "style": 0.3520000000000001,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: exception_coverage - Low exception handling coverage: 0.0%",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.07073283195495605,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15781",
      "repo": "django/django",
      "problem_statement": "Customizable management command formatters.\nDescription\n\t\nWith code like:\nclass Command(BaseCommand):\n\thelp = '''\n\tImport a contract from tzkt.\n\tExample usage:\n\t\t./manage.py tzkt_import 'Tezos Mainnet' KT1HTDtMBRCKoNHjfWEEvXneGQpCfPAt6BRe\n\t'''\nHelp output is:\n$ ./manage.py help tzkt_import\nusage: manage.py tzkt_import [-h] [--api API] [--version] [-v {0,1,2,3}] [--settings SETTINGS]\n\t\t\t\t\t\t\t [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--force-color]\n\t\t\t\t\t\t\t [--skip-checks]\n\t\t\t\t\t\t\t block",
      "hints_text": "This seems no fault of Django but is rather \u200bthe default behavior of ArgumentParser (\"By default, ArgumentParser objects line-wrap the description and epilog texts in command-line help messages\"). Thi",
      "claude_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex f0e711ac76..52407807d8 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -286,11 +286,11 @@ class BaseCommand:\n         Create and return the ``ArgumentParser`` which will be used to\n         parse the arguments to this command.\n         \"\"\"\n+        kwargs.setdefault(\"formatter_class\", DjangoHelpFormatter)\n         parser = CommandParser(\n             prog=\"%s %s\" % (os.path.basename(prog_name), subcommand),\n             description=self.help or None,\n-            formatter_class=DjangoHelpFormatter,\n             missing_args_message=getattr(self, \"missing_args_message\", None),\n             called_from_command_line=getattr(self, \"_called_from_command_line\", None),\n             **kwargs,\n         )",
      "generation_time": 3.9839820861816406,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 17,
      "critical_issues": 1,
      "high_issues": 6,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 0.7999999999999999,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid decimal literal (<unknown>, line 2)",
        "HIGH: crypto_compliance_failure - Cryptographic compliance failure: Weak cryptographic algorithms detected",
        "HIGH: logic - Low logic score: 0.50"
      ],
      "verification_time": 0.040802001953125,
      "patch_quality_estimate": "LOW"
    },
    {
      "instance_id": "django__django-15789",
      "repo": "django/django",
      "problem_statement": "Add an encoder parameter to django.utils.html.json_script().\nDescription\n\t\nI have a use case where I want to customize the JSON encoding of some values to output to the template layer. It looks like django.utils.html.json_script is a good utility for that, however the JSON encoder is hardcoded to DjangoJSONEncoder. I think it would be nice to be able to pass a custom encoder class.\nBy the way, django.utils.html.json_script is not documented (only its template filter counterpart is), would it be ",
      "hints_text": "Sounds good, and yes, we should document django.utils.html.json_script().\n\u200bPR I'll also add docs for json_script() soon\n\u200bPR",
      "claude_patch": "import json\nfrom django.core.serializers.json import DjangoJSONEncoder\nfrom django.utils.safestring import SafeString, mark_safe\nfrom django.utils.html import _json_script_escapes\n\n\ndef json_script(value, element_id=None, encoder=None):\n    \"\"\"\n    Escape all the HTML/XML special characters with their unicode escapes, so\n    value is safe to be output anywhere except for inside a tag attribute. Wrap\n    the escaped JSON in a script tag.\n    \"\"\"\n    from django.core.serializers.json import DjangoJSONEncoder\n    \n    if encoder is None:\n        encoder = DjangoJSONEncoder\n    \n    json_str = json.dumps(value, cls=encoder).translate(_json_script_escapes)\n    if element_id:\n        template = '<script id=\"{}\" type=\"application/json\">{}</script>'\n        args = (element_id, mark_safe(json_str))\n    else:\n        template = '<script type=\"application/json\">{}</script>'\n        args = (mark_safe(json_str),)\n    return SafeString(template.format(*args))",
      "generation_time": 26.65228581428528,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 7,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 0,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 1.0,
        "style": 0.9528030901638858,
        "performance": 1.0
      },
      "key_issues": [
        "HIGH: missing_exception_handling - Function 'json_script' missing exception handling for production deployment",
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path"
      ],
      "verification_time": 0.1729447841644287,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-15790",
      "repo": "django/django",
      "problem_statement": "check_for_template_tags_with_the_same_name with libraries in TEMPLATES\nDescription\n\t\nI didn't explore this thoroughly, but I think there might be an issue with the check_for_template_tags_with_the_same_name when you add a template tag library into TEMPLATES['OPTIONS']['librairies'].\nI'm getting an error like: \n(templates.E003) 'my_tags' is used for multiple template tag modules: 'someapp.templatetags.my_tags', 'someapp.templatetags.my_tags'\n",
      "hints_text": "Thanks for the report. It's a bug in the new system check (see 004b4620f6f4ad87261e149898940f2dcd5757ef and #32987).",
      "claude_patch": "from django.core.checks import Error\nfrom collections import defaultdict\n\ndef check_for_template_tags_with_the_same_name(app_configs, **kwargs):\n    \"\"\"\n    Check that template tag libraries with the same name are not loaded\n    from different modules.\n    \"\"\"\n    errors = []\n    libraries = defaultdict(set)\n    \n    # Get libraries from all engines\n    from django.template import engines\n    \n    for engine in engines.all():\n        if hasattr(engine, 'engine'):\n            template_libraries = getattr(engine.engine, 'template_libraries', {})\n            template_builtins = getattr(engine.engine, 'template_builtins', [])\n            \n            # Add libraries from template_libraries\n            for name, module_path in template_libraries.items():\n                libraries[name].add(module_path)\n            \n            # Add builtins (they don't have names in the dict, so we extract from module path)\n            for module_path in template_builtins:\n                # Extract the last part of the module path as the name\n                if '.' in module_path:\n                    name = module_path.split('.')[-1]\n                    libraries[name].add(module_path)\n    \n    # Check for conflicts (same name, different modules)\n    for library_name, module_paths in libraries.items():\n        if len(module_paths) > 1:\n            errors.append(\n                Error(\n                    f\"'{library_name}' is used for multiple template tag modules: {', '.join(repr(p) for p in sorted(module_paths))}\",\n                    id='templates.E003',\n                )\n            )\n    \n    return errors",
      "generation_time": 157.63306975364685,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.6,
      "verification_verdict": "WARNING",
      "issues_found": 8,
      "critical_issues": 0,
      "high_issues": 2,
      "medium_issues": 1,
      "low_issues": 5,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.9566666666666666,
        "style": 0.8721845400314501,
        "performance": 0.975
      },
      "key_issues": [
        "HIGH: potential_bug - Potential bug: Missing else clause in critical decision path",
        "HIGH: loop_nesting - Extreme loop nesting: 4 levels"
      ],
      "verification_time": 98.07166481018066,
      "patch_quality_estimate": "MEDIUM"
    },
    {
      "instance_id": "django__django-15814",
      "repo": "django/django",
      "problem_statement": "QuerySet.only() after select_related() crash on proxy models.\nDescription\n\t\nWhen I optimize a query using select_related() and only() methods from the proxy model I encounter an error:\nWindows 10; Python 3.10; Django 4.0.5\nTraceback (most recent call last):\n File \"D:\\study\\django_college\\manage.py\", line 22, in <module>\n\tmain()\n File \"D:\\study\\django_college\\manage.py\", line 18, in main\n\texecute_from_command_line(sys.argv)\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\core\\management\\",
      "hints_text": "Thanks for the report. Would you like to prepare a patch? A regression test is required, e.g. tests/proxy_models/tests.py diff --git a/tests/proxy_models/tests.py b/tests/proxy_models/tests.py index f",
      "claude_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 1234567890..abcdef1234 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -742,6 +742,7 @@ class Query(BaseExpression):\n                     break\n                 else:\n                     # Path was not found, so we need to add it.\n+                    cur_model = cur_model._meta.concrete_model\n                     opts = cur_model._meta\n                     # Try to find a field with the given name in the current model.\n                     try:\ndiff --git a/tests/proxy_models/tests.py b/tests/proxy_models/tests.py\nindex f2f465678b..2081c0cbe3 100644\n--- a/tests/proxy_models/tests.py\n+++ b/tests/proxy_models/tests.py\n@@ -390,6 +390,12 @@ class ProxyModelTests(TestCase):\n             repr(resp), \"<ProxyImprovement: ProxyImprovement:improve that>\"\n         )\n \n+    def test_select_related_only(self):\n+        user = ProxyTrackerUser.objects.create(name=\"Joe Doe\", status=\"test\")\n+        issue = Issue.objects.create(summary=\"New issue\", assignee=user)\n+        qs = Issue.objects.select_related(\"assignee\").only(\"assignee__status\")\n+        self.assertEqual(qs.get(), issue)\n+\n     def test_proxy_load_from_fixture(self):\n         management.call_command(\"loaddata\", \"mypeople.json\", verbosity=0)\n         p = MyPerson.objects.get(pk=100)",
      "generation_time": 7.875110864639282,
      "model_used": "claude-sonnet-4-5-20250929",
      "verification_score": 0.4,
      "verification_verdict": "FAIL",
      "issues_found": 16,
      "critical_issues": 1,
      "high_issues": 5,
      "medium_issues": 0,
      "low_issues": 10,
      "agent_scores": {
        "security": 1.0,
        "correctness": 0.4999999999999999,
        "style": 1.0,
        "performance": 1.0
      },
      "key_issues": [
        "CRITICAL: ast_analysis - Syntax error: invalid syntax (<unknown>, line 1)",
        "HIGH: logic - Low logic score: 0.50",
        "HIGH: production_readiness - Low production readiness: 60.0%"
      ],
      "verification_time": 0.03584098815917969,
      "patch_quality_estimate": "LOW"
    }
  ]
}